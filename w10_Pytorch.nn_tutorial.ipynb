{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is `torch.nn` *really*?  (translated by huffon)\n",
    "============================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch는 사용자가 신경망을 모델링하고 훈련시키는데 도움이 될 수 있는 정교히 고안된 모듈과 클래스들을 제공하며, `torch.nn`, `torch.optim`, `Dataset`, `DataLoader` 이 그 좋은 예이다.\n",
    "- 이러한 모듈들을 잘 활용하고 사용자가 풀고자 하는 문제에 맞게 커스터마이징하기 위해서는 각 모듈들이 내부적으로 어떠한 일을 수행하는지 알 필요가 있다.\n",
    "- 각 모듈들의 내부 로직을 이해하기 위해 처음에는 아무 모듈도 사용하지 않은 채 기본 신경망을 훈련시켜 볼 것\n",
    "    - 즉, PyTorch의 가장 기본적인 tensor 기능들만 사용하며 모델링 !\n",
    "    - 이후, `torch.nn`, `torch.optim`, `Dataset`, `DataLoader` 등의 모듈들을 하나씩 추가해가며 각 모듈이 어떤 역할을 수행하는지 알아볼 것\n",
    "\n",
    "\n",
    "\n",
    "MNIST 데이터 셋업\n",
    "----------------\n",
    "\n",
    "- 가장 기본적인 `MNIST` 데이터셋을 사용할 것: 해당 데이터셋은 손글씨로 적힌 흑백의 0부터 9까지의 숫자로 구성\n",
    "- Python3의 스탠다드 라이브러리인 `pathlib`을 경로 관리를 위해 사용할 것이며, 데이터셋을 다운로드 할 때는 `requests` 라이브러리를 사용\n",
    "- 이 때, 라이브러리를 필요한 시기에만 import 함으로써 어떤 라이브러리가 어떤 지점에서 사용되는지를 보다 자세히 확인하게 될 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "# parents: 경로에서 필요한 파일이 없을 경우, 생성해주는 옵션\n",
    "# exist_ok: 이미 경로에 해당하는 폴더가 존재하더라도 괜찮다는 옵션\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "# 다운로드 받고자 하는 파일이 존재하지 않을 경우, 다운로드 수행\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다운 받은 MNIST 데이터셋은 numpy 배열 포맷으로 구성된 데이터들이 pickle 포맷으로 이진화되어 저장된 형태\n",
    "- **pickle**은 python에서 데이터의 시리얼라이즈를 위해 사용되는 파일 포맷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# as_posix: 경로를 string 형태로 반환\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각각의 이미지는 28x28의 픽셀이 1차원으로 나열되어 있는 구조: (28x28) = 784\n",
    "- 해당 데이터를 2차원으로 reshape 후, 그림으로 찍어보자 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train dataset shape: (50000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11dcc5978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "print(f'Total train dataset shape: {x_train.shape}')\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch는 기본 자료형으로 `torch.tensor`를 사용하기 때문에 데이터를 변환시켜줄 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "\n",
    "n, c = x_train.shape\n",
    "\n",
    "# torch.tensor로 변환된 데이터와 라벨 확인\n",
    "print(x_train, y_train)\n",
    "\n",
    "# 훈련 데이터의 shape 확인\n",
    "print(x_train.shape)\n",
    "\n",
    "# 라벨 데이터의 최대, 최소값 확인\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn을 사용하지 않고 신경망 구성해보기\n",
    "---------------------------------------------\n",
    "\n",
    "- 먼저, PyTorch의 tensor 연산만을 이용해 모델을 구성해보자 !\n",
    "- PyTorch는 0 혹은 임의의 수로 tensor를 채워줄 수 있는 생성 연산을 제공한다. \n",
    "- 우리는 해당 연산을 활용해 차후 선형 모델의 가중치와 편향을 생성할 것 !\n",
    "- `torch.tensor`는 보통의 tensor와 크게 다르지는 않지만, `기울기` 계산이 필요하다는 정보를 `requires_grad` 속성에 기록한다는 특징을 가진다.\n",
    "- 해당 속성을 이용해 PyTorch 프레임워크는 tensor에 행해지는 모든 연산을 기록하며, 역전파 수행 시 기울기를 자동으로 계산해주게 되는 것\n",
    "- 그러니, 기울기 계산을 PyTorch에 맡기기 위해, 가중치 tensor 초기화 이후 `requires_grad` 옵션을 설정해주도록 하자\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Xavier 가중치 초기화 기법을 이용해 가중치를 초기화 할 것이며, 해당 초기화는 가중치를 1/sqrt(n)만큼 곱해서 이루어짐</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch가 기울기를 자동으로 계산해주는 덕분에, 우리는 Python 표준 함수들을 모델에서도 쉽게 사용할 있게 된다 !\n",
    "- 또한 **활성화 함수**가 필요하기 때문에 `log_softmax` 함수를 작성할 것.\n",
    "- PyTorch가 이미 기작성된 손실 함수, 활성화 함수 등을 제공해주기는 하지만, python 함수를 이용해 간단한 사용자 정의 함수를 작성해 사용할 수도 있다는 것을 기억하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    print(f'activated x value: {x[0]}')\n",
    "    print(f'exponential summation value: {x.exp().sum(-1).log().unsqueeze(-1)[0]}\\n')\n",
    "    # exp(x)를 row 기준으로 summation 한 뒤, log 취한 값\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 `@` 문자는 dot product 연산을 의미\n",
    "- 앞서 정의한 함수를 하나의 mini-batch에 대해 호출할 것이며, 한 batch는 64개의 이미지로 구성될 것.\n",
    "- 가중치가 randn으로 정의되어 있으므로, 초기의 예측값은 좋을 수가 없음 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-0.7498,  0.2105,  0.2900, -0.1753, -0.0628, -0.0151,  0.2832, -0.0061,\n",
      "         0.1485, -0.0928], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.3223], grad_fn=<SelectBackward>)\n",
      "\n",
      "tensor([-3.0721, -2.1118, -2.0323, -2.4976, -2.3852, -2.3374, -2.0391, -2.3284,\n",
      "        -2.1738, -2.4151], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a mini-batch from x: (64, 784)\n",
    "preds = model(xb)   # predictions: (64, 10)\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞서 확인했듯 `preds` tensor는 값 뿐만 아니라, gradient 함수 정보를 포함며 해당 정보는 이후 역전파에 사용\n",
    "- 이제 손실 함수로 사용할 `Negative log-likelihood` 함수를 정의해보자 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    print(f'substrated value(loss candidates):\\n {input[0]}')\n",
    "    print(f'target index: {target[0]}\\n')\n",
    "    print(f'loss value: {input[range(input.shape[0]), target][0]:.3f}')\n",
    "    return -input[range(target.shape[0]), target].mean()   # [row, column]\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의로 정의된 가중치를 사용한 모델의 손실 값을 확인한 후, 역전파를 거친 후의 성능이 개선되는지 살펴볼 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-3.0721, -2.1118, -2.0323, -2.4976, -2.3852, -2.3374, -2.0391, -2.3284,\n",
      "        -2.1738, -2.4151], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.337\n",
      "tensor(2.3525, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번엔 모델의 정확도를 계산할 함수를 정의해보자\n",
    "- prediction에서 가장 높은 확률 값을 가진 원소의 인덱스와 타겟 값이 같을 경우 예측이 성공한 것으로 상정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의로 정의된 가중치를 사용한 모델의 정확도를 확인한 후, 손실 값이 줄어듬에 따라 성능이 개선되는지 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1094)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 반복문을 이용해 훈련을 진행해보자:\n",
    "\n",
    "- 미니배치 사이즈를 설정(`bs`)\n",
    "- 모델을 이용해 예측 값 계산\n",
    "- 손실 함수를 이용해 손실 값 계산\n",
    "- `loss.backward()` 함수를 이용해 모델의 `가중치`와 `편향`의 기울기를 업데이트\n",
    "\n",
    "기울기 업데이트는 `torch.no_grad()` 컨텍스트에서 이루어져야 하는데, 기울기를 업데이트 하는 과정에서 발생하는 연산이 다음 번 기울기 계산 과정에 들어가기 않게 하기 위함입니다.\n",
    "\n",
    "이후, 다음 반복을 수행하기 위해 기울기들을 0으로 초기화합니다.\n",
    "\n",
    "기울기의 0 초기화를 수행해주지 않으면 `loss.backward()` 과정에서 발생하는 기울기들이 모두 쌓이게 되고 이는 가중치 업데이트를 저해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-0.7498,  0.2105,  0.2900, -0.1753, -0.0628, -0.0151,  0.2832, -0.0061,\n",
      "         0.1485, -0.0928], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.3223], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.0721, -2.1118, -2.0323, -2.4976, -2.3852, -2.3374, -2.0391, -2.3284,\n",
      "        -2.1738, -2.4151], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.337\n",
      "activated x value: tensor([ 1.6102, -0.8791, -1.0345, -0.0286,  0.1534, -0.5384,  0.2786, -0.4934,\n",
      "        -0.6537, -0.3933], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.4529], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-0.8427, -3.3320, -3.4874, -2.4816, -2.2996, -2.9913, -2.1744, -2.9464,\n",
      "        -3.1066, -2.8462], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -2.300\n",
      "activated x value: tensor([-1.3190,  3.1966,  0.9759, -0.9283, -0.8157, -0.8446,  0.6520,  0.2632,\n",
      "         0.4001, -0.3088], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5288], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.8478, -0.3322, -2.5529, -4.4571, -4.3445, -4.3734, -2.8768, -3.2656,\n",
      "        -3.1287, -3.8376], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.332\n",
      "activated x value: tensor([ 1.8991, -3.8931,  1.9610, -0.0300,  0.9871,  0.5307,  0.4200, -0.6764,\n",
      "        -0.2909,  0.9062], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.1951], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2960, -7.0883, -1.2342, -3.2251, -2.2081, -2.6644, -2.7752, -3.8715,\n",
      "        -3.4860, -2.2889], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -1.296\n",
      "activated x value: tensor([-3.6431e-01,  1.5634e+00,  3.4005e-01,  1.8070e-01, -9.1823e-01,\n",
      "         4.9677e-01, -1.2121e-01,  1.0690e-03,  8.3283e-01, -9.9524e-01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.6859], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.0502, -1.1226, -2.3459, -2.5052, -3.6041, -2.1891, -2.8071, -2.6848,\n",
      "        -1.8531, -3.6812], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -2.807\n",
      "activated x value: tensor([ 1.6300, -2.4503,  0.8379, -0.7523,  0.0588,  1.5364,  1.0674, -0.5194,\n",
      "        -0.2079, -0.7464], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.9162], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2862, -5.3664, -2.0782, -3.6685, -2.8574, -1.3798, -1.8488, -3.4355,\n",
      "        -3.1240, -3.6625], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -1.286\n",
      "activated x value: tensor([-1.7584, -0.4161, -0.0454, -0.8680,  1.3453, -0.5478, -0.6856,  1.3516,\n",
      "         0.2191,  1.4738], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.8096], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.5680, -3.2257, -2.8550, -3.6776, -1.4642, -3.3573, -3.4952, -1.4580,\n",
      "        -2.5905, -1.3358], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.458\n",
      "activated x value: tensor([-1.2318, -0.6790,  2.1879, -1.2448,  1.3562, -0.7635,  0.1286, -0.9052,\n",
      "         1.2675, -0.7300], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.9921], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.2238, -3.6711, -0.8041, -4.2369, -1.6358, -3.7555, -2.8634, -3.8972,\n",
      "        -1.7246, -3.7220], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.804\n",
      "activated x value: tensor([ 0.6266, -1.1863, -1.7086,  2.6102, -1.2819,  1.4208, -1.5731,  2.1208,\n",
      "        -0.8014,  0.6661], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.4442], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.8176, -4.6305, -5.1528, -0.8340, -4.7261, -2.0234, -5.0173, -1.3234,\n",
      "        -4.2456, -2.7781], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.023\n",
      "activated x value: tensor([-1.3449, -1.2057, -1.3266,  0.2879,  0.1767,  1.2081, -0.8928,  0.8658,\n",
      "         0.0682,  1.1375], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.6156], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.9605, -3.8213, -3.9422, -2.3277, -2.4389, -1.4075, -3.5084, -1.7498,\n",
      "        -2.5474, -1.4781], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -2.439\n",
      "activated x value: tensor([ 1.5180, -1.4158, -1.6796, -1.2791,  0.3132,  0.7238, -0.0130,  3.1425,\n",
      "        -0.6506,  0.3159], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5480], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0300, -4.9637, -5.2276, -4.8271, -3.2348, -2.8241, -3.5610, -0.4055,\n",
      "        -4.1986, -3.2321], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.405\n",
      "activated x value: tensor([ 2.0358e+00, -2.6560e+00,  9.9928e-01, -1.0311e+00,  8.7407e-01,\n",
      "        -3.2650e-01, -3.0168e-01,  1.9071e+00, -1.2378e+00,  2.3080e-04],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.1216], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0858, -5.7776, -2.1223, -4.1527, -2.2476, -3.4481, -3.4233, -1.2146,\n",
      "        -4.3594, -3.1214], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -3.121\n",
      "activated x value: tensor([ 0.8260, -2.0443, -0.9601,  0.9752, -1.2349,  1.6202,  0.2116, -2.0099,\n",
      "         2.7464, -1.2711], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.3333], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.5073, -5.3775, -4.2933, -2.3580, -4.5681, -1.7130, -3.1217, -5.3431,\n",
      "        -0.5869, -4.6043], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.713\n",
      "activated x value: tensor([-0.3152, -0.4476, -0.0748,  1.8742, -2.7113,  2.4519,  1.0808, -0.4986,\n",
      "        -1.1059, -0.7081], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.2135], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.5288, -3.6611, -3.2883, -1.3393, -5.9249, -0.7617, -2.1327, -3.7121,\n",
      "        -4.3194, -3.9216], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.762\n",
      "activated x value: tensor([-1.1501, -3.3560, -0.7695, -0.7542,  4.3842, -1.5931,  1.9279,  0.5285,\n",
      "        -0.4013,  0.5707], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5291], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.6792, -7.8850, -5.2986, -5.2833, -0.1449, -6.1221, -2.6012, -4.0005,\n",
      "        -4.9304, -3.9583], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.145\n",
      "activated x value: tensor([ 0.9669, -2.7479, -0.7771,  0.8707, -1.9171,  4.2197, -1.1227, -0.6845,\n",
      "         1.8834,  0.4457], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4148], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.4480, -7.1627, -5.1919, -3.5441, -6.3319, -0.1952, -5.5375, -5.0993,\n",
      "        -2.5314, -3.9691], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.195\n",
      "activated x value: tensor([-1.4221, -2.3285,  0.6902,  0.0985,  1.8346,  0.5660,  1.2465, -1.1008,\n",
      "         0.1556,  0.1644], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.8689], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.2910, -5.1974, -2.1787, -2.7704, -1.0343, -2.3029, -1.6224, -3.9697,\n",
      "        -2.7133, -2.7045], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.303\n",
      "activated x value: tensor([-1.1981, -0.3678, -0.2078,  0.5849,  0.1088,  0.0689, -0.9980, -0.3346,\n",
      "         0.6789,  1.6985], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.6609], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.8590, -3.0287, -2.8687, -2.0760, -2.5521, -2.5920, -3.6589, -2.9956,\n",
      "        -1.9820, -0.9624], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -2.996\n",
      "activated x value: tensor([ 5.3152, -4.2377,  1.1017,  1.2202, -1.3939,  1.1466,  0.7989, -2.2007,\n",
      "        -0.0634, -0.8585], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3795], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-0.0643, -9.6171, -4.2778, -4.1593, -6.7733, -4.2329, -4.5806, -7.5802,\n",
      "        -5.4429, -6.2380], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.064\n",
      "activated x value: tensor([-0.2095, -3.7530, -1.0089,  0.1720,  0.6449, -0.2605, -2.1760,  3.8300,\n",
      "        -0.3689,  2.4459], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1506], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.3601, -7.9036, -5.1595, -3.9786, -3.5057, -4.4111, -6.3266, -0.3206,\n",
      "        -4.5195, -1.7047], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.321\n",
      "activated x value: tensor([-1.8189, -1.8338, -0.7135, -0.9484,  3.9986, -0.4297, -0.4187, -0.9176,\n",
      "         0.4484,  2.2998], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2336], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.0525, -6.0674, -4.9471, -5.1820, -0.2350, -4.6634, -4.6524, -5.1512,\n",
      "        -3.7852, -1.9338], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.235\n",
      "activated x value: tensor([-2.6591, -0.7395,  0.3410,  0.9099, -0.2582,  2.2064, -1.2684,  0.3161,\n",
      "         0.5067,  0.4461], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.9532], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.6123, -3.6927, -2.6122, -2.0434, -3.2114, -0.7469, -4.2216, -2.6371,\n",
      "        -2.4465, -2.5072], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.447\n",
      "activated x value: tensor([ 0.5490, -3.3112, -0.0085, -0.3936,  3.1110, -3.9350,  0.4290, -0.3176,\n",
      "         0.6598,  2.3495], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7032], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.1541, -7.0143, -3.7116, -4.0967, -0.5922, -7.6382, -3.2741, -4.0208,\n",
      "        -3.0434, -1.3537], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.592\n",
      "activated x value: tensor([-4.1904,  3.1684, -0.0278,  1.1192, -1.8041, -0.9749,  1.1512, -0.3420,\n",
      "         1.6957, -0.2043], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6506], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8410, -0.4823, -3.6784, -2.5314, -5.4547, -4.6255, -2.4994, -3.9926,\n",
      "        -1.9549, -3.8549], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.482\n",
      "activated x value: tensor([ 1.6233, -2.8139,  2.6207, -2.2117,  0.7250,  0.0870,  3.1334, -1.4474,\n",
      "        -0.8208, -0.7586], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8337], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.2104, -6.6476, -1.2130, -6.0455, -3.1088, -3.7468, -0.7004, -5.2812,\n",
      "        -4.6546, -4.5923], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.700\n",
      "activated x value: tensor([ 1.0244, -1.8105,  0.4219,  1.5239, -2.3241,  0.4963,  0.3420, -0.2633,\n",
      "         1.3107, -0.2877], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.8587], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8343, -4.6693, -2.4369, -1.3348, -5.1828, -2.3624, -2.5167, -3.1220,\n",
      "        -1.5480, -3.1464], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -1.834\n",
      "activated x value: tensor([ 7.7531, -3.9702,  0.2554,  0.4220, -3.9428,  3.0741, -0.5059,  0.5792,\n",
      "        -0.6958, -1.3680], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7649], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0118, -11.7351,  -7.5095,  -7.3429, -11.7077,  -4.6908,  -8.2709,\n",
      "         -7.1857,  -8.4607,  -9.1329], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-3.3582, -0.1573, -1.8359, -0.4647,  0.6100,  0.7831, -1.5903,  1.7921,\n",
      "        -0.3615,  4.1090], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2972], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.6555, -4.4545, -6.1332, -4.7619, -3.6872, -3.5142, -5.8876, -2.5051,\n",
      "        -4.6588, -0.1882], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.188\n",
      "activated x value: tensor([-4.5495,  0.2009,  0.1936, -0.6585,  0.7569, -0.6690,  3.6784, -1.9012,\n",
      "         2.4359,  0.0869], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0580], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6075, -3.8571, -3.8644, -4.7165, -3.3011, -4.7270, -0.3796, -5.9592,\n",
      "        -1.6221, -3.9711], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.380\n",
      "activated x value: tensor([-0.7037, -3.2649,  0.8947,  0.1362,  1.0836,  2.6736, -1.1924, -3.0901,\n",
      "         3.3032, -0.5108], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9064], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.6102, -7.1713, -3.0118, -3.7703, -2.8228, -1.2328, -5.0988, -6.9965,\n",
      "        -0.6032, -4.4172], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-3.6318,  0.5549,  1.9545,  1.6289, -1.8300,  0.0208,  0.2832, -0.3476,\n",
      "         1.2663,  0.5226], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.1080], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.7398, -2.5531, -1.1535, -1.4791, -4.9380, -3.0872, -2.8248, -3.4556,\n",
      "        -1.8417, -2.5854], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.154\n",
      "activated x value: tensor([-3.6783, -3.0408,  0.5963,  0.4377,  2.8254, -0.1299,  0.2645, -0.6018,\n",
      "         0.7382,  3.4564], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0401], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7183, -7.0809, -3.4438, -3.6024, -1.2147, -4.1700, -3.7756, -4.6418,\n",
      "        -3.3019, -0.5836], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.584\n",
      "activated x value: tensor([-1.8838, -1.1031, -0.3680, -0.1955, -0.6102, -0.5471, -2.6733,  4.5985,\n",
      "         0.9286,  1.9285], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7179], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6017, -5.8210, -5.0859, -4.9134, -5.3281, -5.2651, -7.3912, -0.1194,\n",
      "        -3.7894, -2.7895], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.119\n",
      "activated x value: tensor([ 5.2205, -5.9462,  1.6010,  0.7575, -1.0434,  0.9987,  0.4502, -1.5128,\n",
      "         0.8753, -1.5383], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2962], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0758, -11.2425,  -3.6953,  -4.5388,  -6.3396,  -4.2975,  -4.8461,\n",
      "         -6.8091,  -4.4209,  -6.8346], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.076\n",
      "activated x value: tensor([-2.4048, -2.6711, -0.0430,  0.2666,  3.5335, -0.2020,  0.0059,  0.4296,\n",
      "        -0.1623,  1.9335], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8668], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.2716, -6.5379, -3.9098, -3.6002, -0.3333, -4.0688, -3.8609, -3.4372,\n",
      "        -4.0291, -1.9333], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.333\n",
      "activated x value: tensor([-2.5584, -2.7804, -0.5519,  0.8477,  5.4556, -1.2381, -2.7451,  1.8225,\n",
      "         0.6315,  2.0125], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5334], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0918, -8.3139, -6.0854, -4.6858, -0.0779, -6.7715, -8.2786, -3.7109,\n",
      "        -4.9020, -3.5210], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.078\n",
      "activated x value: tensor([-0.3674, -2.9365, -0.3507, -0.8371,  1.1445,  2.8620, -2.1805,  0.0715,\n",
      "         0.7760,  2.6938], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7054], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.0728, -6.6420, -4.0562, -4.5425, -2.5609, -0.8434, -5.8860, -3.6339,\n",
      "        -2.9295, -1.0116], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.843\n",
      "activated x value: tensor([-0.7784, -2.1823, -1.0516,  3.3702, -1.9536,  3.3340,  0.4726,  0.0500,\n",
      "        -0.2985, -1.5604], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1240], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.9023, -6.3063, -5.1755, -0.7538, -6.0776, -0.7900, -3.6514, -4.0740,\n",
      "        -4.4225, -5.6843], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.790\n",
      "activated x value: tensor([-3.8842,  4.2921, -0.4645,  1.1826, -1.9459,  0.9361,  0.2931, -0.4637,\n",
      "         0.4173, -0.8332], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4266], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.3108, -0.1345, -4.8910, -3.2440, -6.3724, -3.4905, -4.1334, -4.8902,\n",
      "        -4.0093, -5.2598], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.135\n",
      "activated x value: tensor([-2.5184, -0.6667,  0.9189, -0.4325,  3.3844, -0.7583,  2.1138, -1.2928,\n",
      "         0.5394, -1.0658], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7917], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.3101, -4.4584, -2.8728, -4.2242, -0.4073, -4.5501, -1.6779, -5.0845,\n",
      "        -3.2523, -4.8575], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -1.678\n",
      "activated x value: tensor([-2.8612, -4.1620, -2.2706, -1.1462,  6.4464, -0.0821, -0.7597,  0.1632,\n",
      "        -0.1266,  4.1235], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5455], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4068, -10.7076,  -8.8161,  -7.6917,  -0.0992,  -6.6277,  -7.3052,\n",
      "         -6.3824,  -6.6721,  -2.4221], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.099\n",
      "activated x value: tensor([ 8.5832, -7.2400, -1.3676, -1.1653, -1.9021,  3.6122,  0.0464, -1.6662,\n",
      "         1.5125, -0.2661], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5914], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.2617e-03, -1.5831e+01, -9.9590e+00, -9.7567e+00, -1.0493e+01,\n",
      "        -4.9792e+00, -8.5450e+00, -1.0258e+01, -7.0789e+00, -8.8575e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-2.9499,  3.3295, -0.8922,  0.6834, -1.3433,  0.1407,  0.2465, -0.3178,\n",
      "         1.2647, -0.6388], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6338], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.5837, -0.3043, -4.5260, -2.9504, -4.9770, -3.4931, -3.3873, -3.9516,\n",
      "        -2.3691, -4.2726], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.304\n",
      "activated x value: tensor([-1.4802, -2.1836, -2.1876,  0.3083,  0.6739, -0.5757, -2.6482,  5.5507,\n",
      "        -0.8034,  3.1572], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6552], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.1355, -7.8389, -7.8429, -5.3470, -4.9813, -6.2310, -8.3034, -0.1045,\n",
      "        -6.4586, -2.4981], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.105\n",
      "activated x value: tensor([-1.0780, -0.4802,  2.4098,  9.2814, -3.0096,  0.7771, -3.4673, -2.5228,\n",
      "         0.4490, -2.5389], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2829], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0361e+01, -9.7631e+00, -6.8732e+00, -1.4954e-03, -1.2293e+01,\n",
      "        -8.5059e+00, -1.2750e+01, -1.1806e+01, -8.8340e+00, -1.1822e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-1.6975,  1.0308,  2.3075, -1.9310,  3.7928, -5.7579,  1.3271,  0.0892,\n",
      "         0.9576,  0.1302], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1923], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.8898, -3.1615, -1.8848, -6.1233, -0.3995, -9.9502, -2.8652, -4.1031,\n",
      "        -3.2347, -4.0621], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -2.865\n",
      "activated x value: tensor([ 8.9325, -5.5922, -0.0480,  1.5218, -3.4162,  3.7056,  1.4217, -4.0674,\n",
      "         1.2683, -2.5095], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9396], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.1096e-03, -1.4532e+01, -8.9876e+00, -7.4177e+00, -1.2356e+01,\n",
      "        -5.2340e+00, -7.5179e+00, -1.3007e+01, -7.6713e+00, -1.1449e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-3.2550, -0.2839, -1.8716,  0.0987, -0.7215, -1.2512, -4.0643,  7.2306,\n",
      "         0.6583,  3.2974], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2534], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5084,  -7.5373,  -9.1250,  -7.1547,  -7.9749,  -8.5046, -11.3177,\n",
      "         -0.0228,  -6.5951,  -3.9560], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-3.5886, -0.7456,  0.6900, -0.4993,  1.5840, -1.2483,  1.5323, -0.4937,\n",
      "         1.4238,  0.2304], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.9400], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.5285, -3.6856, -2.2500, -3.4392, -1.3559, -4.1883, -1.4077, -3.4337,\n",
      "        -1.5162, -2.7096], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.356\n",
      "activated x value: tensor([ 0.6727,  1.2075,  0.2677, -0.0996, -2.1526,  0.5132,  2.6628, -1.1294,\n",
      "         1.0496, -1.6837], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.2960], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.6233, -2.0885, -3.0283, -3.3957, -5.4486, -2.7828, -0.6333, -4.4255,\n",
      "        -2.2464, -4.9797], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.633\n",
      "activated x value: tensor([-0.1567,  1.3161,  4.8651,  3.2321, -3.5427, -0.5129, -2.1886, -2.2943,\n",
      "         3.2592, -3.8105], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2284], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.3851, -3.9124, -0.3633, -1.9963, -8.7712, -5.7414, -7.4170, -7.5227,\n",
      "        -1.9692, -9.0390], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.363\n",
      "activated x value: tensor([ 0.6257, -1.7677, -0.2507,  5.5108, -0.8782,  3.0567, -2.6225, -2.3446,\n",
      "         0.9448, -3.2945], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6154], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.9897, -7.3831, -5.8661, -0.1046, -6.4935, -2.5587, -8.2379, -7.9600,\n",
      "        -4.6706, -8.9098], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.105\n",
      "activated x value: tensor([ 7.6630, -5.6898,  0.7626,  0.6133, -5.4004,  4.0977, -4.9205,  0.4266,\n",
      "         2.1608,  0.4374], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6980], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0351, -13.3878,  -6.9354,  -7.0847, -13.0984,  -3.6004, -12.6186,\n",
      "         -7.2714,  -5.5373,  -7.2606], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.035\n",
      "activated x value: tensor([ 2.3898, -4.1593,  0.5703, -1.8329,  0.8130,  3.0243, -1.2636, -4.2451,\n",
      "         2.3317,  1.5820], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9347], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5449, -8.0940, -3.3644, -5.7676, -3.1217, -0.9104, -5.1983, -8.1798,\n",
      "        -1.6030, -2.3527], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -5.198\n",
      "activated x value: tensor([-3.4568,  2.4731, -0.3384,  2.6996, -2.1392, -0.3908, -0.5313,  1.4384,\n",
      "         0.4248,  0.4475], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5881], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.0449, -1.1150, -3.9265, -0.8886, -5.7274, -3.9789, -4.1195, -2.1497,\n",
      "        -3.1634, -3.1406], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -1.115\n",
      "activated x value: tensor([-1.8435, -2.1992,  0.6726, -0.8874,  0.6539,  1.5944,  4.4045, -3.3850,\n",
      "         1.5865, -0.2471], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5748], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4183, -6.7740, -3.9022, -5.4622, -3.9209, -2.9805, -0.1703, -7.9598,\n",
      "        -2.9883, -4.8219], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.170\n",
      "activated x value: tensor([ 0.1682, -3.5030, -0.8985, -0.6259, -1.2735,  2.3933, -0.3015, -2.4854,\n",
      "         4.2239,  2.2626], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5230], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.3548, -8.0260, -5.4215, -5.1489, -5.7965, -2.1297, -4.8245, -7.0084,\n",
      "        -0.2992, -2.2604], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.299\n",
      "activated x value: tensor([ 0.4653, -2.0590,  1.1750,  0.6601, -3.1199,  3.1468,  2.7819, -3.0374,\n",
      "         1.5800, -1.6000], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9407], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.4753, -5.9997, -2.7656, -3.2806, -7.0606, -0.7939, -1.1588, -6.9781,\n",
      "        -2.3606, -5.5407], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.794\n",
      "activated x value: tensor([-3.4233, -1.9626,  5.2883, -0.1343,  0.7106, -2.6852,  1.7411,  0.6675,\n",
      "        -0.4040,  0.2678], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3509], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.7742, -7.3135, -0.0625, -5.4852, -4.6402, -8.0361, -3.6097, -4.6834,\n",
      "        -5.7549, -5.0831], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.063\n",
      "activated x value: tensor([ 9.7002, -7.0130,  1.9513, -0.5627, -5.1223,  1.8933, -1.9598, -1.4681,\n",
      "         3.8668, -0.7898], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7040], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.8452e-03, -1.6717e+01, -7.7527e+00, -1.0267e+01, -1.4826e+01,\n",
      "        -7.8108e+00, -1.1664e+01, -1.1172e+01, -5.8372e+00, -1.0494e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: -0.004\n",
      "activated x value: tensor([-3.1176,  1.0610,  0.1643,  0.6653, -2.4182, -0.3246, -0.8557,  3.0544,\n",
      "         0.5237,  1.8803], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6041], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.7217, -2.5431, -3.4398, -2.9387, -6.0222, -3.9286, -4.4598, -0.5496,\n",
      "        -3.0803, -1.7237], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.550\n",
      "activated x value: tensor([-1.6904, -2.9236,  2.3197,  0.3620, -0.6230, -2.6813, -0.3875,  2.4277,\n",
      "        -0.5913,  2.9270], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7771], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.4675, -6.7007, -1.4574, -3.4151, -4.4001, -6.4584, -4.1646, -1.3494,\n",
      "        -4.3684, -0.8501], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.850\n",
      "activated x value: tensor([-1.6651, -3.9108, -1.6552, -1.9057,  0.2487,  2.7345, -1.1682,  1.7296,\n",
      "         4.1422,  0.3943], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4729], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.1380, -8.3837, -6.1281, -6.3786, -4.2242, -1.7383, -5.6411, -2.7432,\n",
      "        -0.3307, -4.0786], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.331\n",
      "activated x value: tensor([ 0.1753, -5.0777,  0.7178, -4.3431,  2.1122, -1.4663,  0.4511,  1.1103,\n",
      "         0.3467,  5.3190], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4025], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.2272, -10.4802,  -4.6847,  -9.7456,  -3.2903,  -6.8688,  -4.9514,\n",
      "         -4.2922,  -5.0558,  -0.0835], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.083\n",
      "activated x value: tensor([-2.4275, -2.3945,  4.3681,  0.2355, -1.6641, -1.4028,  1.4327,  0.9026,\n",
      "         0.4357, -0.4674], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4954], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9229, -6.8899, -0.1273, -4.2598, -6.1594, -5.8981, -3.0626, -3.5927,\n",
      "        -4.0596, -4.9628], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.127\n",
      "activated x value: tensor([-5.1076,  5.3592, -0.8801,  2.4925, -2.7699, -1.4473, -1.4495,  1.9801,\n",
      "         0.9476,  1.6898], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4842], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5917,  -0.1249,  -6.3643,  -2.9917,  -8.2541,  -6.9314,  -6.9337,\n",
      "         -3.5041,  -4.5366,  -3.7944], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.125\n",
      "activated x value: tensor([-2.4395, -0.5712, -0.8473, -0.1612,  2.5230,  1.1027, -0.7769,  0.0274,\n",
      "         0.2813,  1.2808], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.1706], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.6101, -3.7418, -4.0179, -3.3318, -0.6476, -2.0679, -3.9475, -3.1432,\n",
      "        -2.8892, -1.8898], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.648\n",
      "activated x value: tensor([10.1275, -5.7054, -1.2852,  1.0998, -5.1436,  4.4558, -3.9609,  0.9076,\n",
      "         3.1708, -1.8413], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1321], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.6215e-03, -1.5838e+01, -1.1417e+01, -9.0323e+00, -1.5276e+01,\n",
      "        -5.6763e+00, -1.4093e+01, -9.2245e+00, -6.9613e+00, -1.1973e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-2.5000,  0.4463,  1.6536,  5.2640, -1.2000, -0.2460, -4.0068, -0.6842,\n",
      "         1.1557,  0.1724], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3284], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8283, -4.8820, -3.6747, -0.0643, -6.5283, -5.5743, -9.3351, -6.0126,\n",
      "        -4.1727, -5.1560], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.064\n",
      "activated x value: tensor([-0.8053, -3.3652,  1.6283, -1.6067,  1.1633,  2.5305,  0.9842, -3.8229,\n",
      "         1.9404,  1.5123], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5761], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.3814, -6.9413, -1.9478, -5.1828, -2.4127, -1.0456, -2.5919, -7.3989,\n",
      "        -1.6357, -2.0638], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.046\n",
      "activated x value: tensor([ 1.5427, -3.1318, -3.5838, -3.1888,  0.1688,  5.4350, -1.4653,  3.4383,\n",
      "         0.0895,  1.0757], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6009], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.0582, -8.7327, -9.1846, -8.7897, -5.4321, -0.1659, -7.0661, -2.1626,\n",
      "        -5.5114, -4.5252], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.166\n",
      "activated x value: tensor([-4.6784, -2.1502, -0.5706,  1.5971,  3.2045,  0.8471,  0.0572, -2.6554,\n",
      "         0.9621,  4.1429], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5985], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2769, -6.7487, -5.1692, -3.0014, -1.3940, -3.7514, -4.5413, -7.2539,\n",
      "        -3.6364, -0.4556], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.456\n",
      "activated x value: tensor([ 7.5215, -5.3395,  3.0250, -0.3242, -4.8409,  1.3566,  2.1434, -1.7815,\n",
      "        -0.4346, -0.2715], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5405], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0189, -12.8800,  -4.5155,  -7.8646, -12.3813,  -6.1838,  -5.3971,\n",
      "         -9.3219,  -7.9750,  -7.8119], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-2.6340, -2.6939, -0.3918,  0.3208, -0.9901, -1.4131, -4.6769,  7.4233,\n",
      "         1.2019,  3.5744], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4480], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0820, -10.1419,  -7.8398,  -7.1272,  -8.4381,  -8.8611, -12.1249,\n",
      "         -0.0247,  -6.2461,  -3.8736], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([-0.7525, -1.4713,  0.0201,  4.2903,  0.6079,  1.4048, -2.9477, -2.6913,\n",
      "         2.2970, -1.3510], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5102], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2627, -5.9816, -4.4901, -0.2200, -3.9024, -3.1054, -7.4579, -7.2016,\n",
      "        -2.2132, -5.8612], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.220\n",
      "activated x value: tensor([ 1.0626, -3.6708,  0.2266,  0.9949,  0.0621,  2.9722,  2.3696, -5.5198,\n",
      "         1.7091, -1.1150], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7848], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.7222, -7.4556, -3.5582, -2.7899, -3.7226, -0.8126, -1.4152, -9.3046,\n",
      "        -2.0757, -4.8998], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -1.415\n",
      "activated x value: tensor([-5.1931, -2.1808,  1.4911,  5.4879, -0.3149, -0.4942, -4.5407,  0.1123,\n",
      "         2.5276,  2.8294], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6284], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8216,  -7.8092,  -4.1374,  -0.1406,  -5.9433,  -6.1227, -10.1692,\n",
      "         -5.5161,  -3.1008,  -2.7991], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.141\n",
      "activated x value: tensor([-0.7973, -1.2296, -2.8503, -0.2476,  0.0728,  1.1646, -1.5407,  4.3041,\n",
      "        -0.0879,  1.2620], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4371], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2343, -5.6667, -7.2874, -4.6846, -4.3643, -3.2725, -5.9778, -0.1330,\n",
      "        -4.5249, -3.1750], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.133\n",
      "activated x value: tensor([-1.6601, -0.2749,  0.7229, -1.6900, -0.5666,  1.8122, -0.7418, -1.4273,\n",
      "         2.7915,  1.2076], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.4096], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.0697, -3.6845, -2.6867, -5.0996, -3.9762, -1.5974, -4.1514, -4.8369,\n",
      "        -0.6181, -2.2021], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.618\n",
      "activated x value: tensor([ 1.0371, -4.6966, -1.5705,  0.0421,  1.5148,  5.1747, -0.8414, -2.8051,\n",
      "         1.3506,  1.7751], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2762], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.2391, -9.9728, -6.8467, -5.2341, -3.7614, -0.1015, -6.1175, -8.0813,\n",
      "        -3.9256, -3.5011], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.102\n",
      "activated x value: tensor([ 9.3850, -9.1771, -0.0360,  0.4325, -3.7010,  6.2531, -1.1990, -2.4563,\n",
      "         3.0578, -1.5048], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4297], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0447, -18.6068,  -9.4657,  -8.9972, -13.1307,  -3.1766, -10.6287,\n",
      "        -11.8860,  -6.3719, -10.9345], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-0.3800, -0.2555,  0.5243,  4.5912, -1.3134,  1.1539, -3.6603, -0.1964,\n",
      "         1.6337, -2.3766], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7119], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.0919, -4.9675, -4.1876, -0.1207, -6.0254, -3.5580, -8.3722, -4.9083,\n",
      "        -3.0783, -7.0885], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.121\n",
      "activated x value: tensor([-5.3825, -1.1789,  2.6040,  1.4476,  0.8742, -0.4450,  1.4984, -2.4353,\n",
      "         4.5595, -1.3227], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7998], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1822,  -5.9787,  -2.1958,  -3.3522,  -3.9256,  -5.2447,  -3.3014,\n",
      "         -7.2351,  -0.2403,  -6.1225], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.240\n",
      "activated x value: tensor([-2.3123, -6.0042, -3.9621, -1.1822,  1.4285, -0.2488, -2.8868,  8.3825,\n",
      "         3.1089,  1.8873], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3904], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0703e+01, -1.4395e+01, -1.2352e+01, -9.5726e+00, -6.9619e+00,\n",
      "        -8.6392e+00, -1.1277e+01, -7.8478e-03, -5.2815e+00, -6.5030e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-1.5527, -4.1312,  0.3665,  0.1226,  1.1376,  1.6552, -1.2396, -3.1071,\n",
      "         6.7181, -1.9564], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7321], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.2848, -10.8633,  -6.3655,  -6.6095,  -5.5945,  -5.0769,  -7.9717,\n",
      "         -9.8392,  -0.0140,  -8.6884], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([ 1.1526, -1.8061, -0.4708, -1.1621, -1.4486,  1.4588,  0.2085, -0.6911,\n",
      "         0.3960,  1.7667], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.8834], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7307, -4.6895, -3.3541, -4.0455, -4.3319, -1.4246, -2.6748, -3.5744,\n",
      "        -2.4874, -1.1166], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.425\n",
      "activated x value: tensor([-2.6236, -1.2604,  1.5335,  0.7185, -1.9835, -0.8391, -3.0240,  3.7371,\n",
      "         1.6249,  1.8499], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1121], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.7357, -5.3725, -2.5786, -3.3936, -6.0956, -4.9511, -7.1361, -0.3750,\n",
      "        -2.4872, -2.2622], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.375\n",
      "activated x value: tensor([-1.1182, -3.1796, -0.5765,  1.0603, -1.0741, -0.8897, -1.8919,  4.2147,\n",
      "        -0.0222,  3.6233], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7080], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.8263, -7.8877, -5.2845, -3.6477, -5.7821, -5.5978, -6.5999, -0.4933,\n",
      "        -4.7303, -1.0848], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.493\n",
      "activated x value: tensor([ 1.1038, -4.8634,  0.7621, -1.0195, -0.4435,  3.8504,  2.0210, -6.3401,\n",
      "         4.8701, -0.2223], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2568], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.1530, -10.1202,  -4.4947,  -6.2763,  -5.7003,  -1.4064,  -3.2358,\n",
      "        -11.5969,  -0.3867,  -5.4791], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -3.236\n",
      "activated x value: tensor([-1.3507,  1.1433, -0.0118,  1.8081, -3.8939,  3.4788, -2.6073, -2.4319,\n",
      "         4.2101, -1.7525], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7061], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.0568, -3.5628, -4.7179, -2.8980, -8.6000, -1.2273, -7.3134, -7.1380,\n",
      "        -0.4960, -6.4586], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.496\n",
      "activated x value: tensor([-1.8634,  4.0823,  0.2831,  0.3073, -1.8290,  0.0162,  0.3227, -0.3491,\n",
      "         0.2714, -0.5481], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2088], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.0722, -0.1265, -3.9257, -3.9015, -6.0378, -4.1925, -3.8861, -4.5579,\n",
      "        -3.9374, -4.7568], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.127\n",
      "activated x value: tensor([-2.9733,  5.3812,  0.4982,  1.2073, -2.5764, -1.1176,  0.0762,  0.1279,\n",
      "         0.2910, -0.1351], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4256], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.3990, -0.0444, -4.9274, -4.2183, -8.0020, -6.5432, -5.3494, -5.2977,\n",
      "        -5.1346, -5.5607], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.044\n",
      "activated x value: tensor([ 6.9906, -4.5784, -0.0209, -0.0279, -2.8999,  3.0776,  1.3578, -2.6450,\n",
      "         0.4325, -1.1275], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0175], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0268, -11.5958,  -7.0384,  -7.0454,  -9.9173,  -3.9399,  -5.6596,\n",
      "         -9.6624,  -6.5850,  -8.1450], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.027\n",
      "activated x value: tensor([-3.4024,  2.9526,  7.3028,  5.2295, -5.4617, -2.8515,  0.7116, -2.2316,\n",
      "         0.7483, -2.3459], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4353], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8377,  -4.4827,  -0.1325,  -2.2058, -12.8970, -10.2868,  -6.7237,\n",
      "         -9.6669,  -6.6870,  -9.7812], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.132\n",
      "activated x value: tensor([-1.8493, -0.2992, -0.6457,  3.1861, -0.2152,  1.6448, -2.7239,  1.1334,\n",
      "         0.5833, -0.4991], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6156], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.4650, -3.9148, -4.2613, -0.4295, -3.8308, -1.9708, -6.3395, -2.4823,\n",
      "        -3.0323, -4.1148], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.429\n",
      "activated x value: tensor([-0.8670,  1.0004,  2.7571, -1.6616,  0.3105, -2.8775,  2.5290, -1.2069,\n",
      "         0.5591, -1.0819], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5676], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.4347, -2.5672, -0.8105, -5.2293, -3.2571, -6.4451, -1.0386, -4.7746,\n",
      "        -3.0086, -4.6496], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.811\n",
      "activated x value: tensor([-5.5558,  3.7854,  4.3046,  1.3399, -5.1067, -0.3467,  0.6396, -0.3971,\n",
      "         1.0060, -0.2301], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8577], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.4135,  -1.0723,  -0.5531,  -3.5178,  -9.9643,  -5.2044,  -4.2181,\n",
      "         -5.2547,  -3.8516,  -5.0877], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.553\n",
      "activated x value: tensor([-4.2611,  6.2576,  1.1660,  0.4554, -2.8274, -1.7599, -0.2536,  0.5282,\n",
      "         2.0156, -0.5048], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2870], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5481,  -0.0295,  -5.1210,  -5.8316,  -9.1145,  -8.0470,  -6.5406,\n",
      "         -5.7589,  -4.2714,  -6.7918], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.029\n",
      "activated x value: tensor([-3.8423,  1.2297, -4.5846,  1.9396,  0.7726,  2.2541, -2.3990,  2.9375,\n",
      "        -0.1194,  1.7685], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8672], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7095, -2.6376, -8.4518, -1.9276, -3.0946, -1.6131, -6.2662, -0.9297,\n",
      "        -3.9867, -2.0988], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -2.099\n",
      "activated x value: tensor([-2.3907,  0.3177,  0.7060, -1.8235,  3.1453, -2.9967, -1.4971,  1.1518,\n",
      "         1.6722,  1.4773], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6894], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.0801, -3.3717, -2.9834, -5.5129, -0.5442, -6.6861, -5.1865, -2.5376,\n",
      "        -2.0172, -2.2121], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.544\n",
      "activated x value: tensor([ 9.1703, -5.2204, -0.9401,  0.5386, -4.7874,  5.1957, -5.0899, -1.4625,\n",
      "         2.4217,  0.1641], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1904], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0201, -14.4108, -10.1305,  -8.6518, -13.9778,  -3.9947, -14.2803,\n",
      "        -10.6529,  -6.7687,  -9.0263], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-2.4619,  3.2382,  2.2236, -0.0678, -2.4997, -0.4826,  3.1746, -2.2373,\n",
      "         1.3115, -1.2621], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1662], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6280, -0.9279, -1.9426, -4.2340, -6.6658, -4.6487, -0.9915, -6.4035,\n",
      "        -2.8547, -5.4283], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.992\n",
      "activated x value: tensor([-1.3659, -2.6852, -1.3223,  0.9768, -0.5435, -1.0046, -2.9393,  7.6263,\n",
      "        -0.2475,  1.8067], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6317], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9976e+00, -1.0317e+01, -8.9540e+00, -6.6549e+00, -8.1752e+00,\n",
      "        -8.6363e+00, -1.0571e+01, -5.4040e-03, -7.8793e+00, -5.8250e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-1.8527, -1.9604,  1.3864,  9.2707, -3.2912,  1.3910, -1.3373, -1.7252,\n",
      "        -0.2413, -1.8761], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2717], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1124e+01, -1.1232e+01, -7.8853e+00, -9.1553e-04, -1.2563e+01,\n",
      "        -7.8807e+00, -1.0609e+01, -1.0997e+01, -9.5129e+00, -1.1148e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-0.8884, -4.3327,  1.0467, -3.5773,  6.4052, -3.1683,  0.2169,  1.2539,\n",
      "         0.6529,  1.6102], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4297], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([ -7.3181, -10.7623,  -5.3830, -10.0070,  -0.0245,  -9.5980,  -6.2127,\n",
      "         -5.1758,  -5.7768,  -4.8195], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([-3.0898, -3.1032,  1.0243, -0.2628,  0.8986,  1.8422,  6.4016, -4.4995,\n",
      "         1.4249, -0.1947], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4300], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.5198,  -9.5332,  -5.4058,  -6.6928,  -5.5315,  -4.5878,  -0.0285,\n",
      "        -10.9296,  -5.0052,  -6.6248], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([ 1.1694, -3.6045, -3.9224,  3.8512, -1.0578,  4.5471,  0.8514, -0.9404,\n",
      "        -0.2341, -0.4744], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0051], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.8357, -8.6096, -8.9275, -1.1538, -6.0628, -0.4580, -4.1537, -5.9455,\n",
      "        -5.2392, -5.4794], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.154\n",
      "activated x value: tensor([ 6.1861, -3.9828,  2.0752,  2.0795, -4.9607,  2.0502, -2.9516,  0.5262,\n",
      "         1.5669, -2.1176], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2468], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0607, -10.2295,  -4.1716,  -4.1672, -11.2075,  -4.1966,  -9.1984,\n",
      "         -5.7206,  -4.6799,  -8.3644], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -4.197\n",
      "activated x value: tensor([-0.7168, -0.7235,  0.1846,  6.5208, -1.0648,  2.6084, -1.6543, -2.1318,\n",
      "         0.4755, -3.3459], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5470], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.2638, -7.2705, -6.3624, -0.0262, -7.6118, -3.9386, -8.2013, -8.6788,\n",
      "        -6.0715, -9.8930], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.026\n",
      "activated x value: tensor([-1.0545,  0.3578,  1.1204,  2.6115, -2.7228,  0.7914, -0.1156, -1.7326,\n",
      "         3.1761, -1.2789], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8294], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.8839, -3.4717, -2.7091, -1.2179, -6.5522, -3.0380, -3.9451, -5.5620,\n",
      "        -0.6533, -5.1084], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.653\n",
      "activated x value: tensor([-3.2108,  6.1019,  1.1003,  0.4481, -3.2080, -0.2668,  0.9343, -1.7253,\n",
      "         1.7411, -1.3591], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1330], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.3439, -0.0311, -5.0327, -5.6850, -9.3410, -6.3999, -5.1987, -7.8584,\n",
      "        -4.3919, -7.4921], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.031\n",
      "activated x value: tensor([ 0.4311, -3.9746,  4.3985, -4.3219,  2.2766, -1.4633,  7.8142, -3.6813,\n",
      "        -0.3552, -0.8688], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8514], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4203, -11.8260,  -3.4529, -12.1734,  -5.5749,  -9.3147,  -0.0373,\n",
      "        -11.5327,  -8.2067,  -8.7202], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.037\n",
      "activated x value: tensor([ 2.3612, -5.4027,  2.2585,  0.8409,  0.4881,  2.3372,  2.3429, -6.9043,\n",
      "         1.8767, -0.9362], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9476], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.5864,  -9.3503,  -1.6892,  -3.1068,  -3.4595,  -1.6104,  -1.6047,\n",
      "        -10.8520,  -2.0710,  -4.8838], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.071\n",
      "activated x value: tensor([ 0.3259, -2.8039, -0.1304, -1.4522,  0.6320,  1.9130, -1.9243,  0.9664,\n",
      "         1.1542,  0.7292], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.9566], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.6307, -5.7604, -3.0870, -4.4088, -2.3246, -1.0436, -4.8808, -1.9901,\n",
      "        -1.8024, -2.2274], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.044\n",
      "activated x value: tensor([-3.0334, -4.4098, -1.5351,  0.0177,  4.4852,  1.0973, -1.2326,  0.5035,\n",
      "         0.5994,  2.9495], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7523], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7857, -9.1621, -6.2874, -4.7346, -0.2671, -3.6551, -5.9849, -4.2488,\n",
      "        -4.1529, -1.8028], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.267\n",
      "activated x value: tensor([-3.2664, -1.1845,  6.9978, -0.7978, -0.4344, -1.8580,  2.0641, -1.9317,\n",
      "         2.0659, -2.1945], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0137], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2801,  -8.1983,  -0.0160,  -7.8116,  -7.4481,  -8.8718,  -4.9496,\n",
      "         -8.9455,  -4.9478,  -9.2083], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-4.0505,  5.6989,  0.2980,  1.8297, -2.4932, -0.6767, -0.3005,  0.1388,\n",
      "         0.1118,  0.2129], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7397], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.7902, -0.0408, -5.4417, -3.9100, -8.2330, -6.4164, -6.0402, -5.6009,\n",
      "        -5.6279, -5.5268], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.041\n",
      "activated x value: tensor([-0.7048,  0.0559,  0.1427,  1.3495, -2.7333,  2.7777, -1.1297, -2.3878,\n",
      "         4.5834, -0.0810], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8031], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.5079, -4.7472, -4.6604, -3.4536, -7.5364, -2.0254, -5.9328, -7.1909,\n",
      "        -0.2197, -4.8841], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.220\n",
      "activated x value: tensor([ 6.8024, -4.1938,  0.2754,  0.8356, -3.5053,  3.6502, -2.6363, -1.6411,\n",
      "         3.5258, -1.4956], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8841], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0817, -11.0779,  -6.6087,  -6.0485, -10.3895,  -3.2339,  -9.5205,\n",
      "         -8.5253,  -3.3584,  -8.3797], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.082\n",
      "activated x value: tensor([-2.0180, -2.5206,  1.0957, -0.2185, -1.0689, -2.2949, -2.1106,  5.7056,\n",
      "         0.9241,  1.8380], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7492], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7672, -8.2697, -4.6535, -5.9677, -6.8181, -8.0441, -7.8597, -0.0435,\n",
      "        -4.8251, -3.9112], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.044\n",
      "activated x value: tensor([-4.1324, -1.1572, -3.0480,  0.6267,  0.7708, -0.9862, -3.2792,  2.2574,\n",
      "         2.8001,  5.9979], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0717], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2041,  -7.2289,  -9.1197,  -5.4450,  -5.3009,  -7.0579,  -9.3509,\n",
      "         -3.8142,  -3.2715,  -0.0738], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.074\n",
      "activated x value: tensor([ 0.0600, -1.3887,  3.7494, -2.3497, -1.0106, -2.4672,  7.0702, -4.0105,\n",
      "         2.6795, -1.8828], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1192], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0593,  -8.5079,  -3.3699,  -9.4690,  -8.1298,  -9.5864,  -0.0490,\n",
      "        -11.1297,  -4.4397,  -9.0020], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.049\n",
      "activated x value: tensor([-5.3503, -0.2500,  0.2510,  3.8835, -0.7491, -2.5617, -4.3478,  1.7573,\n",
      "         2.7925,  4.1009], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8959], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2462,  -5.1459,  -4.6449,  -1.0124,  -5.6450,  -7.4576,  -9.2436,\n",
      "         -3.1386,  -2.1034,  -0.7950], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -3.139\n",
      "activated x value: tensor([-2.7438, -2.7706, -1.8367, -1.7167, -1.2983,  3.8725, -3.3437, -0.5503,\n",
      "         8.3445,  1.5379], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3573], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.1011, -11.1279, -10.1940, -10.0739,  -9.6555,  -4.4847, -11.7010,\n",
      "         -8.9076,  -0.0128,  -6.8194], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-5.5335,  1.9975, -3.2207, -0.4906, -1.5747,  1.4756, -2.1889,  1.6625,\n",
      "         2.8662,  4.6439], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9382], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.4717,  -2.9407,  -8.1588,  -5.4288,  -6.5128,  -3.4626,  -7.1270,\n",
      "         -3.2757,  -2.0720,  -0.2942], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.294\n",
      "activated x value: tensor([10.4511, -8.3943,  1.5827, -1.1244, -4.6999,  1.6652,  0.2714,  0.4812,\n",
      "         1.3850, -0.1256], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.4516], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2929e-04, -1.8846e+01, -8.8689e+00, -1.1576e+01, -1.5152e+01,\n",
      "        -8.7865e+00, -1.0180e+01, -9.9704e+00, -9.0666e+00, -1.0577e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 0.6486, -2.9817, -0.4132, -0.5743,  0.8036,  0.6582,  4.8556, -3.0165,\n",
      "         1.2688, -0.7198], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9410], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.2924, -7.9226, -5.3542, -5.5152, -4.1374, -4.2828, -0.0853, -7.9575,\n",
      "        -3.6722, -5.6607], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 2.6945, -4.2515, -2.5995,  3.3358, -3.1622,  6.5126, -3.0177, -1.4684,\n",
      "         2.2953, -1.5731], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5889], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.8944, -10.8404,  -9.1885,  -3.2531,  -9.7511,  -0.0764,  -9.6066,\n",
      "         -8.0573,  -4.2936,  -8.1620], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.076\n",
      "activated x value: tensor([-0.7958, -1.6120, -0.9454,  4.5398,  0.3184,  1.0720, -1.9891, -2.1510,\n",
      "         1.3950,  0.3037], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6507], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.4464, -6.2626, -5.5960, -0.1108, -4.3323, -3.5787, -6.6398, -6.8016,\n",
      "        -3.2557, -4.3469], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.111\n",
      "activated x value: tensor([-3.2326, -1.4319,  1.6456, -1.1188, -1.1703, -3.4006, -1.9421,  5.7692,\n",
      "         2.0302,  3.8275], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9405], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1731, -7.3724, -4.2950, -7.0593, -7.1108, -9.3411, -7.8826, -0.1713,\n",
      "        -3.9103, -2.1130], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.171\n",
      "activated x value: tensor([ 1.6025, -2.4534,  0.8687,  0.5390, -0.8284,  2.0946, -0.1648,  0.0139,\n",
      "         0.8493, -2.5189], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.0905], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4880, -5.5439, -2.2219, -2.5515, -3.9189, -0.9960, -3.2553, -3.0766,\n",
      "        -2.2413, -5.6094], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.996\n",
      "activated x value: tensor([ 1.5116, -4.9999,  0.1445, -3.0263,  1.1707, -1.1603,  3.6825,  0.0626,\n",
      "         0.7625,  2.0289], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0917], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.5801, -9.0916, -3.9472, -7.1181, -2.9210, -5.2520, -0.4092, -4.0291,\n",
      "        -3.3292, -2.0629], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.409\n",
      "activated x value: tensor([-3.3972, -4.6237, -0.0112, -1.5556,  3.7008, -2.0707, -1.1860,  1.8659,\n",
      "         0.5569,  6.2223], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3176], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7148, -10.9412,  -6.3288,  -7.8732,  -2.6167,  -8.3883,  -7.5036,\n",
      "         -4.4517,  -5.7607,  -0.0953], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.095\n",
      "activated x value: tensor([-3.3298,  7.3622,  2.9576,  0.7684, -4.1085, -2.8368, -0.8049, -0.4675,\n",
      "         2.6492, -0.6498], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3855], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7154,  -0.0234,  -4.4279,  -6.6171, -11.4941, -10.2223,  -8.1905,\n",
      "         -7.8531,  -4.7364,  -8.0353], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([ 1.3136, -4.3727,  0.6759,  0.4799, -3.3678, -2.6719, -4.1246, 10.4681,\n",
      "        -0.7470,  1.9746], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.4685], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1549e+00, -1.4841e+01, -9.7926e+00, -9.9886e+00, -1.3836e+01,\n",
      "        -1.3140e+01, -1.4593e+01, -4.2915e-04, -1.1216e+01, -8.4938e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 0.6040,  2.0463,  3.6141,  1.3657, -4.4316,  0.1916, -0.4999, -2.5528,\n",
      "         3.9325, -4.7085], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6401], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.0361, -2.5938, -1.0260, -3.2744, -9.0717, -4.4485, -5.1400, -7.1929,\n",
      "        -0.7076, -9.3485], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.026\n",
      "activated x value: tensor([-3.3016,  5.1853,  0.8312,  0.5780, -0.2236, -1.4742, -0.4237, -2.7313,\n",
      "         2.1568,  0.8305], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2752], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.5767, -0.0899, -4.4440, -4.6971, -5.4988, -6.7494, -5.6988, -8.0064,\n",
      "        -3.1183, -4.4447], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.090\n",
      "activated x value: tensor([-2.1315, -5.5317,  1.0076, -1.6802,  6.5737, -1.5685, -0.4299, -0.4694,\n",
      "         1.1782,  3.0189], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6124], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.7439, -12.1441,  -5.6048,  -8.2926,  -0.0387,  -8.1809,  -7.0423,\n",
      "         -7.0818,  -5.4342,  -3.5935], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.039\n",
      "activated x value: tensor([-3.8758, -2.3058, -1.8338,  0.1011,  5.4216, -1.8704, -0.5255, -0.0628,\n",
      "         0.9884,  3.8032], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6234], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4992, -7.9292, -7.4572, -5.5223, -0.2019, -7.4938, -6.1489, -5.6862,\n",
      "        -4.6350, -1.8202], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.202\n",
      "activated x value: tensor([  8.8391, -10.1509,   3.9992,   0.1151,  -1.7352,   1.3583,   3.3157,\n",
      "         -3.4298,   0.2410,  -1.7576], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8519], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2784e-02, -1.9003e+01, -4.8526e+00, -8.7368e+00, -1.0587e+01,\n",
      "        -7.4936e+00, -5.5362e+00, -1.2282e+01, -8.6109e+00, -1.0610e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-3.1133,  1.4453,  7.2407,  2.4098, -4.4368, -2.0041,  1.1787,  0.2103,\n",
      "        -0.3439, -2.9153], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2555], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3688,  -5.8102,  -0.0148,  -4.8457, -11.6923,  -9.2596,  -6.0768,\n",
      "         -7.0452,  -7.5994, -10.1708], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-1.8537, -2.3033,  2.4859, -3.7304,  2.9131, -1.0168,  7.8440, -2.7831,\n",
      "        -0.7437, -1.1456], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8564], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7101, -10.1597,  -5.3705, -11.5868,  -4.9433,  -8.8732,  -0.0124,\n",
      "        -10.6395,  -8.6002,  -9.0021], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([ 0.4346, -2.6289,  1.7568,  1.7872, -2.2757,  2.9422,  1.7130, -7.0920,\n",
      "         4.5635, -0.9599], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9000], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.4653,  -7.5289,  -3.1432,  -3.1128,  -7.1757,  -1.9578,  -3.1870,\n",
      "        -11.9919,  -0.3365,  -5.8599], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.337\n",
      "activated x value: tensor([ 1.9851, -4.3753,  0.9077,  0.7912, -2.0881,  0.1678, -2.8819, -3.7405,\n",
      "         5.5698,  2.5067], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6630], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.6779, -10.0383,  -4.7553,  -4.8718,  -7.7511,  -5.4951,  -8.5448,\n",
      "         -9.4035,  -0.0932,  -3.1563], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.093\n",
      "activated x value: tensor([-3.9716,  3.1435,  0.6390, -0.5570,  1.9104, -1.2218,  0.4046, -0.5581,\n",
      "         0.1481,  0.4569], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6252], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5968, -0.4817, -2.9861, -4.1822, -1.7148, -4.8470, -3.2206, -4.1833,\n",
      "        -3.4771, -3.1683], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.715\n",
      "activated x value: tensor([-0.9236, -3.8542,  2.3083, -2.1811,  1.7755,  0.3208,  8.8522, -5.5322,\n",
      "         0.4751, -0.8491], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8551], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.7786e+00, -1.2709e+01, -6.5467e+00, -1.1036e+01, -7.0796e+00,\n",
      "        -8.5342e+00, -2.8439e-03, -1.4387e+01, -8.3800e+00, -9.7042e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-0.8760, -3.3897,  3.4520,  0.0687,  0.4026,  2.4342,  4.4036, -5.7363,\n",
      "         1.3642, -1.9046], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8813], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.7573,  -8.2709,  -1.4293,  -4.8126,  -4.4787,  -2.4470,  -0.4777,\n",
      "        -10.6175,  -3.5171,  -6.7859], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.447\n",
      "activated x value: tensor([-1.6148, -3.5463,  1.9792,  1.7165, -0.0561,  0.1377, -0.2543, -4.0373,\n",
      "         3.7264,  1.7867], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1497], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.7645, -7.6960, -2.1705, -2.4332, -4.2057, -4.0120, -4.4040, -8.1870,\n",
      "        -0.4233, -2.3630], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.423\n",
      "activated x value: tensor([-1.4127,  1.7535, -0.8229, -2.5068,  5.2628, -3.7881,  3.8212, -5.5313,\n",
      "         0.4915,  3.2782], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6109], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0236,  -3.8574,  -6.4338,  -8.1177,  -0.3482,  -9.3991,  -1.7898,\n",
      "        -11.1423,  -5.1194,  -2.3327], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -6.434\n",
      "activated x value: tensor([ 0.3154, -4.9293,  1.2009, -3.5244,  6.1134, -0.6111,  2.4765, -2.8036,\n",
      "         0.6010,  1.0311], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1607], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8453, -11.0900,  -4.9598,  -9.6851,  -0.0472,  -6.7718,  -3.6842,\n",
      "         -8.9643,  -5.5597,  -5.1296], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.047\n",
      "activated x value: tensor([-3.9318, -0.5697, 11.3945,  0.8340, -1.5968, -5.0696,  3.0382, -4.4918,\n",
      "         1.3661, -0.8301], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.3948], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5327e+01, -1.1965e+01, -3.1853e-04, -1.0561e+01, -1.2992e+01,\n",
      "        -1.6464e+01, -8.3566e+00, -1.5887e+01, -1.0029e+01, -1.2225e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-0.6327, -2.2229,  0.9832,  2.2102, -5.4235,  3.9544,  5.8952, -3.7326,\n",
      "         0.9167, -1.5534], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0653], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6980,  -8.2882,  -5.0821,  -3.8551, -11.4888,  -2.1108,  -0.1700,\n",
      "         -9.7979,  -5.1486,  -7.6187], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -3.855\n",
      "activated x value: tensor([-3.4233, -4.3523, -4.0143,  1.6929,  2.1496,  1.3067, -3.5556,  2.0792,\n",
      "         1.4333,  5.8764], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9571], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.3805, -10.3095,  -9.9715,  -4.2642,  -3.8075,  -4.6504,  -9.5127,\n",
      "         -3.8779,  -4.5238,  -0.0808], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([-1.9076,  0.1387, -0.1117,  1.7166, -3.0443,  1.5918, -3.8831,  0.2598,\n",
      "         3.8603,  1.5949], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1963], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.1039, -4.0576, -4.3081, -2.4797, -7.2406, -2.6045, -8.0794, -3.9365,\n",
      "        -0.3360, -2.6015], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.336\n",
      "activated x value: tensor([-3.5008,  4.4808,  0.7781,  2.2353, -3.3019, -1.7191, -2.0490,  1.9050,\n",
      "         0.3742,  1.9935], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7512], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.2520, -0.2704, -3.9731, -2.5159, -8.0531, -6.4703, -6.8002, -2.8462,\n",
      "        -4.3770, -2.7577], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.270\n",
      "activated x value: tensor([-2.8574, -3.2953, -0.7460, -1.2488,  5.5764, -0.3215, -1.0780,  1.5567,\n",
      "         0.1097,  2.4171], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6458], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.5032, -8.9412, -6.3919, -6.8947, -0.0694, -5.9673, -6.7238, -4.0891,\n",
      "        -5.5362, -3.2287], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.069\n",
      "activated x value: tensor([-0.9422, -6.2188,  1.2418, -3.1512,  7.7166, -3.7859,  1.3548, -1.7814,\n",
      "         2.8885,  3.6396], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7447], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.6869, -13.9634,  -6.5029, -10.8958,  -0.0281, -11.5306,  -6.3898,\n",
      "         -9.5261,  -4.8561,  -4.1051], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-1.4274,  3.0132, -2.6416,  1.1100, -1.2180,  1.3900, -1.3229,  0.1694,\n",
      "         1.4744,  0.0454], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5518], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.9791, -0.5385, -6.1934, -2.4418, -4.7698, -2.1618, -4.8747, -3.3824,\n",
      "        -2.0774, -3.5064], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.539\n",
      "activated x value: tensor([-2.5191, -1.4453, -0.1217,  0.1912,  1.9258, -2.5629, -0.8973,  1.6301,\n",
      "         0.8844,  3.5533], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9553], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4744, -5.4006, -4.0770, -3.7642, -2.0295, -6.5182, -4.8526, -2.3253,\n",
      "        -3.0709, -0.4020], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.402\n",
      "activated x value: tensor([10.0183, -6.3527, -0.3913,  1.0171, -4.7822,  2.9494, -0.4751, -1.6279,\n",
      "         2.3106, -1.4582], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0198], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5001e-03, -1.6373e+01, -1.0411e+01, -9.0028e+00, -1.4802e+01,\n",
      "        -7.0704e+00, -1.0495e+01, -1.1648e+01, -7.7093e+00, -1.1478e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 4.9357, -9.0061,  0.4232, -1.2752,  0.4474,  3.1252,  3.1570, -1.6052,\n",
      "         0.0817, -0.0323], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2526], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.3169, -14.2586,  -4.8294,  -6.5277,  -4.8052,  -2.1274,  -2.0956,\n",
      "         -6.8578,  -5.1708,  -5.2849], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.317\n",
      "activated x value: tensor([ 2.9589, -4.6845,  3.0537, -2.6179, -0.9847, -1.3116,  5.1368, -1.2458,\n",
      "         0.6546, -0.7072], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3663], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -2.4074, -10.0509,  -2.3126,  -7.9843,  -6.3510,  -6.6780,  -0.2295,\n",
      "         -6.6122,  -4.7118,  -6.0735], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.230\n",
      "activated x value: tensor([ 2.6666,  2.0830,  7.3527,  4.5331, -6.1306, -0.6927,  2.6451, -6.8251,\n",
      "         0.7577, -5.1627], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4341], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.7675,  -5.3510,  -0.0813,  -2.9010, -13.5647,  -8.1268,  -4.7890,\n",
      "        -14.2592,  -6.6764, -12.5968], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([ 1.6516, -2.1782, -2.3443,  0.4817,  0.8610,  4.3995,  1.9235, -3.2747,\n",
      "        -0.6557, -0.0628], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5968], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.9452, -6.7749, -6.9411, -4.1151, -3.7358, -0.1972, -2.6733, -7.8715,\n",
      "        -5.2525, -4.6595], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.197\n",
      "activated x value: tensor([ 1.1185, -6.3594, -0.4435,  2.3122, -2.2204, -1.9292, -5.1587, 10.5632,\n",
      "        -1.4127,  3.5159], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([10.5644], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4460e+00, -1.6924e+01, -1.1008e+01, -8.2522e+00, -1.2785e+01,\n",
      "        -1.2494e+01, -1.5723e+01, -1.2388e-03, -1.1977e+01, -7.0486e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-3.7922, -5.2346, -0.4349, -4.1316,  6.9439, -2.9773, -0.3334,  4.5368,\n",
      "         1.2231,  2.9561], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0512], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8434, -12.2857,  -7.4861, -11.1827,  -0.1073, -10.0284,  -7.3846,\n",
      "         -2.5144,  -5.8281,  -4.0951], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.107\n",
      "activated x value: tensor([-4.0146,  6.0664,  1.2777,  0.3966, -1.6925, -1.3675,  0.3221, -0.6518,\n",
      "         1.0762, -0.7865], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0911], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1058,  -0.0248,  -4.8134,  -5.6946,  -7.7836,  -7.4587,  -5.7690,\n",
      "         -6.7430,  -5.0150,  -6.8777], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([-4.6161,  0.5066,  6.6193,  1.7953, -4.2076, -2.5940,  0.5831,  1.4001,\n",
      "        -0.0511, -0.5571], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6393], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2554,  -6.1327,  -0.0200,  -4.8440, -10.8469,  -9.2334,  -6.0563,\n",
      "         -5.2392,  -6.6904,  -7.1964], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-2.2764, -4.9979, -0.7118, -0.4097,  3.2132, -1.6884,  0.1598, -0.2370,\n",
      "         2.3620,  4.9306], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1781], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4545, -10.1759,  -5.8898,  -5.5877,  -1.9649,  -6.8665,  -5.0182,\n",
      "         -5.4151,  -2.8161,  -0.2475], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.247\n",
      "activated x value: tensor([-0.0930, -4.4731,  1.5350, -3.5927,  1.5051, -2.4292,  6.9327, -0.2992,\n",
      "         0.2125,  0.4783], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9460], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0390, -11.4191,  -5.4111, -10.5387,  -5.4409,  -9.3752,  -0.0133,\n",
      "         -7.2453,  -6.7335,  -6.4677], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([ 1.3411, -2.9146,  3.4065,  7.0256, -4.5337,  1.1120, -1.4999, -4.3717,\n",
      "         2.7926, -2.2640], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0722], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.7312,  -9.9868,  -3.6657,  -0.0467, -11.6059,  -5.9602,  -8.5722,\n",
      "        -11.4440,  -4.2797,  -9.3362], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.047\n",
      "activated x value: tensor([-1.7501, -3.0777, -3.2245,  1.1453, -0.2498,  3.2870, -0.8577,  0.3996,\n",
      "         1.1334,  3.6031], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2860], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.0362, -7.3637, -7.5106, -3.1407, -4.5359, -0.9990, -5.1437, -3.8864,\n",
      "        -3.1526, -0.6830], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.683\n",
      "activated x value: tensor([-0.4318, -5.2435,  0.8728, -2.7171,  9.5526, -6.4766,  3.1185, -1.3947,\n",
      "         1.1745,  2.9111], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5560], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.9878e+00, -1.4799e+01, -8.6832e+00, -1.2273e+01, -3.3741e-03,\n",
      "        -1.6033e+01, -6.4374e+00, -1.0951e+01, -8.3815e+00, -6.6448e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 5.5076, -4.9627,  1.3825, -0.0963, -1.2579,  0.8424, -0.3770, -1.1505,\n",
      "         1.4873, -0.8553], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5603], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0528, -10.5230,  -4.1779,  -5.6566,  -6.8182,  -4.7179,  -5.9373,\n",
      "         -6.7108,  -4.0730,  -6.4156], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.053\n",
      "activated x value: tensor([ 0.8435, -4.4614, -0.4998,  3.6154, -1.6825,  6.5246, -1.3585, -5.9060,\n",
      "         3.0984, -0.0264], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6139], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.7704, -11.0753,  -7.1137,  -2.9985,  -8.2964,  -0.0893,  -7.9724,\n",
      "        -12.5199,  -3.5155,  -6.6404], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.089\n",
      "activated x value: tensor([-3.4409,  6.0128, -0.0575,  1.4588, -3.6351, -0.3411, -0.3486, -0.4187,\n",
      "         0.5488,  0.7775], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0400], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4810, -0.0272, -6.0975, -4.5812, -9.6751, -6.3811, -6.3886, -6.4588,\n",
      "        -5.4913, -5.2625], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.027\n",
      "activated x value: tensor([-1.1114, -4.0235, -0.6520, -0.2055,  5.6671,  0.0932, -0.4309, -1.1030,\n",
      "        -0.2941,  1.5992], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6992], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8107, -9.7228, -6.3513, -5.9047, -0.0322, -5.6061, -6.1301, -6.8022,\n",
      "        -5.9933, -4.1000], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.032\n",
      "activated x value: tensor([-3.9295,  2.8271,  0.2699,  1.5633, -2.2855, -1.4167, -2.9760,  4.9479,\n",
      "        -0.7175,  1.6925], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1369], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.0664, -2.3098, -4.8670, -3.5737, -7.4224, -6.5537, -8.1129, -0.1891,\n",
      "        -5.8544, -3.4444], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.189\n",
      "activated x value: tensor([-0.7654, -0.0853,  2.3790,  6.2004, -4.4504,  3.1375, -1.6501, -4.4345,\n",
      "         2.3027, -1.9979], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2888], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0542,  -6.3741,  -3.9098,  -0.0884, -10.7392,  -3.1513,  -7.9389,\n",
      "        -10.7233,  -3.9861,  -8.2867], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.088\n",
      "activated x value: tensor([ 3.8435, -6.2370, -5.2740,  1.1512, -0.9913,  8.0791, -2.2821, -3.3406,\n",
      "         3.2442,  1.8854], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1043], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.2608, -14.3413, -13.3783,  -6.9531,  -9.0957,  -0.0253, -10.3864,\n",
      "        -11.4450,  -4.8602,  -6.2189], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([-0.4641, -0.7091, -0.0946,  7.0074, -2.0619,  2.9760, -4.2548, -1.7252,\n",
      "         0.2821, -0.8357], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0286], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4927,  -7.7378,  -7.1232,  -0.0212,  -9.0905,  -4.0526, -11.2834,\n",
      "         -8.7538,  -6.7465,  -7.8643], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.021\n",
      "activated x value: tensor([ 6.7570, -6.3516, -4.9628,  2.7201,  0.0325,  7.3141, -2.0634, -2.6224,\n",
      "         1.2369, -0.7223], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7756], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.0185, -14.1272, -12.7384,  -5.0555,  -7.7431,  -0.4615,  -9.8389,\n",
      "        -10.3980,  -6.5387,  -8.4979], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -1.019\n",
      "activated x value: tensor([ 3.0224, -5.9814,  2.3267,  3.9733, -0.0184,  1.6937, -0.0358, -2.8822,\n",
      "        -0.9394, -1.5176], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5218], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.4993, -10.5032,  -2.1951,  -0.5485,  -4.5402,  -2.8281,  -4.5576,\n",
      "         -7.4039,  -5.4612,  -6.0394], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -2.195\n",
      "activated x value: tensor([ 5.8029, -7.7634, -0.1849,  1.4217, -2.0434,  1.8641,  1.1970, -1.0358,\n",
      "         0.7751,  0.2873], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8579], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0550, -13.6213,  -6.0427,  -4.4362,  -7.9013,  -3.9938,  -4.6609,\n",
      "         -6.8937,  -5.0828,  -5.5706], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.055\n",
      "activated x value: tensor([ 1.0912, -3.6057, -2.2772,  0.0489,  2.1654,  5.3666,  0.2656, -2.5556,\n",
      "         0.8270, -1.5309], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4419], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.3507, -9.0476, -7.7191, -5.3930, -3.2765, -0.0754, -5.1764, -7.9976,\n",
      "        -4.6149, -6.9729], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.075\n",
      "activated x value: tensor([-2.7302, -4.6812, -1.2413,  1.3360,  1.8646,  0.1536, -2.4144,  1.2955,\n",
      "         1.4212,  4.6669], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8366], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5668, -9.5178, -6.0779, -3.5005, -2.9720, -4.6829, -7.2510, -3.5411,\n",
      "        -3.4154, -0.1697], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.170\n",
      "activated x value: tensor([ 3.0949, -5.2294,  2.3758,  1.4630, -2.1700,  3.0996,  1.0782, -8.2511,\n",
      "         4.6363, -0.0540], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1151], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([ -2.0202, -10.3445,  -2.7394,  -3.6522,  -7.2851,  -2.0155,  -4.0369,\n",
      "        -13.3662,  -0.4788,  -5.1691], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.479\n",
      "activated x value: tensor([-4.5685,  4.7294, -1.3475,  2.8529, -2.9779,  0.6152, -0.9281, -0.7316,\n",
      "         0.8779,  0.9797], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9322], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.5007, -0.2028, -6.2797, -2.0793, -7.9100, -4.3170, -5.8603, -5.6637,\n",
      "        -4.0543, -3.9524], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.203\n",
      "activated x value: tensor([-1.8115, -5.0540, -0.9049,  1.0789,  1.1175,  2.2074, -0.6330, -0.0489,\n",
      "         3.8460, -0.6443], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1663], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9778, -9.2203, -5.0712, -3.0875, -3.0488, -1.9589, -4.7993, -4.2152,\n",
      "        -0.3203, -4.8107], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.320\n",
      "activated x value: tensor([-1.0701, -3.8619, -4.2498,  1.0573,  3.8860, -0.0130, -2.3177,  2.1601,\n",
      "        -0.6878,  4.4481], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9951], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.0652, -8.8570, -9.2449, -3.9379, -1.1092, -5.0081, -7.3128, -2.8350,\n",
      "        -5.6830, -0.5471], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.547\n",
      "activated x value: tensor([-0.7507, -2.4962, -0.5994, -0.3035,  1.2523, -1.4606,  0.3965, -0.5484,\n",
      "         0.7303,  4.0200], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1807], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.9314, -6.6769, -4.7801, -4.4842, -2.9284, -5.6413, -3.7843, -4.7291,\n",
      "        -3.4504, -0.1607], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.161\n",
      "activated x value: tensor([ 0.1042, -7.8969,  0.6579, -3.5260,  5.9108, -3.2626, -0.4189,  1.3014,\n",
      "         1.3599,  4.6604], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1862], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.0820, -14.0832,  -5.5283,  -9.7123,  -0.2755,  -9.4488,  -6.6052,\n",
      "         -4.8848,  -4.8263,  -1.5258], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.275\n",
      "activated x value: tensor([-2.2336,  0.0420, -0.6209,  0.7759, -0.7325,  1.8467,  0.4526, -2.5504,\n",
      "         2.1741,  0.6008], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.1332], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.3668, -3.0912, -3.7542, -2.3573, -3.8657, -1.2865, -2.6806, -5.6836,\n",
      "        -0.9591, -2.5324], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.959\n",
      "activated x value: tensor([-0.0452, -4.1999,  7.0381, -0.4972,  2.2232, -4.9399,  1.6490, -1.5795,\n",
      "        -1.5941,  1.0672], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0550], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1001, -11.2549,  -0.0168,  -7.5521,  -4.8317, -11.9948,  -5.4059,\n",
      "         -8.6344,  -8.6491,  -5.9878], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([ 0.4949, -2.5110,  0.5588,  3.1679,  3.1596,  0.8524, -0.7650, -5.3976,\n",
      "         1.1095, -0.5825], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0464], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.5515, -6.5575, -3.4877, -0.8786, -0.8869, -3.1940, -4.8114, -9.4441,\n",
      "        -2.9370, -4.6290], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.879\n",
      "activated x value: tensor([-3.0905, -3.1227,  2.7218, -0.6211,  1.8622,  0.3082,  4.0922, -2.5220,\n",
      "        -0.0925,  0.4030], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4543], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5447, -7.5770, -1.7325, -5.0754, -2.5921, -4.1460, -0.3621, -6.9763,\n",
      "        -4.5468, -4.0513], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.362\n",
      "activated x value: tensor([-2.2073, -2.4445, -2.1551,  6.0580, -0.3766,  3.9258, -4.4244, -1.8831,\n",
      "         2.9631,  1.3421], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2197], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.4270,  -8.6642,  -8.3748,  -0.1617,  -6.5963,  -2.2939, -10.6442,\n",
      "         -8.1028,  -3.2566,  -4.8777], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.162\n",
      "activated x value: tensor([-3.8240, -0.5367,  7.5362,  3.0767, -2.2334, -2.3605,  2.5072, -1.6144,\n",
      "        -1.5102,  0.3119], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5555], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3796,  -8.0923,  -0.0193,  -4.4788,  -9.7890,  -9.9161,  -5.0483,\n",
      "         -9.1699,  -9.0658,  -7.2437], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-4.1157,  2.6520, 10.2178,  0.7559, -3.4618, -3.6032,  4.0849, -9.4238,\n",
      "         3.6552, -0.7502], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2220], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4338e+01, -7.5699e+00, -4.1895e-03, -9.4661e+00, -1.3684e+01,\n",
      "        -1.3825e+01, -6.1370e+00, -1.9646e+01, -6.5668e+00, -1.0972e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-1.1821, -3.8831, -1.3397,  1.1008,  1.2581,  4.0049,  0.2052, -3.3997,\n",
      "         1.4507,  0.8897], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2477], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.4298, -8.1308, -5.5874, -3.1469, -2.9896, -0.2428, -4.0425, -7.6473,\n",
      "        -2.7970, -3.3580], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.243\n",
      "activated x value: tensor([ 2.7966, -6.6469, -1.7216,  1.3454,  2.3300,  4.2490, -2.7901, -3.6401,\n",
      "         2.0276,  1.4388], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7240], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.9275, -11.3710,  -6.4456,  -3.3786,  -2.3941,  -0.4750,  -7.5141,\n",
      "         -8.3641,  -2.6964,  -3.2852], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.475\n",
      "activated x value: tensor([-1.1798, -1.8093, 10.1250, -0.0300, -0.9510, -3.4620,  1.3417, -4.1053,\n",
      "         0.7598, -1.3295], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1253], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1305e+01, -1.1935e+01, -3.2425e-04, -1.0155e+01, -1.1076e+01,\n",
      "        -1.3587e+01, -8.7836e+00, -1.4231e+01, -9.3655e+00, -1.1455e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-5.4137,  0.5280,  0.4593,  1.5124,  1.7793,  2.3845, -2.3984, -1.7819,\n",
      "         3.5049, -1.3401], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0673], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4810, -3.5393, -3.6080, -2.5549, -2.2880, -1.6828, -6.4657, -5.8492,\n",
      "        -0.5624, -5.4074], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.562\n",
      "activated x value: tensor([ 8.8109, -9.4989,  2.4841,  1.4919, -2.7547,  2.6023, -3.4560, -2.5451,\n",
      "         2.4569,  0.9750], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8175], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6013e-03, -1.8316e+01, -6.3334e+00, -7.3256e+00, -1.1572e+01,\n",
      "        -6.2152e+00, -1.2273e+01, -1.1363e+01, -6.3606e+00, -7.8425e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-5.8681,  0.0807,  1.2688,  1.5252, -1.8324, -2.5758, -3.5544,  4.4163,\n",
      "         1.4131,  5.8547], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0987], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.9668,  -6.0180,  -4.8299,  -4.5735,  -7.9311,  -8.6745,  -9.6530,\n",
      "         -1.6824,  -4.6856,  -0.2440], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.682\n",
      "activated x value: tensor([-1.7865,  5.8046, -0.1045,  4.8959, -5.0525,  3.8463, -5.2065, -0.6551,\n",
      "         0.9387, -2.7760], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2473], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.0338,  -0.4427,  -6.3518,  -1.3514, -11.2998,  -2.4010, -11.4538,\n",
      "         -6.9024,  -5.3087,  -9.0233], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.401\n",
      "activated x value: tensor([ 8.0378, -5.3499,  3.7942,  0.4937, -5.6839, -1.0890,  4.0911, -1.4012,\n",
      "         0.2656, -1.2267], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0721], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0343, -13.4220,  -4.2779,  -7.5784, -13.7560,  -9.1611,  -3.9810,\n",
      "         -9.4733,  -7.8065,  -9.2988], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.034\n",
      "activated x value: tensor([-0.2368, -1.1375, -0.1816,  0.9868, -0.7661,  2.6486, -0.5227, -1.9822,\n",
      "         1.4973, -0.0393], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.2342], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.4711, -4.3718, -3.4158, -2.2474, -4.0003, -0.5856, -3.7569, -5.2165,\n",
      "        -1.7370, -3.2735], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.586\n",
      "activated x value: tensor([ 0.4769, -4.3994, -3.7720,  2.4193, -1.7902,  7.5908, -2.7289, -2.3073,\n",
      "         3.9762,  0.3174], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([7.6245], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1476, -12.0239, -11.3965,  -5.2052,  -9.4147,  -0.0337, -10.3534,\n",
      "         -9.9318,  -3.6483,  -7.3071], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.034\n",
      "activated x value: tensor([-2.7064, -1.1267, -0.7421,  0.0241,  0.5346,  3.5766,  0.4302, -2.1332,\n",
      "         1.9765, -0.0661], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8951], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6014, -5.0218, -4.6372, -3.8709, -3.3605, -0.3185, -3.4649, -6.0282,\n",
      "        -1.9185, -3.9612], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -3.871\n",
      "activated x value: tensor([-4.2631,  0.8283, -1.9674,  0.2083, -1.5623,  2.2537, -3.5091,  3.7320,\n",
      "         4.3043, -1.0052], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8643], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1275, -4.0360, -6.8317, -4.6560, -6.4266, -2.6107, -8.3734, -1.1323,\n",
      "        -0.5600, -5.8695], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.560\n",
      "activated x value: tensor([-4.2772,  6.2701,  1.3847,  1.1640, -2.2448, -1.5362, -0.6447,  0.1752,\n",
      "         1.1515, -0.9284], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2940], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5712,  -0.0239,  -4.9093,  -5.1300,  -8.5388,  -7.8302,  -6.9387,\n",
      "         -6.1188,  -5.1425,  -7.2224], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-0.6350,  1.6111,  0.8232,  2.5403, -3.0317,  0.6117,  0.0688, -2.1546,\n",
      "         1.9675, -0.8477], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.4391], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.0741, -1.8280, -2.6160, -0.8988, -6.4709, -2.8275, -3.3703, -5.5937,\n",
      "        -1.4716, -4.2868], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.899\n",
      "activated x value: tensor([-2.4393, -6.7385,  2.1675, -0.1286,  2.1978,  2.3057, -3.0151, -2.4205,\n",
      "         6.7975, -0.2116], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8301], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2694, -13.5686,  -4.6625,  -6.9587,  -4.6323,  -4.5244,  -9.8452,\n",
      "         -9.2506,  -0.0326,  -7.0417], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([-3.4223, -4.0370,  0.9860, -2.4243,  2.9542,  0.9638,  5.9516, -1.9174,\n",
      "        -0.1707,  0.1098], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0188], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4411, -10.0558,  -5.0328,  -8.4431,  -3.0646,  -5.0550,  -0.0672,\n",
      "         -7.9362,  -6.1895,  -5.9090], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.067\n",
      "activated x value: tensor([ 2.4243, -2.1700,  1.9984,  0.5685, -1.0091, -1.1614,  2.5844, -1.8941,\n",
      "         2.4220, -3.3162], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8274], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4030, -5.9973, -1.8289, -3.2588, -4.8365, -4.9888, -1.2429, -5.7214,\n",
      "        -1.4053, -7.1436], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -1.243\n",
      "activated x value: tensor([-4.4454, -0.4314,  3.6398,  8.9167, -1.7603,  0.4383, -4.4805, -2.4262,\n",
      "         2.3169, -1.4297], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9236], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3369e+01, -9.3550e+00, -5.2838e+00, -6.8102e-03, -1.0684e+01,\n",
      "        -8.4852e+00, -1.3404e+01, -1.1350e+01, -6.6066e+00, -1.0353e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-3.4432,  3.6076,  1.2208,  3.6678, -3.3216, -0.1835, -1.5595,  0.3936,\n",
      "         2.7714, -2.3999], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5860], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0292, -0.9784, -3.3651, -0.9182, -7.9075, -4.7695, -6.1454, -4.1923,\n",
      "        -1.8145, -6.9859], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.815\n",
      "activated x value: tensor([ 1.0368, -4.9477,  8.3051,  4.4285, -3.8480, -2.7738,  1.0446, -0.9219,\n",
      "         0.0294, -2.3979], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3274], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.2905, -13.2751,  -0.0223,  -3.8989, -12.1753, -11.1011,  -7.2828,\n",
      "         -9.2492,  -8.2980, -10.7253], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.022\n",
      "activated x value: tensor([-3.1203,  4.0791,  0.6197,  0.9998, -1.7501, -1.0056, -1.0384,  1.2292,\n",
      "         0.2442,  0.2835], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2574], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.3777, -0.1783, -3.6377, -3.2576, -6.0075, -5.2630, -5.2958, -3.0282,\n",
      "        -4.0132, -3.9739], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.178\n",
      "activated x value: tensor([-0.1641, -2.9248, -2.7359,  8.6510, -4.2366,  2.9703, -4.3414,  1.2846,\n",
      "         0.8999,  0.2058], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6558], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8200e+00, -1.1581e+01, -1.1392e+01, -4.8513e-03, -1.2892e+01,\n",
      "        -5.6855e+00, -1.2997e+01, -7.3712e+00, -7.7559e+00, -8.4500e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([ 5.6217, -3.2813, -0.5101, -0.3168, -4.9016,  3.4245,  0.1830,  1.2185,\n",
      "         2.2220, -2.5507], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7756], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1539,  -9.0568,  -6.2857,  -6.0923, -10.6772,  -2.3510,  -5.5925,\n",
      "         -4.5570,  -3.5536,  -8.3263], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.351\n",
      "activated x value: tensor([-5.4839, -0.6872, -2.9501, -0.2934,  2.0951,  3.0126, -0.9829, -2.0795,\n",
      "         3.3016,  4.4956], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9908], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.4746,  -5.6780,  -7.9409,  -5.2842,  -2.8956,  -1.9782,  -5.9737,\n",
      "         -7.0703,  -1.6891,  -0.4952], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.495\n",
      "activated x value: tensor([-3.2180, -1.2881, -3.1930, -1.2108,  7.2227, -1.2151, -1.2916, -1.7697,\n",
      "         1.7950,  4.1799], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2744], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.4924,  -8.5625, -10.4674,  -8.4852,  -0.0518,  -8.4895,  -8.5660,\n",
      "         -9.0441,  -5.4794,  -3.0945], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.052\n",
      "activated x value: tensor([-0.4076, -4.4532, -2.2001, -4.8027,  3.8855, -0.2500, -0.6105,  0.8100,\n",
      "         1.8177,  7.0857], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1341], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5417, -11.5873,  -9.3341, -11.9368,  -3.2486,  -7.3841,  -7.7446,\n",
      "         -6.3241,  -5.3164,  -0.0484], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.048\n",
      "activated x value: tensor([ 0.7983, -5.0038,  3.4960, -1.9072,  0.2132, -1.3977,  7.9654, -6.7036,\n",
      "         2.5371,  0.2488], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9829], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1846, -12.9867,  -4.4869,  -9.8901,  -7.7697,  -9.3806,  -0.0175,\n",
      "        -14.6865,  -5.4458,  -7.7341], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([-4.7915,  6.5331,  0.8937,  1.4813, -4.5239,  0.7354,  0.6417, -2.4963,\n",
      "         3.4285, -1.4142], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5924], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3839,  -0.0593,  -5.6987,  -5.1111, -11.1163,  -5.8570,  -5.9507,\n",
      "         -9.0888,  -3.1639,  -8.0066], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.059\n",
      "activated x value: tensor([-2.2369, -5.4642,  1.8722, -1.8129,  3.4982,  2.4648,  1.5116, -1.2827,\n",
      "        -0.0709,  0.9748], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0941], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.3310, -9.5583, -2.2219, -5.9070, -0.5959, -1.6293, -2.5825, -5.3768,\n",
      "        -4.1650, -3.1193], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.596\n",
      "activated x value: tensor([-1.6273, -4.5594,  0.7225, -2.6693,  5.2791, -0.9867,  0.7949, -1.2696,\n",
      "         1.0277,  2.6870], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3885], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.0158, -9.9479, -4.6660, -8.0578, -0.1094, -6.3752, -4.5936, -6.6581,\n",
      "        -4.3608, -2.7015], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.109\n",
      "activated x value: tensor([-7.4082,  3.4142, -1.4935,  1.1828,  0.5776,  0.7425, -0.1293,  0.3157,\n",
      "         1.4841,  0.1778], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8203], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-11.2285,  -0.4061,  -5.3138,  -2.6375,  -3.2428,  -3.0778,  -3.9497,\n",
      "         -3.5046,  -2.3363,  -3.6425], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.406\n",
      "activated x value: tensor([ 0.5129, -6.3852,  0.2732, -3.8826,  4.1079, -0.5166,  0.5748,  0.2174,\n",
      "         2.0124,  2.4030], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4541], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.9412, -10.8393,  -4.1809,  -8.3367,  -0.3462,  -4.9707,  -3.8793,\n",
      "         -4.2367,  -2.4417,  -2.0511], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.346\n",
      "activated x value: tensor([-0.1398, -2.1010,  0.2052,  0.1309, -2.4606,  2.0665,  7.1110, -6.4496,\n",
      "         2.7116, -1.3011], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1325], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.2723,  -9.2335,  -6.9273,  -7.0016,  -9.5931,  -5.0659,  -0.0215,\n",
      "        -13.5821,  -4.4209,  -8.4336], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.022\n",
      "activated x value: tensor([ 1.1332, -2.8915,  1.1982, -3.5277,  1.1695, -1.6450,  6.4229, -2.8207,\n",
      "         0.0516,  1.5622], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4482], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.3150, -9.3397, -5.2500, -9.9759, -5.2787, -8.0932, -0.0253, -9.2689,\n",
      "        -6.3966, -4.8860], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([ 4.2173, -3.7958,  2.2695, -1.1735, -2.1217,  1.5085,  1.2078, -1.8746,\n",
      "         3.4010, -2.9629], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7539], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-0.5367, -8.5497, -2.4845, -5.9274, -6.8756, -3.2454, -3.5461, -6.6285,\n",
      "        -1.3529, -7.7168], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -3.546\n",
      "activated x value: tensor([-5.2186, -6.7301, -4.0694, -1.6270,  6.9195,  0.2223, -1.5572,  0.9227,\n",
      "         3.1710,  6.7698], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5553], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7739, -14.2854, -11.6248,  -9.1824,  -0.6359,  -7.3330,  -9.1125,\n",
      "         -6.6326,  -4.3843,  -0.7856], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.636\n",
      "activated x value: tensor([-4.0388,  2.1838,  6.4982,  1.2696, -4.9605, -0.7497,  1.1279, -1.4987,\n",
      "         3.5831, -3.8516], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5740], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6128,  -4.3902,  -0.0758,  -5.3044, -11.5345,  -7.3237,  -5.4461,\n",
      "         -8.0727,  -2.9909, -10.4256], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.076\n",
      "activated x value: tensor([-1.9000, -2.1660,  2.5650,  2.4446,  0.6494,  2.3773,  0.5311, -6.4047,\n",
      "         6.2164, -3.6356], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2917], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.1917,  -8.4577,  -3.7268,  -3.8472,  -5.6423,  -3.9144,  -5.7606,\n",
      "        -12.6964,  -0.0754,  -9.9273], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.075\n",
      "activated x value: tensor([-4.4256,  4.8897,  1.7861,  1.2109, -3.2613, -2.8211, -3.4111,  4.5298,\n",
      "        -0.4125,  1.8198], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4887], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.9143, -0.5990, -3.7026, -4.2778, -8.7500, -8.3098, -8.8998, -0.9589,\n",
      "        -5.9012, -3.6689], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.959\n",
      "activated x value: tensor([-0.2524, -4.2573, -5.1471,  3.2969, -2.2074,  5.5606, -6.2152,  2.6971,\n",
      "         1.8943,  5.9950], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5664], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.8188, -10.8237, -11.7135,  -3.2696,  -8.7738,  -1.0058, -12.7816,\n",
      "         -3.8693,  -4.6721,  -0.5714], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.006\n",
      "activated x value: tensor([-0.7055, -1.7163, 11.3899,  3.6763, -5.9897, -1.2712,  5.2977, -7.6673,\n",
      "         2.9593, -6.3405], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.3929], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2098e+01, -1.3109e+01, -2.9316e-03, -7.7166e+00, -1.7383e+01,\n",
      "        -1.2664e+01, -6.0952e+00, -1.9060e+01, -8.4336e+00, -1.7733e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-1.5570, -1.6090, -2.6026,  0.7274,  2.2087,  1.1666, -0.5035, -0.5502,\n",
      "        -0.6249,  4.9153], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0300], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.5870, -6.6390, -7.6327, -4.3026, -2.8213, -3.8635, -5.5335, -5.5803,\n",
      "        -5.6550, -0.1148], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.115\n",
      "activated x value: tensor([-5.2691, -1.1087, -0.5752,  0.3768,  0.7895,  1.3895, -1.8844,  0.5817,\n",
      "         1.8428,  4.5673], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7284], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.9975, -5.8371, -5.3036, -4.3516, -3.9389, -3.3389, -6.6128, -4.1467,\n",
      "        -2.8856, -0.1611], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.886\n",
      "activated x value: tensor([ 1.9807, -2.5369,  0.0927, -1.9596, -0.2345,  4.3525, -0.9194, -2.6608,\n",
      "         2.0294,  0.1830], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5676], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.5869, -7.1045, -4.4749, -6.5271, -4.8021, -0.2150, -5.4870, -7.2284,\n",
      "        -2.5382, -4.3846], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.215\n",
      "activated x value: tensor([ 0.4296, -3.5782, -0.3985,  4.0135, -0.7110,  3.8865,  1.4060, -4.4082,\n",
      "         2.5047, -3.5594], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8136], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.3839, -8.3917, -5.2121, -0.8001, -5.5245, -0.9270, -3.4075, -9.2217,\n",
      "        -2.3088, -8.3729], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.927\n",
      "activated x value: tensor([-5.0467, -1.8496,  3.9511,  5.4801, -2.0745,  0.7766, -3.3192, -3.1506,\n",
      "         6.8076, -1.3918], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0895], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.1362,  -8.9391,  -3.1384,  -1.6094,  -9.1640,  -6.3129, -10.4087,\n",
      "        -10.2401,  -0.2819,  -8.4813], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.282\n",
      "activated x value: tensor([-4.4418,  1.5622,  2.9625,  0.9156, -4.4784, -1.4405,  1.8260,  2.8755,\n",
      "         0.4995,  0.4443], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9894], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.4312, -2.4273, -1.0270, -3.0738, -8.4679, -5.4300, -2.1634, -1.1139,\n",
      "        -3.4900, -3.5451], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.027\n",
      "activated x value: tensor([-1.1390, -5.4573,  3.4417, -2.4823,  1.2416,  1.5271,  9.9378, -7.1792,\n",
      "         0.4647, -0.3339], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9399], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1079e+01, -1.5397e+01, -6.4982e+00, -1.2422e+01, -8.6983e+00,\n",
      "        -8.4128e+00, -2.0285e-03, -1.7119e+01, -9.4752e+00, -1.0274e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-1.4628, -4.5643, -0.9299,  0.8001, -0.4646, -1.0742, -5.4284,  9.5356,\n",
      "         0.5466,  2.4092], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5368], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1000e+01, -1.4101e+01, -1.0467e+01, -8.7367e+00, -1.0001e+01,\n",
      "        -1.0611e+01, -1.4965e+01, -1.2045e-03, -8.9902e+00, -7.1276e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.4070, -0.7404,  1.4130,  9.4174, -0.9355,  0.0395, -6.1564, -0.7926,\n",
      "         2.9149, -0.6725], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4195], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3826e+01, -1.0160e+01, -8.0064e+00, -2.0666e-03, -1.0355e+01,\n",
      "        -9.3800e+00, -1.5576e+01, -1.0212e+01, -6.5045e+00, -1.0092e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-2.2886, -2.6173, -0.9071,  7.5956, -2.1356,  3.5190, -5.0640, -0.2466,\n",
      "         2.3468, -0.9125], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6185], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.9071, -10.2357,  -8.5256,  -0.0229,  -9.7541,  -4.0995, -12.6825,\n",
      "         -7.8651,  -5.2717,  -8.5310], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-3.0948, -3.2039,  0.9900,  0.9606, -2.2487,  1.9846, -2.5885, -4.2051,\n",
      "         8.7451,  1.7962], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7481], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1843e+01, -1.1952e+01, -7.7581e+00, -7.7876e+00, -1.0997e+01,\n",
      "        -6.7635e+00, -1.1337e+01, -1.2953e+01, -3.0031e-03, -6.9519e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 3.3359, -5.6246,  6.4359, -3.4902, -0.5822, -0.9848, 11.6675, -9.5853,\n",
      "         2.1976, -2.4591], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.6731], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.3372e+00, -1.7298e+01, -5.2372e+00, -1.5163e+01, -1.2255e+01,\n",
      "        -1.2658e+01, -5.6562e-03, -2.1258e+01, -9.4755e+00, -1.4132e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-4.9666, -3.1870,  3.7100,  0.5695,  1.9260,  0.5745,  0.6483, -3.4189,\n",
      "         4.4282, -0.8446], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9233], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8900, -8.1103, -1.2133, -4.3539, -2.9974, -4.3489, -4.2750, -8.3422,\n",
      "        -0.4952, -5.7680], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.495\n",
      "activated x value: tensor([10.5931, -8.1677, -0.3258,  1.2312, -2.5971,  6.0155, -3.2584, -2.1366,\n",
      "         1.5217, -0.9118], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6036], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0459e-02, -1.8771e+01, -1.0929e+01, -9.3724e+00, -1.3201e+01,\n",
      "        -4.5881e+00, -1.3862e+01, -1.2740e+01, -9.0819e+00, -1.1515e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-1.8101, -5.4165,  0.9573, -1.0381,  2.5287, -0.9823, -1.5858,  2.0452,\n",
      "        -0.0686,  4.7144], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9160], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.7261, -10.3324,  -3.9587,  -5.9541,  -2.3873,  -5.8983,  -6.5018,\n",
      "         -2.8707,  -4.9846,  -0.2015], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.202\n",
      "activated x value: tensor([ 2.6701, -3.9200,  9.4790, -1.4564, -1.9472, -2.0496, -0.7822, -2.1859,\n",
      "         3.7625, -4.2508], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4834], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8133e+00, -1.3403e+01, -4.4699e-03, -1.0940e+01, -1.1431e+01,\n",
      "        -1.1533e+01, -1.0266e+01, -1.1669e+01, -5.7210e+00, -1.3734e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-1.8760, -1.8660, -0.6209,  1.9074,  0.4016,  3.6937, -0.2095, -3.2285,\n",
      "         1.4842,  0.2773], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0227], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.8987, -5.8888, -4.6436, -2.1153, -3.6211, -0.3290, -4.2322, -7.2512,\n",
      "        -2.5385, -3.7454], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.329\n",
      "activated x value: tensor([ 0.5814, -6.4335,  1.5139, -6.8083,  5.3026,  2.1456,  3.4580, -2.7954,\n",
      "         1.1016,  1.5994], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5432], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.9619, -11.9767,  -4.0294, -12.3516,  -0.2407,  -3.3977,  -2.0852,\n",
      "         -8.3386,  -4.4417,  -3.9439], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.241\n",
      "activated x value: tensor([-4.5647, -1.3500,  4.6152,  7.9545,  0.2354,  0.1291, -1.3484, -5.8846,\n",
      "         2.6256, -1.7668], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9951], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.5597,  -9.3451,  -3.3799,  -0.0406,  -7.7597,  -7.8660,  -9.3435,\n",
      "        -13.8796,  -5.3695,  -9.7618], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.041\n",
      "activated x value: tensor([ 0.6826, -5.6201, 10.1774,  2.4024, -5.0097, -1.7804,  1.0689, -1.9794,\n",
      "         1.8350, -4.1068], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1783], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4957e+00, -1.5798e+01, -8.5640e-04, -7.7759e+00, -1.5188e+01,\n",
      "        -1.1959e+01, -9.1094e+00, -1.2158e+01, -8.3432e+00, -1.4285e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 7.1085, -6.7701,  1.5659, -0.7723, -2.3254,  1.6113,  3.1450, -3.1705,\n",
      "         2.3448, -1.8279], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1440], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0355, -13.9141,  -5.5781,  -7.9163,  -9.4695,  -5.5327,  -3.9990,\n",
      "        -10.3146,  -4.7992,  -8.9720], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.036\n",
      "activated x value: tensor([-1.9551, -6.8764, -0.7243,  0.7541,  1.7641, -2.8486, -2.2593,  5.2007,\n",
      "         0.4150,  6.5288], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7757], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.7307, -13.6520,  -7.4999,  -6.0215,  -5.0116,  -9.6243,  -9.0350,\n",
      "         -1.5749,  -6.3607,  -0.2468], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-3.0629,  1.4859,  0.5130,  3.6147, -2.8753,  0.9834,  1.2807, -4.4164,\n",
      "         2.6644, -0.0845], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1728], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.2357, -2.6868, -3.6597, -0.5581, -7.0481, -3.1894, -2.8920, -8.5892,\n",
      "        -1.5083, -4.2572], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -2.892\n",
      "activated x value: tensor([-1.9024, -1.7402, -1.1930,  3.4195, -1.7541,  0.9481,  0.4595, -0.1976,\n",
      "         0.8219,  0.3131], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6884], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.5908, -5.4286, -4.8814, -0.2689, -5.4426, -2.7404, -3.2290, -3.8860,\n",
      "        -2.8665, -3.3753], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.740\n",
      "activated x value: tensor([-3.8432, -5.1820,  0.1977, -5.5698,  6.1706, -4.3114,  5.4999,  2.0416,\n",
      "        -0.2619,  4.7509], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7435], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5867, -11.9256,  -6.5458, -12.3134,  -0.5729, -11.0549,  -1.2437,\n",
      "         -4.7019,  -7.0054,  -1.9926], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -1.244\n",
      "activated x value: tensor([-5.2893,  7.8016,  0.1726,  1.7119, -3.6819, -0.5132, -0.6858, -1.0191,\n",
      "         1.7470,  0.6344], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8081], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3097e+01, -6.4602e-03, -7.6355e+00, -6.0962e+00, -1.1490e+01,\n",
      "        -8.3213e+00, -8.4939e+00, -8.8272e+00, -6.0611e+00, -7.1737e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 0.4734, -6.8694,  0.6667,  1.2654,  0.9946,  4.1576,  0.1170, -5.2431,\n",
      "         3.9263,  1.2237], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8595], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.3861, -11.7290,  -4.1929,  -3.5942,  -3.8649,  -0.7020,  -4.7425,\n",
      "        -10.1026,  -0.9333,  -3.6358], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.702\n",
      "activated x value: tensor([ 3.9799, -4.8180, -1.9230, 10.5991, -5.2426,  2.4294, -5.2967,  3.2031,\n",
      "        -1.5438, -0.8661], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6014], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6215e+00, -1.5419e+01, -1.2524e+01, -2.2488e-03, -1.5844e+01,\n",
      "        -8.1720e+00, -1.5898e+01, -7.3983e+00, -1.2145e+01, -1.1467e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-3.0715, -2.4717, -3.0561,  0.4730,  4.0397, -0.6274, -1.6453, -0.3254,\n",
      "         0.9452,  5.7595], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9397], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.0112, -8.4114, -8.9957, -5.4666, -1.8999, -6.5671, -7.5849, -6.2651,\n",
      "        -4.9944, -0.1802], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.180\n",
      "activated x value: tensor([-2.0464,  0.8589,  4.3702, -1.3972, -2.3060, -4.8861, -0.9093,  1.9723,\n",
      "         2.9205,  1.3534], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7178], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.7642, -3.8588, -0.3475, -6.1150, -7.0238, -9.6039, -5.6271, -2.7455,\n",
      "        -1.7972, -3.3644], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.348\n",
      "activated x value: tensor([ 0.8229, -5.1896, -0.7040,  7.5185, -5.6498,  5.9638, -4.5629, -1.9819,\n",
      "         3.9907, -0.5951], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7356], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9127, -12.9252,  -8.4396,  -0.2171, -13.3854,  -1.7718, -12.2985,\n",
      "         -9.7176,  -3.7449,  -8.3307], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.217\n",
      "activated x value: tensor([-0.2592, -2.1479,  1.7640, -1.6712,  0.0294,  0.5828,  5.8635, -5.2408,\n",
      "         0.8244,  0.1139], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9001], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.1593,  -8.0480,  -4.1362,  -7.5713,  -5.8708,  -5.3174,  -0.0367,\n",
      "        -11.1410,  -5.0758,  -5.7862], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.037\n",
      "activated x value: tensor([-3.0740, -1.2095,  0.7943, -1.5988,  2.1610, -2.8950,  5.5168, -0.9706,\n",
      "         2.5301, -1.1459], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6116], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6856, -6.8211, -4.8174, -7.2105, -3.4507, -8.5066, -0.0948, -6.5822,\n",
      "        -3.0816, -6.7575], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.095\n",
      "activated x value: tensor([-2.8393,  4.7989,  1.9874,  0.7267, -3.9127,  0.0687,  0.9551, -4.4313,\n",
      "         5.1635, -1.3090], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7351], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.5745,  -0.9362,  -3.7477,  -5.0085,  -9.6478,  -5.6664,  -4.7800,\n",
      "        -10.1664,  -0.5716,  -7.0442], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.936\n",
      "activated x value: tensor([-4.2034, -3.6778, -3.2171,  0.5716,  4.9896,  1.7993, -2.8101,  0.3471,\n",
      "         1.5543,  3.8772], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3436], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.5470, -9.0214, -8.5608, -4.7720, -0.3540, -3.5443, -8.1537, -4.9966,\n",
      "        -3.7894, -1.4664], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.354\n",
      "activated x value: tensor([ -0.1303,   1.2541,   8.9635,   6.8578,  -5.8556,  -0.1658,   2.9867,\n",
      "        -10.6370,   4.3326,  -7.1756], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0898], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2201,  -7.8357,  -0.1264,  -2.2321, -14.9454,  -9.2557,  -6.1031,\n",
      "        -19.7268,  -4.7572, -16.2655], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.126\n",
      "activated x value: tensor([-2.0556,  3.2370, -0.2241,  0.9268, -1.3338, -0.3128, -0.3989,  0.2761,\n",
      "         0.1038,  0.3819], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5401], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.5957, -0.3031, -3.7642, -2.6133, -4.8739, -3.8528, -3.9389, -3.2639,\n",
      "        -3.4363, -3.1582], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.303\n",
      "activated x value: tensor([ 0.8305, -8.6604,  2.5556, -7.7361,  6.7502,  2.7235,  8.0793, -7.3001,\n",
      "         1.0776,  1.1221], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3230], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4925, -16.9835,  -5.7674, -16.0591,  -1.5728,  -5.5995,  -0.2437,\n",
      "        -15.6232,  -7.2455,  -7.2009], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.244\n",
      "activated x value: tensor([ 3.2853, -7.2084,  3.1267,  0.2925, -0.9907,  1.1608, -2.9025,  1.4390,\n",
      "         0.5571,  1.2206], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1562], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.8709, -11.3646,  -1.0295,  -3.8637,  -5.1469,  -2.9953,  -7.0587,\n",
      "         -2.7172,  -3.5991,  -2.9355], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -2.936\n",
      "activated x value: tensor([-4.5891,  6.2079,  0.1066,  1.0903, -1.5493, -1.3504, -0.1866,  0.1395,\n",
      "         0.3143,  0.5511], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2271], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8163,  -0.0193,  -6.1205,  -5.1368,  -7.7765,  -7.5775,  -6.4138,\n",
      "         -6.0876,  -5.9129,  -5.6760], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([ 1.2287, -3.7863, -0.1292, -0.9445, -0.2812,  6.9217, -2.3524, -2.8423,\n",
      "         2.8529,  0.2051], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9452], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.7166, -10.7315,  -7.0744,  -7.8898,  -7.2264,  -0.0236,  -9.2976,\n",
      "         -9.7875,  -4.0923,  -6.7402], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-4.9697,  6.7765,  0.8936,  2.0955, -3.3571, -1.1388,  0.1984, -0.8627,\n",
      "         1.0375, -0.2754], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7947], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.7645,  -0.0183,  -5.9011,  -4.6992, -10.1518,  -7.9335,  -6.5963,\n",
      "         -7.6574,  -5.7572,  -7.0701], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([-0.7760, -3.5949, -3.6343,  2.0037,  1.2039, -0.0128, -2.5079,  6.4428,\n",
      "        -0.7915,  0.6856], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4660], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.2420, -10.0609, -10.1004,  -4.4624,  -5.2621,  -6.4789,  -8.9739,\n",
      "         -0.0232,  -7.2575,  -5.7804], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([ 10.2310, -10.3766,   0.2266,  -0.9100,  -1.2846,   5.1208,  -1.1339,\n",
      "         -1.0746,   1.0979,  -0.7980], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2373], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.2332e-03, -2.0614e+01, -1.0011e+01, -1.1147e+01, -1.1522e+01,\n",
      "        -5.1165e+00, -1.1371e+01, -1.1312e+01, -9.1394e+00, -1.1035e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-5.4990,  6.8629,  0.4771,  2.2742, -3.0179, -1.7408, -1.6813,  0.7638,\n",
      "         1.3455,  1.5246], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8860], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.3850,  -0.0231,  -6.4089,  -4.6118,  -9.9039,  -8.6268,  -8.5673,\n",
      "         -6.1222,  -5.5405,  -5.3614], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([ 0.7129, -2.8131,  1.1375,  2.7899,  1.6439,  1.8576, -0.9585, -4.7827,\n",
      "         0.8127,  0.0825], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([3.6059], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.8930, -6.4190, -2.4684, -0.8160, -1.9620, -1.7483, -4.5644, -8.3886,\n",
      "        -2.7932, -3.5234], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.816\n",
      "activated x value: tensor([-3.0968,  5.1239,  0.6777,  0.7527, -2.1257, -0.6100, -0.2709, -0.7696,\n",
      "         0.8199, -0.0694], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1774], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.2742, -0.0535, -4.4997, -4.4247, -7.3030, -5.7873, -5.4482, -5.9469,\n",
      "        -4.3575, -5.2468], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.053\n",
      "activated x value: tensor([ 0.2052, -4.5728,  1.0968,  0.3695,  0.1899,  2.1063, -1.7650, -3.8147,\n",
      "         4.6708,  0.9253], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8251], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.6200, -9.3979, -3.7283, -4.4556, -4.6352, -2.7188, -6.5902, -8.6398,\n",
      "        -0.1544, -3.8998], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.154\n",
      "activated x value: tensor([-0.6415, -3.8344,  2.0742, -2.5220,  1.6437, -1.4751, 10.6577, -7.6714,\n",
      "         2.0183, -0.5292], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6582], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1300e+01, -1.4493e+01, -8.5840e+00, -1.3180e+01, -9.0145e+00,\n",
      "        -1.2133e+01, -5.1975e-04, -1.8330e+01, -8.6399e+00, -1.1187e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-5.2608, -5.3094, -2.4924, -1.1772,  9.6944,  0.3311,  0.1037, -0.8880,\n",
      "        -1.3053,  7.1743], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7720], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.0328, -15.0814, -12.2644, -10.9492,  -0.0776,  -9.4409,  -9.6683,\n",
      "        -10.6600, -11.0773,  -2.5977], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.078\n",
      "activated x value: tensor([-5.2646, -1.8887, -0.1374,  0.4528,  6.4488, -0.6325,  0.8589, -1.7898,\n",
      "        -0.6608,  3.3260], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5012], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.7658,  -8.3899,  -6.6386,  -6.0484,  -0.0524,  -7.1337,  -5.6423,\n",
      "         -8.2910,  -7.1620,  -3.1752], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.052\n",
      "activated x value: tensor([-5.3283,  0.1146, -0.6735, -1.3711,  3.0764, -3.5314, -1.6277,  2.0259,\n",
      "         1.5627,  5.5220], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6570], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9853,  -5.5424,  -6.3304,  -7.0280,  -2.5805,  -9.1884,  -7.2846,\n",
      "         -3.6311,  -4.0943,  -0.1350], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.135\n",
      "activated x value: tensor([-2.8426, -2.8793, -5.3255, -0.5565,  5.6960,  1.0961, -1.2855, -0.5296,\n",
      "        -0.6562,  7.0938], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3180], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1606, -10.1973, -12.6435,  -7.8745,  -1.6220,  -6.2219,  -8.6035,\n",
      "         -7.8476,  -7.9742,  -0.2242], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.224\n",
      "activated x value: tensor([ 0.7530, -3.0318, -1.3264,  7.2670, -4.3550,  3.5267,  0.3225, -3.7538,\n",
      "         0.7690, -0.5793], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2949], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.5419, -10.3268,  -8.6213,  -0.0279, -11.6499,  -3.7682,  -6.9724,\n",
      "        -11.0488,  -6.5259,  -7.8742], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-8.0080,  4.4255,  1.4882,  1.8882, -1.3810, -2.3100, -0.1171,  0.5444,\n",
      "         1.5904,  2.1108], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7070], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7150,  -0.2815,  -3.2188,  -2.8188,  -6.0880,  -7.0170,  -4.8241,\n",
      "         -4.1626,  -3.1166,  -2.5962], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -4.163\n",
      "activated x value: tensor([-3.7319,  5.4919,  0.9986,  0.8087, -1.4521, -1.1992, -0.6727,  0.1439,\n",
      "         0.5298, -0.3001], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5308], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2627, -0.0389, -4.5322, -4.7221, -6.9829, -6.7301, -6.2035, -5.3869,\n",
      "        -5.0010, -5.8309], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.039\n",
      "activated x value: tensor([-2.1058, -5.3749,  0.1531, -0.9242,  1.6389, -0.7748, -1.7807,  3.2744,\n",
      "        -0.2869,  5.1641], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3448], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4506, -10.7198,  -5.1918,  -6.2690,  -3.7059,  -6.1197,  -7.1256,\n",
      "         -2.0705,  -5.6317,  -0.1807], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.181\n",
      "activated x value: tensor([ 6.3899, -9.0083,  1.5984, -0.1854, -1.3042,  2.1126, -0.7211, -0.4671,\n",
      "         0.9831,  0.2962], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4220], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0321, -15.4303,  -4.8236,  -6.6074,  -7.7262,  -4.3094,  -7.1431,\n",
      "         -6.8891,  -5.4389,  -6.1258], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.032\n",
      "activated x value: tensor([ 6.8295, -9.6151,  2.4082, -1.4751, -2.9274, -0.6591, -1.6609,  3.2688,\n",
      "         0.9995,  3.7986], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9182], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0887, -16.5333,  -4.5100,  -8.3933,  -9.8456,  -7.5772,  -8.5791,\n",
      "         -3.6493,  -5.9186,  -3.1196], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.089\n",
      "activated x value: tensor([-5.0156,  6.8379,  2.6677, -0.8021, -0.1591, -2.6237, -1.2164, -0.0401,\n",
      "         2.8389, -2.7673], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8739], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8895,  -0.0360,  -4.2062,  -7.6761,  -7.0331,  -9.4976,  -8.0903,\n",
      "         -6.9141,  -4.0350,  -9.6413], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.036\n",
      "activated x value: tensor([ 2.8782, -4.5439,  0.6020,  9.4541, -6.8621,  5.0055, -4.5664,  0.2874,\n",
      "         0.2312, -3.1319], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4675], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.5893e+00, -1.4011e+01, -8.8655e+00, -1.3350e-02, -1.6330e+01,\n",
      "        -4.4620e+00, -1.4034e+01, -9.1801e+00, -9.2363e+00, -1.2599e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([ 0.0449, -0.7023,  1.6920,  5.5344, -1.9714,  0.2810,  2.0653, -5.0570,\n",
      "        -0.2040, -1.7313], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6005], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.5556,  -6.3028,  -3.9085,  -0.0662,  -7.5719,  -5.3196,  -3.5353,\n",
      "        -10.6576,  -5.8046,  -7.3319], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.066\n",
      "activated x value: tensor([ 0.2812, -2.5984, -1.4061, -2.8045, -0.4572,  0.2933, -0.4080,  2.5992,\n",
      "         0.0738,  4.3972], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6061], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.3250, -7.2045, -6.0122, -7.4106, -5.0633, -4.3128, -5.0142, -2.0069,\n",
      "        -4.5324, -0.2089], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -4.313\n",
      "activated x value: tensor([ 0.0983, -4.2687,  1.2797,  2.8786, -1.7394,  3.9643, -1.0418, -6.4142,\n",
      "         8.0845, -3.4363], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1075], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.0093, -12.3763,  -6.8279,  -5.2289,  -9.8470,  -4.1433,  -9.1493,\n",
      "        -14.5217,  -0.0231, -11.5438], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([ 0.6163, -4.7519,  0.5047,  2.2690, -1.3457,  9.4240, -4.2932, -5.2006,\n",
      "         4.7841, -2.6274], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4347], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8184e+00, -1.4187e+01, -8.9300e+00, -7.1657e+00, -1.0780e+01,\n",
      "        -1.0695e-02, -1.3728e+01, -1.4635e+01, -4.6506e+00, -1.2062e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-1.1273, -3.5141,  0.2385, -3.9762,  6.0550, -2.2595,  1.2135,  1.0702,\n",
      "         0.5825,  1.1928], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0853], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.2127,  -9.5994,  -5.8468, -10.0615,  -0.0303,  -8.3448,  -4.8718,\n",
      "         -5.0152,  -5.5029,  -4.8925], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.030\n",
      "activated x value: tensor([ 7.6210, -9.9100,  2.6412,  0.5520, -5.9788,  3.5683, -1.4315, -2.5593,\n",
      "         3.8104,  1.8376], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6702], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0492, -17.5802,  -5.0290,  -7.1183, -13.6491,  -4.1019,  -9.1017,\n",
      "        -10.2295,  -3.8599,  -5.8327], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.049\n",
      "activated x value: tensor([-7.4217,  2.5731,  0.6988,  2.2738, -2.9175, -1.8874, -3.1300,  5.7636,\n",
      "         1.2453,  2.4929], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8838], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.3055,  -3.3106,  -5.1849,  -3.6100,  -8.8013,  -7.7711,  -9.0138,\n",
      "         -0.1201,  -4.6384,  -3.3908], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.120\n",
      "activated x value: tensor([ 0.6870, -3.8031,  1.0541,  1.7914, -3.1151,  3.8088,  7.5227, -8.5742,\n",
      "         1.0968, -0.4818], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5544], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.8674, -11.3576,  -6.5004,  -5.7630, -10.6695,  -3.7456,  -0.0317,\n",
      "        -16.1286,  -6.4577,  -8.0363], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: -0.032\n",
      "activated x value: tensor([-6.4787,  8.1198,  0.0295,  1.3531, -2.7822, -0.3732,  0.6124, -1.5544,\n",
      "         2.0420, -0.8155], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1245], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4603e+01, -4.7073e-03, -8.0950e+00, -6.7715e+00, -1.0907e+01,\n",
      "        -8.4977e+00, -7.5121e+00, -9.6789e+00, -6.0825e+00, -8.9401e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-3.9314, -0.3448, -0.1541,  0.1306,  4.2827, -2.8687,  1.1682, -1.2903,\n",
      "         0.6508,  2.3455], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5116], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.4430, -4.8564, -4.6657, -4.3809, -0.2289, -7.3803, -3.3434, -5.8019,\n",
      "        -3.8607, -2.1661], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.229\n",
      "activated x value: tensor([-2.4450, -5.7101,  2.5035,  5.0266, -3.1867,  0.4666, -1.8400,  5.4009,\n",
      "        -2.4173,  3.6048], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0521], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.4971, -11.7621,  -3.5485,  -1.0254,  -9.2387,  -5.5855,  -7.8921,\n",
      "         -0.6512,  -8.4694,  -2.4473], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.651\n",
      "activated x value: tensor([-3.8456,  4.9154,  0.5522, -0.2424, -0.5815, -1.1206, -0.9248,  1.3916,\n",
      "         1.0254, -0.7726], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9937], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8393, -0.0782, -4.4415, -5.2361, -5.5752, -6.1142, -5.9185, -3.6020,\n",
      "        -3.9683, -5.7663], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.078\n",
      "activated x value: tensor([-0.1347, -6.0044, -1.8002, -1.6937,  0.6462,  1.7865, -3.7378,  3.6086,\n",
      "         1.5268,  5.3416], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5587], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6934, -11.5632,  -7.3589,  -7.2524,  -4.9126,  -3.7723,  -9.2965,\n",
      "         -1.9501,  -4.0319,  -0.2171], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.950\n",
      "activated x value: tensor([-2.2418, -3.1322,  2.2134, 10.6996, -1.9699,  2.4350, -4.7236, -3.5128,\n",
      "         1.9672, -2.0417], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7003], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2942e+01, -1.3833e+01, -8.4869e+00, -6.3515e-04, -1.2670e+01,\n",
      "        -8.2653e+00, -1.5424e+01, -1.4213e+01, -8.7331e+00, -1.2742e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([  1.3710,  -2.0950,  12.2947,   6.8630,  -8.0810,   0.2274,  -0.0660,\n",
      "        -11.2311,   6.7582,  -6.4528], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.3030], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0932e+01, -1.4398e+01, -8.3103e-03, -5.4400e+00, -2.0384e+01,\n",
      "        -1.2076e+01, -1.2369e+01, -2.3534e+01, -5.5448e+00, -1.8756e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([ 1.1240, -3.2815,  6.7016,  6.3045, -4.3940, -1.9890, -0.7842,  1.5452,\n",
      "        -2.7995, -1.5970], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2221], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.0982, -10.5036,  -0.5205,  -0.9176, -11.6161,  -9.2112,  -8.0063,\n",
      "         -5.6769, -10.0216,  -8.8191], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.521\n",
      "activated x value: tensor([-1.6088e+00,  2.5248e-01,  2.5905e-03,  1.1946e+00, -8.9467e-01,\n",
      "         9.0978e-01,  1.6136e+00, -2.8928e+00,  1.0909e+00,  5.8564e-02],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([2.8791], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.4879, -2.6266, -2.8765, -1.6845, -3.7738, -1.9693, -1.2655, -5.7719,\n",
      "        -1.7882, -2.8205], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -1.266\n",
      "activated x value: tensor([-5.4415,  1.5382, -1.8916,  0.9503, -0.2538,  3.4678, -3.1321, -1.1313,\n",
      "         5.2502,  1.3826], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4604], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9019,  -3.9222,  -7.3520,  -4.5102,  -5.7142,  -1.9926,  -8.5926,\n",
      "         -6.5918,  -0.2102,  -4.0778], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.210\n",
      "activated x value: tensor([-0.9151, -4.3436,  4.9160, -4.0895,  0.9333,  2.1198,  7.3240, -5.2127,\n",
      "         1.0584, -2.3819], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4188], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3339, -11.7624,  -2.5029, -11.5083,  -6.4855,  -5.2991,  -0.0948,\n",
      "        -12.6315,  -6.3604,  -9.8007], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.095\n",
      "activated x value: tensor([ 0.2929, -5.3098,  4.4640, -4.9610,  2.3100, -0.4323, 10.3897, -9.2548,\n",
      "         1.7821,  1.7097], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3931], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0100e+01, -1.5703e+01, -5.9291e+00, -1.5354e+01, -8.0831e+00,\n",
      "        -1.0825e+01, -3.3884e-03, -1.9648e+01, -8.6109e+00, -8.6834e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 0.7231, -5.1673,  3.3608,  9.0130, -2.4109,  1.6849, -3.4177, -5.6286,\n",
      "         1.4359,  0.7196], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0182], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.2951e+00, -1.4185e+01, -5.6574e+00, -5.1823e-03, -1.1429e+01,\n",
      "        -7.3332e+00, -1.2436e+01, -1.4647e+01, -7.5822e+00, -8.2986e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([  9.0513, -10.3312,   0.7577,  -3.5999,  -3.5918,   3.9672,  -2.3549,\n",
      "         -1.1340,   5.3178,   2.1801], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0822], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0310, -19.4134,  -8.3245, -12.6821, -12.6740,  -5.1150, -11.4371,\n",
      "        -10.2162,  -3.7644,  -6.9022], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.031\n",
      "activated x value: tensor([-1.5601,  0.9574,  9.6786,  1.1657, -4.7764, -2.4393,  4.3468, -5.1181,\n",
      "         1.0481, -3.1448], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6840], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1244e+01, -8.7266e+00, -5.3854e-03, -8.5183e+00, -1.4460e+01,\n",
      "        -1.2123e+01, -5.3372e+00, -1.4802e+01, -8.6359e+00, -1.2829e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -8.727\n",
      "activated x value: tensor([-1.4622, -3.1375,  1.4559, -3.0704,  0.9292,  2.0949,  9.4236, -7.4359,\n",
      "         2.9214, -0.9618], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4264], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0889e+01, -1.2564e+01, -7.9704e+00, -1.2497e+01, -8.4972e+00,\n",
      "        -7.3315e+00, -2.7609e-03, -1.6862e+01, -6.5050e+00, -1.0388e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-1.2829, -1.6928, -1.3529,  5.5804, -0.9221,  0.1879, -3.0875, -2.2492,\n",
      "         1.2043,  3.0768], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6791], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9619, -7.3718, -7.0319, -0.0987, -6.6012, -5.4912, -8.7666, -7.9282,\n",
      "        -4.4748, -2.6023], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.099\n",
      "activated x value: tensor([-3.7169, -6.1993, -1.7299, -1.1857,  3.9814,  0.5828, -1.1336,  1.6329,\n",
      "         1.2047,  6.8840], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9482], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6650, -13.1475,  -8.6780,  -8.1338,  -2.9667,  -6.3654,  -8.0817,\n",
      "         -5.3153,  -5.7434,  -0.0641], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.064\n",
      "activated x value: tensor([12.9222, -9.3439,  3.6000, -3.5247, -9.2893,  1.8773,  1.0699, -0.4405,\n",
      "         3.5153,  1.2354], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.9224], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0504e-04, -2.2266e+01, -9.3223e+00, -1.6447e+01, -2.2212e+01,\n",
      "        -1.1045e+01, -1.1853e+01, -1.3363e+01, -9.4070e+00, -1.1687e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-6.6364, -2.5046,  5.4183,  2.8824, -2.6537, -2.2086, -1.3002,  5.2492,\n",
      "        -0.2715,  1.1643], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0828], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7192,  -8.5874,  -0.6645,  -3.2004,  -8.7365,  -8.2914,  -7.3830,\n",
      "         -0.8336,  -6.3543,  -4.9186], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.665\n",
      "activated x value: tensor([-1.5306, -1.4676,  1.3791,  6.5788, -2.3395,  2.0910,  0.8101, -5.3031,\n",
      "         0.5760, -1.6759], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6019], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.1325,  -8.0696,  -5.2228,  -0.0231,  -8.9414,  -4.5110,  -5.7919,\n",
      "        -11.9050,  -6.0260,  -8.2778], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-3.3948, -3.9384,  2.7785,  3.6631, -3.0998,  0.1707, -3.3625, -2.2873,\n",
      "         7.1902,  1.8546], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2365], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6313, -11.1749,  -4.4580,  -3.5734, -10.3363,  -7.0658, -10.5990,\n",
      "         -9.5238,  -0.0463,  -5.3819], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.046\n",
      "activated x value: tensor([ 2.3965, -3.2641,  1.2676, -0.7996, -0.7153,  4.7484, -1.6062, -2.9458,\n",
      "         1.6274,  0.8250], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9311], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.5346, -8.1952, -3.6635, -5.7308, -5.6465, -0.1828, -6.5373, -7.8769,\n",
      "        -3.3038, -4.1062], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.183\n",
      "activated x value: tensor([-4.0280,  6.7015, -0.1761,  1.4115, -3.2137,  0.2631, -0.4309, -1.2383,\n",
      "         1.5441, -0.2551], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7170], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7451,  -0.0155,  -6.8931,  -5.3055,  -9.9307,  -6.4539,  -7.1479,\n",
      "         -7.9554,  -5.1729,  -6.9721], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-1.6815, -3.1827,  1.5755, -2.5559,  0.0428,  1.7243, -0.2825, -2.9936,\n",
      "         6.0909,  1.9191], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1339], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8154, -9.3165, -4.5584, -8.6898, -6.0911, -4.4095, -6.4163, -9.1274,\n",
      "        -0.0430, -4.2148], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([-5.6836,  7.2252,  0.5847,  1.7882, -3.0215,  0.3921,  0.6870, -3.2341,\n",
      "         3.0125, -1.9535], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2481], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.9317,  -0.0229,  -6.6634,  -5.4599, -10.2696,  -6.8560,  -6.5611,\n",
      "        -10.4822,  -4.2356,  -9.2016], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-0.1094, -6.1568, -3.0001,  3.4558,  2.1062,  4.6836, -1.9169, -1.9470,\n",
      "         2.8974, -0.7198], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1234], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.2328, -11.2803,  -8.1236,  -1.6677,  -3.0172,  -0.4398,  -7.0403,\n",
      "         -7.0705,  -2.2261,  -5.8433], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.440\n",
      "activated x value: tensor([-4.0456,  5.9913,  9.2311,  2.8455, -6.7447, -3.5079,  3.3999, -5.5349,\n",
      "         3.1654, -4.6258], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2761], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.3218,  -3.2849,  -0.0451,  -6.4306, -16.0208, -12.7840,  -5.8762,\n",
      "        -14.8110,  -6.1107, -13.9020], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-4.2541,  6.6196,  0.8620,  0.9120, -3.5851,  0.0563, -0.0197, -1.4785,\n",
      "         1.3309, -0.0411], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6354], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8895,  -0.0158,  -5.7734,  -5.7233, -10.2205,  -6.5791,  -6.6551,\n",
      "         -8.1139,  -5.3044,  -6.6765], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([ 2.8590, -0.4964, -0.7869,  1.0758, -2.2688,  7.1637, -5.5853, -0.4033,\n",
      "         2.2630, -3.5297], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1881], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.3291,  -7.6845,  -7.9750,  -6.1123,  -9.4569,  -0.0244, -12.7734,\n",
      "         -7.5913,  -4.9250, -10.7178], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-1.2474, -1.8423,  2.5377, -2.4787,  0.4595, -0.3779,  7.9263, -3.9970,\n",
      "        -0.5395, -0.1921], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9324], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1798e+00, -9.7747e+00, -5.3947e+00, -1.0411e+01, -7.4728e+00,\n",
      "        -8.3102e+00, -6.0754e-03, -1.1929e+01, -8.4718e+00, -8.1245e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 0.4101, -9.1155,  9.8847,  5.1321,  0.5127,  0.5179, -1.0737, -4.9917,\n",
      "         0.4802, -3.0898], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8937], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4836e+00, -1.9009e+01, -8.9388e-03, -4.7616e+00, -9.3810e+00,\n",
      "        -9.3758e+00, -1.0967e+01, -1.4885e+01, -9.4135e+00, -1.2983e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-5.9347, -3.8632, -0.1047, -0.6897,  2.8949, -4.1439, -3.5313, 10.0115,\n",
      "         1.7198,  3.4240], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0140], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5949e+01, -1.3877e+01, -1.0119e+01, -1.0704e+01, -7.1192e+00,\n",
      "        -1.4158e+01, -1.3545e+01, -2.5024e-03, -8.2943e+00, -6.5901e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-5.5237, -6.0832, -1.4096, -1.4195,  6.4922, -0.5417,  2.0386, -1.5662,\n",
      "         2.2204,  5.6402], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8666], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.3903, -12.9497,  -8.2761,  -8.2861,  -0.3744,  -7.4083,  -4.8279,\n",
      "         -8.4328,  -4.6462,  -1.2264], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.374\n",
      "activated x value: tensor([ 1.1058,  2.0868,  6.1557,  4.9262, -6.7835,  0.5201,  3.3922, -8.9836,\n",
      "         3.9853, -5.3392], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5590], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.4531,  -4.4722,  -0.4033,  -1.6327, -13.3424,  -6.0389,  -3.1667,\n",
      "        -15.5426,  -2.5737, -11.8981], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.403\n",
      "activated x value: tensor([-0.6861, -6.9088,  0.4636,  4.1671, -2.6763, -1.0364, -5.7418, 10.2096,\n",
      "        -0.8088,  2.7612], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2126], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0899e+01, -1.7121e+01, -9.7490e+00, -6.0455e+00, -1.2889e+01,\n",
      "        -1.1249e+01, -1.5954e+01, -3.0622e-03, -1.1021e+01, -7.4514e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-2.0184, -5.0061, -0.1637, -3.6844,  2.9407, -2.8718, -1.3432,  4.8323,\n",
      "         0.8048,  6.5092], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7084], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.7268, -11.7146,  -6.8721, -10.3928,  -3.7677,  -9.5802,  -8.0516,\n",
      "         -1.8761,  -5.9036,  -0.1992], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.199\n",
      "activated x value: tensor([ 10.0753,  -8.9897,   3.0061,  -1.9574,  -5.4862,   7.3686,   5.1204,\n",
      "        -12.7363,   8.6295,  -4.1274], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3455], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.2702, -19.3352,  -7.3394, -12.3029, -15.8317,  -2.9769,  -5.2251,\n",
      "        -23.0818,  -1.7160, -14.4729], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.270\n",
      "activated x value: tensor([11.1863, -6.0288,  0.7406, -2.3877, -6.6498,  9.2563,  5.3353, -4.1346,\n",
      "        -0.2524, -5.0703], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.3244], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1381, -17.3532, -10.5838, -13.7121, -17.9742,  -2.0681,  -5.9891,\n",
      "        -15.4590, -11.5768, -16.3947], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.138\n",
      "activated x value: tensor([-1.9990, -4.6135,  3.3154,  0.1439,  1.3799,  2.0127,  0.8110, -4.3304,\n",
      "         0.8943,  2.2044], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9902], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9892, -8.6037, -0.6748, -3.8463, -2.6103, -1.9775, -3.1792, -8.3206,\n",
      "        -3.0959, -1.7858], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.977\n",
      "activated x value: tensor([ 1.1895, -5.1510, -2.9901, -1.6592,  1.5834,  1.6096, -1.6205,  4.6325,\n",
      "         0.1771,  2.5967], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8751], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.6856, -10.0261,  -7.8652,  -6.5343,  -3.2918,  -3.2655,  -6.4956,\n",
      "         -0.2426,  -4.6980,  -2.2784], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.243\n",
      "activated x value: tensor([-4.4474, -1.8532, -0.4215, -1.9165,  2.8426,  1.4796, -0.8071,  0.1298,\n",
      "         2.1140,  2.4289], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7782], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.2255, -5.6314, -4.1997, -5.6947, -0.9356, -2.2986, -4.5853, -3.6484,\n",
      "        -1.6641, -1.3493], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.936\n",
      "activated x value: tensor([-3.2737,  4.3197,  1.8543,  0.3099, -0.5219, -1.2590, -1.4035,  0.5758,\n",
      "         0.9599, -1.1716], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4862], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7598, -0.1664, -2.6319, -4.1763, -5.0081, -5.7451, -5.8897, -3.9103,\n",
      "        -3.5262, -5.6577], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.166\n",
      "activated x value: tensor([-1.2130, -4.0612, -1.6781,  0.0481,  0.9801,  0.6401, -2.7719,  4.1772,\n",
      "        -0.5306,  4.7837], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2548], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4678, -9.3160, -6.9330, -5.2067, -4.2747, -4.6147, -8.0268, -1.0776,\n",
      "        -5.7854, -0.4712], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.078\n",
      "activated x value: tensor([-0.1171, -2.1999,  1.1873, -2.1096,  0.7254, -0.1871,  8.4020, -4.8352,\n",
      "         0.1053, -0.3813], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4041], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-8.5212e+00, -1.0604e+01, -7.2168e+00, -1.0514e+01, -7.6787e+00,\n",
      "        -8.5911e+00, -2.0390e-03, -1.3239e+01, -8.2988e+00, -8.7853e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-4.1639,  7.2990,  1.9710,  1.4066, -3.7541, -1.6958,  0.6303, -1.9944,\n",
      "         1.7885, -0.5060], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3125], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.4764,  -0.0135,  -5.3415,  -5.9059, -11.0666,  -9.0083,  -6.6822,\n",
      "         -9.3069,  -5.5240,  -7.8185], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([ 0.2864, -4.6251,  0.5826,  3.9061, -4.1111,  5.2674,  3.5683, -3.4826,\n",
      "         1.6311, -3.6323], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6608], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.3744, -10.2859,  -5.0782,  -1.7547,  -9.7719,  -0.3935,  -2.0925,\n",
      "         -9.1434,  -4.0297,  -9.2931], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.393\n",
      "activated x value: tensor([-2.7226, -1.7390, -3.7194, -1.7124, -0.2018,  5.4194, -3.0256,  0.5149,\n",
      "         4.9687,  1.9980], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9401], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6627, -7.6791, -9.6595, -7.6525, -6.1418, -0.5206, -8.9657, -5.4251,\n",
      "        -0.9713, -3.9420], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.971\n",
      "activated x value: tensor([-4.8103,  6.2818,  0.8288,  0.9634, -2.2663, -1.3285, -0.1224, -0.2170,\n",
      "         0.9793,  0.3442], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3022], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.1126,  -0.0205,  -5.4734,  -5.3388,  -8.5685,  -7.6307,  -6.4246,\n",
      "         -6.5192,  -5.3229,  -5.9581], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([ 8.9595, -4.2509,  2.2046,  2.1421, -9.9171,  3.6758, -3.0904,  1.0871,\n",
      "         0.0758, -1.0500], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9674], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8745e-03, -1.3218e+01, -6.7628e+00, -6.8252e+00, -1.8885e+01,\n",
      "        -5.2915e+00, -1.2058e+01, -7.8803e+00, -8.8916e+00, -1.0017e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-0.7423, -1.5514, -0.4380, -2.2504,  1.2626,  1.0415,  0.7620, -0.6410,\n",
      "         2.2165,  0.8588], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.0916], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.8339, -4.6430, -3.5296, -5.3419, -1.8290, -2.0501, -2.3296, -3.7326,\n",
      "        -0.8750, -2.2328], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.875\n",
      "activated x value: tensor([ 2.2729, -3.5681, 11.7201,  5.4740, -7.6360, -2.4727, -1.4382, -9.5202,\n",
      "         6.7940, -2.5131], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7294], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4564e+00, -1.5297e+01, -9.2325e-03, -6.2554e+00, -1.9365e+01,\n",
      "        -1.4202e+01, -1.3168e+01, -2.1250e+01, -4.9354e+00, -1.4243e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([ 0.1199, -3.3318, -3.9110, -2.9014,  2.6769, -1.1947,  6.4228, -2.2822,\n",
      "         1.8180,  4.0776], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5469], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.4270,  -9.8788, -10.4579,  -9.4483,  -3.8700,  -7.7416,  -0.1241,\n",
      "         -8.8291,  -4.7289,  -2.4693], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -6.427\n",
      "activated x value: tensor([ 2.1545, -3.0161,  2.1928, -2.5537, -0.7464, -1.1349,  6.4073, -4.7309,\n",
      "         1.3048, -0.4116], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4443], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.2898,  -9.4604,  -4.2515,  -8.9980,  -7.1907,  -7.5793,  -0.0370,\n",
      "        -11.1752,  -5.1396,  -6.8559], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.037\n",
      "activated x value: tensor([-3.3381, -3.8252,  2.5685,  1.1910,  0.0533,  1.8183, -1.6125, -4.8990,\n",
      "         8.7645, -1.9995], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7682], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2106e+01, -1.2593e+01, -6.1997e+00, -7.5772e+00, -8.7149e+00,\n",
      "        -6.9499e+00, -1.0381e+01, -1.3667e+01, -3.7336e-03, -1.0768e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 0.6114, -4.7905, -0.5552,  4.4482, -6.7484,  3.0591, -3.5227, -2.5029,\n",
      "         7.8897,  1.3733], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9312], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.3198, -12.7217,  -8.4865,  -3.4830, -14.6796,  -4.8721, -11.4539,\n",
      "        -10.4341,  -0.0416,  -6.5579], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([-2.4697, -4.2161,  1.1246,  0.1036, -2.2755, -0.7837, -5.5389,  8.9021,\n",
      "         0.2423,  5.0400], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9237], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3934, -13.1399,  -7.7991,  -8.8201, -11.1992,  -9.7074, -14.4626,\n",
      "         -0.0216,  -8.6814,  -3.8837], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.022\n",
      "activated x value: tensor([-0.6718,  0.5237, -1.1973,  1.3770, -2.2531,  7.9574, -2.5943, -4.7032,\n",
      "         4.6925, -3.0422], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9972], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.6689,  -7.4735,  -9.1945,  -6.6202, -10.2503,  -0.0397, -10.5915,\n",
      "        -12.7004,  -3.3047, -11.0394], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.040\n",
      "activated x value: tensor([-0.5668,  1.8260, -0.4525,  9.5242, -2.3536,  2.0196, -4.2358, -2.0631,\n",
      "         1.2460, -4.3305], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5255], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0092e+01, -7.6996e+00, -9.9780e+00, -1.3638e-03, -1.1879e+01,\n",
      "        -7.5060e+00, -1.3761e+01, -1.1589e+01, -8.2795e+00, -1.3856e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.3538, -1.7543, -3.6904, -0.8313,  3.3442, -0.7692, -3.9027,  0.9895,\n",
      "         3.2809,  8.4356], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4482], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2802e+01, -1.0203e+01, -1.2139e+01, -9.2796e+00, -5.1041e+00,\n",
      "        -9.2175e+00, -1.2351e+01, -7.4587e+00, -5.1674e+00, -1.2670e-02],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([10.0338, -8.7356,  0.5786, -0.3990, -4.8755,  5.8312,  0.5176, -1.6865,\n",
      "         1.4949, -2.0687], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0491], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5231e-02, -1.8785e+01, -9.4705e+00, -1.0448e+01, -1.4925e+01,\n",
      "        -4.2178e+00, -9.5314e+00, -1.1736e+01, -8.5542e+00, -1.2118e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-5.9009,  5.5441, -2.4200,  2.5045, -3.6117,  0.3949, -5.1960,  2.7534,\n",
      "         3.9988,  1.5512], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8421], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.7430,  -0.2980,  -8.2621,  -3.3376,  -9.4539,  -5.4472, -11.0382,\n",
      "         -3.0887,  -1.8433,  -4.2910], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.843\n",
      "activated x value: tensor([-6.0149, -3.6495, -3.9329,  1.7935,  3.0371,  0.9725, -4.8235,  2.0361,\n",
      "         2.7649,  6.7230], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7849], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7997, -10.4344, -10.7178,  -4.9914,  -3.7478,  -5.8123, -11.6084,\n",
      "         -4.7488,  -4.0200,  -0.0619], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.062\n",
      "activated x value: tensor([ 0.1502,  0.8807,  1.2824, -1.6254, -2.8558,  7.1329,  1.5971, -5.5062,\n",
      "         2.0785, -3.4581], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1491], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9989,  -6.2684,  -5.8667,  -8.7745, -10.0049,  -0.0162,  -5.5520,\n",
      "        -12.6553,  -5.0706, -10.6072], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-5.4544,  4.3875, -0.8669,  1.8004, -1.3487,  1.6219, -1.2344, -1.6317,\n",
      "         1.7135, -0.3049], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5953], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0496,  -0.2077,  -5.4621,  -2.7949,  -5.9440,  -2.9734,  -5.8296,\n",
      "         -6.2270,  -2.8817,  -4.9002], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.208\n",
      "activated x value: tensor([ 0.0863, -5.4211,  0.1110, -5.1386,  5.6559,  0.2134,  1.1318,  1.0622,\n",
      "        -0.6564,  1.9480], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7136], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6273, -11.1347,  -5.6026, -10.8522,  -0.0577,  -5.5002,  -4.5818,\n",
      "         -4.6514,  -6.3700,  -3.7656], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.058\n",
      "activated x value: tensor([-3.0977,  0.8744,  2.4172,  2.4216, -5.2307,  2.2883, -1.1117, -3.3647,\n",
      "         6.7305, -2.5990], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7717], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.8694,  -5.8972,  -4.3544,  -4.3501, -12.0024,  -4.4834,  -7.8834,\n",
      "        -10.1364,  -0.0412,  -9.3707], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-3.1619, -2.8037,  1.1235,  2.4618, -1.9663, -1.3050, -3.2424,  5.2046,\n",
      "        -0.6611,  4.2546], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5925], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.7544, -8.3962, -4.4690, -3.1307, -7.5588, -6.8975, -8.8349, -0.3879,\n",
      "        -6.2536, -1.3379], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.388\n",
      "activated x value: tensor([ 0.4861, -3.0750, -2.6818,  2.6357, -0.3010,  4.5921, -2.2838,  1.7463,\n",
      "         0.5370, -1.6393], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8112], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.3251, -7.8862, -7.4930, -2.1755, -5.1122, -0.2191, -7.0950, -3.0649,\n",
      "        -4.2742, -6.4505], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.219\n",
      "activated x value: tensor([-6.5995, -4.4239, -1.3664,  0.7168,  5.6062, -0.0981, -0.6133,  0.1872,\n",
      "         1.9752,  4.2636], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8731], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.4726, -10.2971,  -7.2395,  -5.1563,  -0.2669,  -5.9712,  -6.4864,\n",
      "         -5.6859,  -3.8980,  -1.6095], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.267\n",
      "activated x value: tensor([-2.5035,  1.2486,  1.9385,  4.4563, -4.2528,  3.1543, -2.1137, -3.5993,\n",
      "         3.9928, -2.2297], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1625], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.6660, -3.9139, -3.2240, -0.7062, -9.4153, -2.0082, -7.2761, -8.7618,\n",
      "        -1.1697, -7.3922], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.170\n",
      "activated x value: tensor([ 9.4683, -9.2759, -0.0259,  1.0489, -3.2927,  2.1491, -1.7937,  0.2857,\n",
      "         1.1720,  1.2705], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4699], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6003e-03, -1.8746e+01, -9.4958e+00, -8.4210e+00, -1.2763e+01,\n",
      "        -7.3208e+00, -1.1264e+01, -9.1841e+00, -8.2979e+00, -8.1994e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-3.4476e+00, -1.3532e+00,  5.6895e-01,  1.0279e+00, -1.5957e+00,\n",
      "        -1.2835e+00, -5.0288e+00,  7.2562e+00, -2.4434e-03,  4.1726e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3053], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7528,  -8.6585,  -6.7363,  -6.2773,  -8.9010,  -8.5888, -12.3340,\n",
      "         -0.0490,  -7.3077,  -3.1327], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.049\n",
      "activated x value: tensor([ 3.0717, -3.6842,  0.2739,  4.2905, -2.7967,  6.1702, -2.4563, -5.6887,\n",
      "         3.7753, -2.9447], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4265], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.3548, -10.1107,  -6.1527,  -2.1360,  -9.2232,  -0.2563,  -8.8829,\n",
      "        -12.1152,  -2.6512,  -9.3713], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -2.136\n",
      "activated x value: tensor([-6.0995, -1.0881,  0.0405,  1.0203,  1.6376,  0.9634, -2.6418, -0.4461,\n",
      "         3.0934,  3.3060], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1264], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2259,  -5.2145,  -4.0860,  -3.1061,  -2.4888,  -3.1630,  -6.7682,\n",
      "         -4.5725,  -1.0331,  -0.8204], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -3.106\n",
      "activated x value: tensor([-3.9200, -1.3462,  4.9663, -4.3198,  1.9915, -3.4084,  9.6819, -6.2889,\n",
      "         2.8996, -0.4727], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6924], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3612e+01, -1.1039e+01, -4.7261e+00, -1.4012e+01, -7.7009e+00,\n",
      "        -1.3101e+01, -1.0550e-02, -1.5981e+01, -6.7928e+00, -1.0165e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([10.6744, -7.6806,  0.6108,  0.8277, -4.1477,  5.6095, -0.4255, -4.3564,\n",
      "         3.2111, -3.3079], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6813], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9761e-03, -1.8362e+01, -1.0071e+01, -9.8537e+00, -1.4829e+01,\n",
      "        -5.0718e+00, -1.1107e+01, -1.5038e+01, -7.4702e+00, -1.3989e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-0.9481, -6.2852,  1.5706, -4.9646,  4.3684, -1.4671,  0.6931,  0.4590,\n",
      "         1.9803,  4.1673], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0735], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.0215, -11.3586,  -3.5028, -10.0381,  -0.7050,  -6.5405,  -4.3804,\n",
      "         -4.6145,  -3.0931,  -0.9061], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.906\n",
      "activated x value: tensor([-5.6746, -1.4170,  1.0736,  1.8848,  2.6365,  2.6643, -0.1551, -4.9237,\n",
      "         5.4995, -1.7544], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6479], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3225,  -7.0649,  -4.5742,  -3.7630,  -3.0114,  -2.9836,  -5.8030,\n",
      "        -10.5716,  -0.1484,  -7.4023], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.148\n",
      "activated x value: tensor([-2.1509, -2.4537, -0.3960, -0.3358, -0.2021,  1.6278,  6.2744, -5.8069,\n",
      "         1.7909,  1.4931], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3077], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.4586,  -8.7614,  -6.7037,  -6.6435,  -6.5098,  -4.6799,  -0.0333,\n",
      "        -12.1146,  -4.5168,  -4.8146], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([  9.9023, -10.9696,   2.1303,  -3.0383,  -3.3568,   7.2907,  -1.0291,\n",
      "         -7.6588,   6.7625,  -0.1095], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0131], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1108, -20.9827,  -7.8828, -13.0514, -13.3699,  -2.7224, -11.0422,\n",
      "        -17.6720,  -3.2507, -10.1226], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.111\n",
      "activated x value: tensor([ 2.9044, -7.8734, -8.6000,  4.2996, -1.9049,  8.8406, -2.6499, -1.5458,\n",
      "         3.4101,  3.7113], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8640], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.9596, -16.7373, -17.4640,  -4.5644, -10.7689,  -0.0234, -11.5138,\n",
      "        -10.4097,  -5.4539,  -5.1527], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([11.6015, -9.9353,  3.2702,  1.9142, -8.4336,  6.7457, -4.8835, -2.6314,\n",
      "         6.8762, -4.5604], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.6183], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6813e-02, -2.1554e+01, -8.3481e+00, -9.7041e+00, -2.0052e+01,\n",
      "        -4.8725e+00, -1.6502e+01, -1.4250e+01, -4.7421e+00, -1.6179e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([-5.5597, -1.8491,  9.0164,  1.7594,  0.1139, -7.0157,  5.4562, -2.1631,\n",
      "         0.2749,  0.5150], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0457], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.6054, -10.8948,  -0.0292,  -7.2862,  -8.9318, -16.0614,  -3.5895,\n",
      "        -11.2087,  -8.7708,  -8.5306], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.029\n",
      "activated x value: tensor([ 8.4951, -9.3379,  1.7100, -1.1078, -2.3588,  2.8126,  1.5969, -3.3349,\n",
      "         2.8260, -0.8287], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5042], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1381e-03, -1.7842e+01, -6.7942e+00, -9.6120e+00, -1.0863e+01,\n",
      "        -5.6916e+00, -6.9073e+00, -1.1839e+01, -5.6782e+00, -9.3329e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-2.1614, -5.0055, -1.1537, -2.4648,  5.0190, -0.8770,  0.1346,  0.0625,\n",
      "         2.3044,  5.1082], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7985], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9599, -10.8040,  -6.9522,  -8.2634,  -0.7795,  -6.6755,  -5.6639,\n",
      "         -5.7360,  -3.4941,  -0.6903], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.690\n",
      "activated x value: tensor([-2.6326, -4.0855, -2.6508,  1.0370,  3.2366,  0.1092, -4.0254,  1.1952,\n",
      "         0.9432,  7.7209], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7365], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3690, -11.8220, -10.3873,  -6.6995,  -4.4998,  -7.6272, -11.7619,\n",
      "         -6.5413,  -6.7933,  -0.0156], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([ 5.3209, -6.4160,  0.1062, -0.4551, -1.3711,  2.6738,  0.0239, -1.7008,\n",
      "         0.3449,  1.4555], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4292], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1083, -11.8452,  -5.3230,  -5.8843,  -6.8003,  -2.7554,  -5.4052,\n",
      "         -7.1300,  -5.0843,  -3.9736], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.108\n",
      "activated x value: tensor([10.2401, -7.7008,  5.1473,  1.8981, -8.7643,  2.6205, -2.5518, -0.9649,\n",
      "         2.2643, -2.6568], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2473], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.2069e-03, -1.7948e+01, -5.1000e+00, -8.3492e+00, -1.9012e+01,\n",
      "        -7.6268e+00, -1.2799e+01, -1.1212e+01, -7.9831e+00, -1.2904e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-2.7260, -8.7137,  0.3446, -0.9748,  3.5324, -1.1860, -2.7666,  4.4043,\n",
      "         0.1502,  7.3190], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3952], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1212, -16.1089,  -7.0506,  -8.3700,  -3.8628,  -8.5812, -10.1618,\n",
      "         -2.9909,  -7.2450,  -0.0762], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.076\n",
      "activated x value: tensor([ 0.8898, -1.0322,  2.3407, 11.4540, -7.8955,  5.1737, -3.5267, -5.6841,\n",
      "         2.2851, -3.5133], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.4561], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0566e+01, -1.2488e+01, -9.1155e+00, -2.1152e-03, -1.9352e+01,\n",
      "        -6.2824e+00, -1.4983e+01, -1.7140e+01, -9.1711e+00, -1.4969e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-6.4013,  7.3831, -0.2577,  1.5971, -3.6261,  0.7329, -0.8067, -0.8485,\n",
      "         2.1483,  0.1201], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3945], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3796e+01, -1.1369e-02, -7.6523e+00, -5.7974e+00, -1.1021e+01,\n",
      "        -6.6616e+00, -8.2012e+00, -8.2430e+00, -5.2462e+00, -7.2744e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-1.4039, -6.3688, -1.7068, -4.6012,  3.4500, -4.2322, -3.7243,  5.6537,\n",
      "         4.4038,  7.9556], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0866], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4905, -14.4554,  -9.7933, -12.6877,  -4.6365, -12.3187, -11.8109,\n",
      "         -2.4329,  -3.6828,  -0.1310], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.131\n",
      "activated x value: tensor([-6.0770, -1.4614,  7.9282, 11.8848, -5.2404, -0.3891, -4.1843, -2.2305,\n",
      "         2.6365, -2.1546], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.9039], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.9808, -13.3653,  -3.9757,  -0.0190, -17.1443, -12.2929, -16.0881,\n",
      "        -14.1344,  -9.2674, -14.0584], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-2.6243, -5.7037, -4.8884,  2.3594,  0.1526,  0.4403, -7.7265, 10.7967,\n",
      "         0.2912,  6.8379], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.8159], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.4402, -16.5195, -15.7042,  -8.4565, -10.6632, -10.3756, -18.5424,\n",
      "         -0.0192, -10.5247,  -3.9779], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-6.0020, -8.3486, -5.7175,  0.7823, 13.1413, -1.9659,  0.9448, -2.5146,\n",
      "         3.3546,  5.6239], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.1419], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9144e+01, -2.1490e+01, -1.8859e+01, -1.2360e+01, -6.0940e-04,\n",
      "        -1.5108e+01, -1.2197e+01, -1.5656e+01, -9.7873e+00, -7.5180e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-4.7446, -0.7772,  5.3301,  5.2428, -2.8687, -2.0520, -5.7278,  2.0754,\n",
      "         4.6474, -0.6843], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2326], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9772,  -7.0098,  -0.9026,  -0.9898,  -9.1013,  -8.2847, -11.9605,\n",
      "         -4.1572,  -1.5852,  -6.9169], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.903\n",
      "activated x value: tensor([-1.6303, -3.5974, -0.3006,  0.6060,  2.7937,  3.5997, -0.6878, -3.0868,\n",
      "         4.2523, -2.0566], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8416], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4719, -8.4390, -5.1422, -4.2356, -2.0479, -1.2419, -5.5294, -7.9284,\n",
      "        -0.5893, -6.8982], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.589\n",
      "activated x value: tensor([-3.1954,  0.1456, -1.6409,  3.2760, -1.5885,  1.9757, -4.4150,  0.3073,\n",
      "         3.8720,  1.1636], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4760], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.6715, -4.3304, -6.1170, -1.2001, -6.0646, -2.5004, -8.8911, -4.1687,\n",
      "        -0.6041, -3.3125], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.200\n",
      "activated x value: tensor([ 2.2741, -4.7232,  3.6333,  0.1839, -3.5282,  8.5732,  2.9351, -6.7489,\n",
      "         0.8836, -2.1582], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5864], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.3123e+00, -1.3310e+01, -4.9531e+00, -8.4025e+00, -1.2115e+01,\n",
      "        -1.3180e-02, -5.6513e+00, -1.5335e+01, -7.7028e+00, -1.0745e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([ 10.3329,  -5.4380,   5.4710,  -0.8993, -10.0143,  -0.2289,   1.7046,\n",
      "         -0.4710,   1.2296,  -0.7419], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3410], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0681e-03, -1.5779e+01, -4.8700e+00, -1.1240e+01, -2.0355e+01,\n",
      "        -1.0570e+01, -8.6364e+00, -1.0812e+01, -9.1114e+00, -1.1083e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([ 0.4001, -1.1288, -5.9950, -1.2850,  3.9271,  4.6928, -1.9267, -0.4301,\n",
      "         2.9539, -0.8622], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2062], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.8061,  -6.3351, -11.2012,  -6.4912,  -1.2791,  -0.5135,  -7.1329,\n",
      "         -5.6364,  -2.2524,  -6.0684], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.513\n",
      "activated x value: tensor([ 1.5692, -5.5916, -0.7318,  1.5902, -2.8667, -0.7535, -5.0690, 11.7873,\n",
      "        -0.3462,  1.2595], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7874], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0218e+01, -1.7379e+01, -1.2519e+01, -1.0197e+01, -1.4654e+01,\n",
      "        -1.2541e+01, -1.6856e+01, -1.1349e-04, -1.2134e+01, -1.0528e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 1.3758, -5.1352, -0.5786,  3.5743, -0.5311,  5.7014,  1.5746, -4.2158,\n",
      "         1.2805, -3.1969], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8538], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.4780, -10.9890,  -6.4324,  -2.2796,  -6.3849,  -0.1524,  -4.2793,\n",
      "        -10.0696,  -4.5733,  -9.0507], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.152\n",
      "activated x value: tensor([-0.6649, -3.3525, -1.6660,  6.5288, -1.3618,  5.5828, -2.2165, -7.1990,\n",
      "         4.6204, -0.8228], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9599], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6248, -10.3124,  -8.6259,  -0.4310,  -8.3216,  -1.3771,  -9.1763,\n",
      "        -14.1589,  -2.3394,  -7.7826], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.377\n",
      "activated x value: tensor([-1.3644, -6.0398,  1.3826, -6.2958, -1.0469, -0.2615,  5.1653, -2.7465,\n",
      "         8.5058,  2.2968], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5436], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.9080, -14.5834,  -7.1611, -14.8395,  -9.5905,  -8.8051,  -3.3784,\n",
      "        -11.2901,  -0.0378,  -6.2469], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.038\n",
      "activated x value: tensor([-4.5407,  5.5472, -2.4326, -0.0671, -4.7256,  2.3827, -2.1897,  1.4697,\n",
      "         3.0000,  1.8311], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7010], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2417,  -0.1538,  -8.1337,  -5.7682, -10.4267,  -3.3183,  -7.8907,\n",
      "         -4.2313,  -2.7011,  -3.8700], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -4.231\n",
      "activated x value: tensor([-4.8048,  1.0790, 10.5693,  3.1187, -3.0871, -3.8601,  3.6636, -5.8511,\n",
      "         1.4779, -1.4052], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.5711], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5376e+01, -9.4921e+00, -1.7776e-03, -7.4524e+00, -1.3658e+01,\n",
      "        -1.4431e+01, -6.9075e+00, -1.6422e+01, -9.0933e+00, -1.1976e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-2.4048, -4.5350,  8.8397,  2.0584, -1.4349, -2.9096, -0.6269,  1.7591,\n",
      "        -0.9827,  0.0262], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8420], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1247e+01, -1.3377e+01, -2.3108e-03, -6.7836e+00, -1.0277e+01,\n",
      "        -1.1752e+01, -9.4689e+00, -7.0829e+00, -9.8246e+00, -8.8157e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 1.5325, -6.8268, -2.0037, -3.9583, -0.8523,  7.8953, -2.1252,  2.9767,\n",
      "         3.3095,  0.7992], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9154], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.3829, -14.7422,  -9.9191, -11.8737,  -8.7678,  -0.0201, -10.0406,\n",
      "         -4.9387,  -4.6059,  -7.1162], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-1.1175, -8.7328, -0.6099, -4.2305,  4.9014,  0.6402, -0.5302,  2.4531,\n",
      "         2.6952,  3.2198], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2434], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.3609, -13.9762,  -5.8533,  -9.4739,  -0.3419,  -4.6032,  -5.7735,\n",
      "         -2.7903,  -2.5482,  -2.0236], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.342\n",
      "activated x value: tensor([-1.9453, -5.0776,  9.1011, 14.6422, -4.1804,  0.5058, -5.6993, -7.5155,\n",
      "         2.5643, -3.4643], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.6461], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6591e+01, -1.9724e+01, -5.5450e+00, -3.9215e-03, -1.8826e+01,\n",
      "        -1.4140e+01, -2.0345e+01, -2.2162e+01, -1.2082e+01, -1.8110e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-7.0404,  8.2722, -0.1692,  2.1781, -3.7880, -0.9165, -0.9727,  0.1814,\n",
      "         1.5234,  1.5401], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2775], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5318e+01, -5.3329e-03, -8.4467e+00, -6.0994e+00, -1.2066e+01,\n",
      "        -9.1940e+00, -9.2502e+00, -8.0961e+00, -6.7541e+00, -6.7374e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-3.5700,  1.4701,  3.2264,  0.3430, -4.0875,  1.4374,  2.6215, -4.7081,\n",
      "         4.8907, -0.9744], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2061], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.7762, -3.7360, -1.9797, -4.8631, -9.2937, -3.7687, -2.5846, -9.9142,\n",
      "        -0.3155, -6.1805], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.315\n",
      "activated x value: tensor([-2.5149, -0.9242,  2.5390, -3.5890, -0.1500,  2.5801,  2.1089, -3.1981,\n",
      "         4.4408, -1.4446], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7924], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.3073, -5.7166, -2.2534, -8.3814, -4.9424, -2.2123, -2.6835, -7.9905,\n",
      "        -0.3516, -6.2370], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.352\n",
      "activated x value: tensor([-7.7666,  8.2975,  1.0618,  1.1528, -3.7240, -1.6767,  0.5326,  0.4125,\n",
      "         1.4001,  0.9852], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3015], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6068e+01, -4.0331e-03, -7.2397e+00, -7.1487e+00, -1.2025e+01,\n",
      "        -9.9782e+00, -7.7689e+00, -7.8890e+00, -6.9014e+00, -7.3163e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 7.4001, -8.7350,  0.1239,  0.5087, -5.6221,  1.3515,  1.2883,  1.9712,\n",
      "         1.8808,  1.9225], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4188], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0187, -16.1538,  -7.2949,  -6.9102, -13.0409,  -6.0673,  -6.1305,\n",
      "         -5.4476,  -5.5380,  -5.4963], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-6.0168,  0.3948,  5.7612,  1.0806, -0.8006, -2.2572,  1.7322, -0.3474,\n",
      "         0.6483, -0.6320], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8037], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8205,  -5.4089,  -0.0425,  -4.7231,  -6.6044,  -8.0609,  -4.0715,\n",
      "         -6.1511,  -5.1555,  -6.4357], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([  8.6438,  -7.5844,   4.4801,   7.2429, -10.2393,   2.9677,  -9.1377,\n",
      "          1.6486,   4.5531,  -2.9288], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8930], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.2492, -16.4774,  -4.4129,  -1.6502, -19.1323,  -5.9253, -18.0307,\n",
      "         -7.2444,  -4.3399, -11.8218], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.249\n",
      "activated x value: tensor([-3.8369, -1.0849,  2.0693,  0.1091,  0.2089, -1.5088, -0.8519,  5.1306,\n",
      "        -0.3680,  0.2533], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2061], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.0429, -6.2909, -3.1367, -5.0970, -4.9972, -6.7148, -6.0580, -0.0755,\n",
      "        -5.5740, -4.9528], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.075\n",
      "activated x value: tensor([-0.9648, -4.3535,  4.4847, -0.2994, -6.0489, -1.7077, -0.6219,  5.2480,\n",
      "         1.9417,  1.2557], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6739], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([ -6.6387, -10.0275,  -1.1893,  -5.9734, -11.7228,  -7.3816,  -6.2958,\n",
      "         -0.4259,  -3.7323,  -4.4182], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.189\n",
      "activated x value: tensor([ 0.3631, -4.4946, 11.5786,  2.5567,  0.4941,  1.1416,  3.1653, -6.6065,\n",
      "        -0.6153, -7.2224], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5791], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1216e+01, -1.6074e+01, -4.0531e-04, -9.0223e+00, -1.1085e+01,\n",
      "        -1.0437e+01, -8.4137e+00, -1.8186e+01, -1.2194e+01, -1.8801e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-0.4188, -5.8249, -2.2647, -5.4871,  8.8439,  2.2517,  3.2832, -3.3017,\n",
      "         0.3404,  2.8385], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8519], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2707e+00, -1.4677e+01, -1.1117e+01, -1.4339e+01, -7.9689e-03,\n",
      "        -6.6002e+00, -5.5687e+00, -1.2154e+01, -8.5116e+00, -6.0134e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-0.4351, -5.0507, -1.5502,  3.2028,  0.1980,  5.8500, -2.5333, -3.3651,\n",
      "         2.7694,  1.0166], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9732], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.4083, -11.0239,  -7.5234,  -2.7704,  -5.7752,  -0.1232,  -8.5065,\n",
      "         -9.3383,  -3.2038,  -4.9566], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.123\n",
      "activated x value: tensor([11.4285, -8.3899,  2.8339, -0.6174, -5.7168,  3.3091, -0.1707, -4.4969,\n",
      "         3.9219, -2.1492], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.4296], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0481e-03, -1.9820e+01, -8.5957e+00, -1.2047e+01, -1.7146e+01,\n",
      "        -8.1204e+00, -1.1600e+01, -1.5926e+01, -7.5077e+00, -1.3579e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-0.8909, -4.0550,  0.1245, -0.1047,  5.6878, -0.6563,  0.5188, -1.5748,\n",
      "        -0.8078,  2.8561], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7619], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6528, -9.8169, -5.6374, -5.8666, -0.0741, -6.4182, -5.2431, -7.3367,\n",
      "        -6.5697, -2.9058], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.074\n",
      "activated x value: tensor([-2.5052, -2.5952,  0.3558,  5.3361, -2.6867,  1.2140, -3.8830,  0.1041,\n",
      "         3.5048,  2.9974], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5878], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0931, -8.1831, -5.2321, -0.2517, -8.2746, -4.3739, -9.4708, -5.4838,\n",
      "        -2.0831, -2.5904], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.252\n",
      "activated x value: tensor([-1.1096, -5.2444,  1.8600, -4.5701,  2.4796, -3.1846, -0.1607,  1.9772,\n",
      "         0.7043,  6.0831], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1468], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.2564, -11.3912,  -4.2868, -10.7169,  -3.6672,  -9.3314,  -6.3075,\n",
      "         -4.1696,  -5.4425,  -0.0637], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.064\n",
      "activated x value: tensor([-5.6619,  3.2771, -1.6665,  0.6284,  0.8274, -0.9128, -0.9600,  2.0383,\n",
      "         0.3200,  2.5213], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9728], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.6347, -0.6958, -5.6393, -3.3445, -3.1454, -4.8857, -4.9328, -1.9346,\n",
      "        -3.6528, -1.4516], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.452\n",
      "activated x value: tensor([-2.7434,  4.7817,  3.3039,  6.5582, -6.2890,  0.2474, -3.6734, -2.7170,\n",
      "         2.5839, -2.1728], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7643], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.5077,  -1.9825,  -3.4604,  -0.2061, -13.0532,  -6.5169, -10.4376,\n",
      "         -9.4813,  -4.1804,  -8.9370], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.206\n",
      "activated x value: tensor([-2.4490, -3.0403, -2.1169,  2.7857,  4.5762, -0.2349, -1.4690, -2.1294,\n",
      "        -0.0698,  5.0747], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6190], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0680, -8.6593, -7.7359, -2.8333, -1.0428, -5.8538, -7.0880, -7.7484,\n",
      "        -5.6888, -0.5443], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.043\n",
      "activated x value: tensor([10.0146, -5.6528,  2.9444,  1.9554, -9.5440,  4.9596, -0.5978,  1.0007,\n",
      "         0.1528, -3.2350], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0223], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7143e-03, -1.5675e+01, -7.0779e+00, -8.0669e+00, -1.9566e+01,\n",
      "        -5.0627e+00, -1.0620e+01, -9.0216e+00, -9.8695e+00, -1.3257e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-0.0538, -3.5529, -2.8144,  8.2565, -2.1379,  4.0361, -4.3961, -3.7594,\n",
      "         2.1371,  1.3751], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2746], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3283, -11.8275, -11.0890,  -0.0181, -10.4125,  -4.2385, -12.6706,\n",
      "        -12.0340,  -6.1374,  -6.8995], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([ -1.6644, -10.2709,  -2.1731,  -0.3250,   1.8343,   3.6553,  -3.8023,\n",
      "         -0.0117,   2.8233,   9.4639], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4689], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1133e+01, -1.9740e+01, -1.1642e+01, -9.7939e+00, -7.6346e+00,\n",
      "        -5.8135e+00, -1.3271e+01, -9.4805e+00, -6.6456e+00, -4.9391e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([ 2.5220, -6.5490,  0.2461,  1.0795, -0.4694,  4.3754, -2.5331, -5.4788,\n",
      "         5.5665,  0.5802], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8865], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.3645, -12.4355,  -5.6404,  -4.8070,  -6.3560,  -1.5111,  -8.4197,\n",
      "        -11.3653,  -0.3201,  -5.3063], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.320\n",
      "activated x value: tensor([-0.9292, -8.7510,  1.7891,  2.6424,  3.1829, -3.4878, -3.1852,  2.8861,\n",
      "        -1.2718,  6.6122], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6933], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6225, -15.4443,  -4.9042,  -4.0508,  -3.5103, -10.1811,  -9.8785,\n",
      "         -3.8071,  -7.9650,  -0.0810], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([-7.0371, -0.0668, -0.0356,  5.0092, -4.0659,  3.3088, -1.4741, -2.0128,\n",
      "         5.8081,  0.8283], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2435], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.2806,  -6.3103,  -6.2791,  -1.2343, -10.3095,  -2.9348,  -7.7176,\n",
      "         -8.2563,  -0.4355,  -5.4152], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.435\n",
      "activated x value: tensor([-0.6601, -3.3447,  9.1345,  2.7725, -7.8803, -3.2743,  0.9136,  1.7935,\n",
      "         0.0601, -0.3138], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1374], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.7975e+00, -1.2482e+01, -2.8963e-03, -6.3648e+00, -1.7018e+01,\n",
      "        -1.2412e+01, -8.2237e+00, -7.3439e+00, -9.0772e+00, -9.4511e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 1.7866e+00, -1.7633e+00,  1.1788e-03, -1.6731e+00, -3.4666e+00,\n",
      "         2.1147e+00, -7.5645e-01,  1.9840e+00, -9.2640e-01,  2.6200e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6249], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8383, -5.3882, -3.6237, -5.2980, -7.0915, -1.5102, -4.3814, -1.6409,\n",
      "        -4.5513, -1.0049], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.510\n",
      "activated x value: tensor([ 0.7623, -5.0143,  7.3723, -1.3338,  0.7057, -2.6378,  1.0703, -0.9289,\n",
      "         0.5425, -1.0914], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3785], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6163e+00, -1.2393e+01, -6.1879e-03, -8.7123e+00, -6.6729e+00,\n",
      "        -1.0016e+01, -6.3082e+00, -8.3074e+00, -6.8360e+00, -8.4699e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-8.0758,  8.2125, -0.2993,  2.6932, -3.3826, -1.3570, -0.4136,  0.0296,\n",
      "         2.0858,  1.3572], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2205], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6296e+01, -7.9527e-03, -8.5198e+00, -5.5273e+00, -1.1603e+01,\n",
      "        -9.5775e+00, -8.6341e+00, -8.1909e+00, -6.1347e+00, -6.8633e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-5.5401, -5.2474, -2.4909, -0.2088,  8.4656,  1.4420, -0.8344, -2.7545,\n",
      "         1.7015,  5.7255], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5304], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.0705, -13.7778, -11.0212,  -8.7391,  -0.0648,  -7.0883,  -9.3648,\n",
      "        -11.2849,  -6.8289,  -2.8049], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.065\n",
      "activated x value: tensor([-2.7243, -2.6215, -0.3100,  0.9876, -0.8285,  0.1985, -3.4975,  5.9555,\n",
      "        -0.4286,  3.4562], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0484], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.7727, -8.6699, -6.3585, -5.0608, -6.8770, -5.8499, -9.5460, -0.0930,\n",
      "        -6.4770, -2.5923], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.093\n",
      "activated x value: tensor([-0.3473, -9.3310, -0.4018, -4.8125,  4.0996, -5.3224, -1.3949,  8.5033,\n",
      "         0.9187,  7.2732], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7697], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.1170, -18.1007,  -9.1715, -13.5823,  -4.6701, -14.0922, -10.1646,\n",
      "         -0.2665,  -7.8510,  -1.4966], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.497\n",
      "activated x value: tensor([ 9.3917, -5.4195,  8.0184,  5.7524, -7.9757,  2.2949, -0.1469, -4.5792,\n",
      "        -0.9217, -5.6769], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6389], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.2472, -15.0584,  -1.6205,  -3.8865, -17.6146,  -7.3440,  -9.7858,\n",
      "        -14.2182, -10.5606, -15.3158], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.247\n",
      "activated x value: tensor([ 7.0423, -6.8897,  1.9470, -2.5474, -3.3710,  2.9998, -1.6227, -1.3526,\n",
      "         3.8219, -0.3056], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1050], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0628, -13.9948,  -5.1580,  -9.6524, -10.4760,  -4.1053,  -8.7277,\n",
      "         -8.4576,  -3.2831,  -7.4106], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.063\n",
      "activated x value: tensor([ 1.7848, -4.5067,  2.5899, -1.6035,  1.1029,  3.7300, -2.8264, -2.7960,\n",
      "         1.4350,  1.6839], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3027], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.5179, -8.8093, -1.7128, -5.9062, -3.1997, -0.5727, -7.1291, -7.0986,\n",
      "        -2.8676, -2.6188], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.573\n",
      "activated x value: tensor([-0.5146, -9.7309,  0.2649,  4.8181, -4.2207, -1.9234, -6.5983, 12.5398,\n",
      "        -0.1357,  4.7644], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.5407], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3055e+01, -2.2272e+01, -1.2276e+01, -7.7226e+00, -1.6761e+01,\n",
      "        -1.4464e+01, -1.9139e+01, -8.7357e-04, -1.2676e+01, -7.7764e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 3.0584, -1.7805, -5.3907,  0.0477, -0.4105,  7.4207, -4.8212,  2.1288,\n",
      "         2.2401, -3.0816], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4450], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.3866,  -9.2255, -12.8357,  -7.3973,  -7.8555,  -0.0243, -12.2662,\n",
      "         -5.3162,  -5.2049, -10.5267], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([ 1.3027, -4.7513, 12.1822,  2.2031, -5.6616,  0.9382, -3.3200, -2.3576,\n",
      "         5.3399, -7.3940], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.1833], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0881e+01, -1.6935e+01, -1.1463e-03, -9.9802e+00, -1.7845e+01,\n",
      "        -1.1245e+01, -1.5503e+01, -1.4541e+01, -6.8435e+00, -1.9577e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-7.7117,  3.5799, -2.3144, -0.2487,  1.3963, -0.8371, -3.3012,  5.3312,\n",
      "         1.6652,  1.9609], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5620], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.2737,  -1.9821,  -7.8764,  -5.8107,  -4.1657,  -6.3990,  -8.8632,\n",
      "         -0.2308,  -3.8968,  -3.6011], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.231\n",
      "activated x value: tensor([-1.6891,  0.2911, -1.4940, -0.4797, -2.8673, -0.2624, -4.4954,  4.0716,\n",
      "         3.6567,  3.3406], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8584], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.5476, -4.5673, -6.3524, -5.3381, -7.7257, -5.1208, -9.3539, -0.7869,\n",
      "        -1.2017, -1.5179], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.787\n",
      "activated x value: tensor([-0.5238, -2.2706, -1.7451,  9.2904, -2.9140,  4.5377, -5.1636, -2.7842,\n",
      "         2.7820, -1.8301], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.3006], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8244e+00, -1.1571e+01, -1.1046e+01, -1.0173e-02, -1.2215e+01,\n",
      "        -4.7629e+00, -1.4464e+01, -1.2085e+01, -6.5186e+00, -1.1131e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-1.5114, -2.9999,  1.5530, -4.1702,  1.6760,  1.9268,  7.3615, -2.2403,\n",
      "        -1.3993, -1.0144], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3728], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8842e+00, -1.0373e+01, -5.8198e+00, -1.1543e+01, -5.6968e+00,\n",
      "        -5.4460e+00, -1.1331e-02, -9.6131e+00, -8.7721e+00, -8.3872e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-6.0616,  2.0874,  1.8599, -0.7389, -0.1073, -3.5844,  0.7028,  5.5357,\n",
      "         0.3705,  0.7442], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6169], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.6785,  -3.5296,  -3.7570,  -6.3558,  -5.7243,  -9.2014,  -4.9141,\n",
      "         -0.0813,  -5.2464,  -4.8727], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([ 1.8864, -3.5221, -0.4247,  0.4660, -0.6743,  6.6116, -1.1182, -4.9320,\n",
      "         2.7249, -0.9990], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6451], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.7587, -10.1672,  -7.0698,  -6.1791,  -7.3193,  -0.0335,  -7.7633,\n",
      "        -11.5770,  -3.9202,  -7.6441], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.034\n",
      "activated x value: tensor([ 1.5046e+00,  1.2490e+00, -3.0177e-03,  1.7209e+00, -4.0858e+00,\n",
      "         3.6340e+00, -3.7774e+00,  4.7455e-02,  1.0019e+00, -4.4200e-01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0412], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.5367, -2.7922, -4.0442, -2.3203, -8.1270, -0.4072, -7.8186, -3.9938,\n",
      "        -3.0393, -4.4832], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.407\n",
      "activated x value: tensor([-6.5577, -0.7012, -2.6010,  1.6778,  1.6943,  1.3133, -1.7918,  0.6659,\n",
      "         1.1611,  5.4375], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5225], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.0802,  -6.2237,  -8.1235,  -3.8447,  -3.8282,  -4.2092,  -7.3143,\n",
      "         -4.8566,  -4.3614,  -0.0850], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.085\n",
      "activated x value: tensor([ 1.6605, -3.9395, -2.5009, -2.0258,  3.0836,  0.7668, -2.1966,  3.6664,\n",
      "        -0.6216,  2.5356], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4051], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.7446, -8.3446, -6.9061, -6.4309, -1.3215, -3.6383, -6.6017, -0.7387,\n",
      "        -5.0267, -1.8695], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.739\n",
      "activated x value: tensor([-3.4334,  4.8438,  3.5996, -0.5237,  0.3327, -3.4150,  0.9914, -4.5449,\n",
      "         5.6056, -3.9814], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0874], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.5207,  -1.2436,  -2.4878,  -6.6110,  -5.7546,  -9.5024,  -5.0960,\n",
      "        -10.6323,  -0.4817, -10.0688], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -1.244\n",
      "activated x value: tensor([ 1.3947, -6.2544, -2.9921, -2.2117,  3.5353,  1.6882,  0.2521, -0.0142,\n",
      "         0.2992,  4.4563], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8956], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.5009, -11.1500,  -7.8877,  -7.1073,  -1.3603,  -3.2074,  -4.6435,\n",
      "         -4.9098,  -4.5964,  -0.4393], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.360\n",
      "activated x value: tensor([ 9.1812, -4.4640, -1.4058,  0.7626, -5.6078,  2.8336,  1.8143, -1.8299,\n",
      "         0.4340, -1.5299], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1840], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.8238e-03, -1.3648e+01, -1.0590e+01, -8.4214e+00, -1.4792e+01,\n",
      "        -6.3504e+00, -7.3697e+00, -1.1014e+01, -8.7500e+00, -1.0714e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 11.1568, -11.7940,  -5.1140,   0.3625,  -1.7494,   6.2452,   1.0166,\n",
      "         -3.2858,   2.5967,   1.8716], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1645], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.6790e-03, -2.2958e+01, -1.6278e+01, -1.0802e+01, -1.2914e+01,\n",
      "        -4.9193e+00, -1.0148e+01, -1.4450e+01, -8.5678e+00, -9.2929e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -9.293\n",
      "activated x value: tensor([-4.0138, -6.4199, -4.3675, -1.3827,  3.8474,  1.2484, -1.2892,  0.9406,\n",
      "         3.7100,  8.6476], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6641], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.6778, -15.0840, -13.0316, -10.0468,  -4.8167,  -7.4157,  -9.9533,\n",
      "         -7.7234,  -4.9541,  -0.0164], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-5.4366, -4.0349, -2.1903, -0.3955,  7.7380,  0.7136,  0.9971, -3.3286,\n",
      "         1.3753,  3.0804], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7515], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.1881, -11.7864,  -9.9419,  -8.1471,  -0.0136,  -7.0379,  -6.7545,\n",
      "        -11.0801,  -6.3762,  -4.6712], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([ 1.6829, -5.4143,  7.1320,  5.1811, -1.3849, -3.5798,  3.4443, -2.2350,\n",
      "        -1.9340, -2.0267], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2907], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6078, -12.7050,  -0.1587,  -2.1097,  -8.6756, -10.8705,  -3.8464,\n",
      "         -9.5257,  -9.2247,  -9.3174], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.159\n",
      "activated x value: tensor([-4.2352, -2.0709,  0.1163,  6.7968, -1.0539,  3.1437, -3.8333, -1.2068,\n",
      "         2.8019,  0.7954], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8446], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.0798,  -8.9155,  -6.7283,  -0.0478,  -7.8984,  -3.7009, -10.6779,\n",
      "         -8.0514,  -4.0426,  -6.0492], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.048\n",
      "activated x value: tensor([-5.9647,  1.2309, -3.9388,  0.4643,  2.7296,  1.5127, -2.7853,  0.8339,\n",
      "         3.8829,  1.6422], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3944], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3591,  -3.1635,  -8.3332,  -3.9301,  -1.6648,  -2.8817,  -7.1797,\n",
      "         -3.5605,  -0.5115,  -2.7522], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.665\n",
      "activated x value: tensor([ 3.3904, -4.4781, -3.5859, -1.1454, -0.0613,  6.0215,  2.4702, -5.1698,\n",
      "         1.8995,  0.9879], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1406], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -2.7503, -10.6187,  -9.7265,  -7.2860,  -6.2019,  -0.1192,  -3.6704,\n",
      "        -11.3105,  -4.2412,  -5.1527], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.119\n",
      "activated x value: tensor([-7.0966,  7.6488,  1.1089,  2.5647, -3.8240, -2.2241, -0.5199,  1.0191,\n",
      "         1.1617,  1.1620], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6611], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4758e+01, -1.2277e-02, -6.5521e+00, -5.0963e+00, -1.1485e+01,\n",
      "        -9.8852e+00, -8.1809e+00, -6.6419e+00, -6.4994e+00, -6.4990e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-1.5111, -1.9741,  1.9947, -0.6488, -0.6722,  1.2889, -0.4809, -2.8711,\n",
      "         5.2391,  0.0172], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3111], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8222, -7.2852, -3.3163, -5.9599, -5.9832, -4.0221, -5.7919, -8.1821,\n",
      "        -0.0720, -5.2938], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.072\n",
      "activated x value: tensor([-3.2235,  1.0286,  7.9570,  2.3783, -3.0488, -1.6405,  0.4934, -5.7919,\n",
      "         3.7815, -2.4240], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9776], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2011,  -6.9490,  -0.0206,  -5.5993, -11.0264,  -9.6181,  -7.4842,\n",
      "        -13.7695,  -4.1961, -10.4016], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -5.599\n",
      "activated x value: tensor([ -5.3865,  -1.4416,   3.3102,  -0.4471,  -0.7337,   1.6921,   9.4531,\n",
      "        -10.1734,   4.3643,  -0.4096], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4620], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4848e+01, -1.0904e+01, -6.1517e+00, -9.9091e+00, -1.0196e+01,\n",
      "        -7.7699e+00, -8.8596e-03, -1.9635e+01, -5.0977e+00, -9.8716e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-6.0509,  6.7239,  1.1229,  1.7048, -3.2048, -2.5484, -0.3419,  1.1245,\n",
      "         1.8789,  0.1727], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7479], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7988,  -0.0240,  -5.6250,  -5.0431,  -9.9527,  -9.2963,  -7.0898,\n",
      "         -5.6235,  -4.8690,  -6.5752], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-0.9163, -8.7529,  2.3928,  3.9555, -2.6538, -2.2988, -5.2634,  9.2718,\n",
      "        -1.0228,  3.8236], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2821], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0198e+01, -1.8035e+01, -6.8893e+00, -5.3266e+00, -1.1936e+01,\n",
      "        -1.1581e+01, -1.4545e+01, -1.0279e-02, -1.0305e+01, -5.4585e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([ 1.8469, -6.1655,  9.1955,  4.4022, -1.1164, -1.9673,  2.5827, -3.8987,\n",
      "        -1.0112, -4.4798], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2058], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.3589e+00, -1.5371e+01, -1.0306e-02, -4.8035e+00, -1.0322e+01,\n",
      "        -1.1173e+01, -6.6230e+00, -1.3104e+01, -1.0217e+01, -1.3686e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-4.2273, -0.9041,  1.4903,  0.9372, -0.6371,  2.6360,  4.9887, -6.9488,\n",
      "         2.9290, -0.4733], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2363], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4637,  -6.1404,  -3.7461,  -4.2991,  -5.8734,  -2.6003,  -0.2476,\n",
      "        -12.1851,  -2.3074,  -5.7096], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.248\n",
      "activated x value: tensor([ 0.8261, -3.1687,  1.1895, -3.5245,  0.1055,  1.6903,  7.1216, -3.3469,\n",
      "         0.1832,  0.0692], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1332], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.3071, -10.3019,  -5.9437, -10.6577,  -7.0278,  -5.4429,  -0.0116,\n",
      "        -10.4801,  -6.9500,  -7.0640], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-0.2564, -3.6954,  1.5892,  3.9336, -3.3773,  1.7217, -0.6047, -5.7277,\n",
      "         5.6067,  1.3158], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8259], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.0823,  -9.5212,  -4.2366,  -1.8922,  -9.2032,  -4.1041,  -6.4305,\n",
      "        -11.5535,  -0.2191,  -4.5100], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.219\n",
      "activated x value: tensor([-3.8336,  0.3235,  2.0444,  0.1770, -0.3925,  0.9165,  5.0440, -4.8096,\n",
      "         1.7203, -0.6206], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1632], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9968, -4.8397, -3.1188, -4.9862, -5.5557, -4.2466, -0.1192, -9.9728,\n",
      "        -3.4429, -5.7838], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.119\n",
      "activated x value: tensor([-2.4764,  5.1732,  1.9654,  0.8016, -2.8571, -0.5533, -0.4435, -1.7558,\n",
      "         2.0229, -1.5295], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2738], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7502, -0.1006, -3.3084, -4.4722, -8.1309, -5.8271, -5.7173, -7.0296,\n",
      "        -3.2509, -6.8033], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.101\n",
      "activated x value: tensor([-6.2440,  2.4378,  7.3613,  2.7304, -6.4645,  1.2102,  2.6891, -3.8269,\n",
      "         1.9548, -3.0697], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([7.3938], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.6378,  -4.9560,  -0.0325,  -4.6634, -13.8583,  -6.1836,  -4.7046,\n",
      "        -11.2207,  -5.4390, -10.4635], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([ 2.8495, -5.6295,  0.1616,  0.2945, -1.6002,  9.8880, -1.5217, -3.3889,\n",
      "         1.9015, -2.8207], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8894], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.0399e+00, -1.5519e+01, -9.7278e+00, -9.5949e+00, -1.1490e+01,\n",
      "        -1.3704e-03, -1.1411e+01, -1.3278e+01, -7.9879e+00, -1.2710e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-6.4643,  0.6344,  2.5973,  6.9159, -1.6474, -0.9155, -3.8126, -0.6001,\n",
      "         1.3818,  0.8476], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9383], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.4026,  -6.3039,  -4.3410,  -0.0224,  -8.5856,  -7.8538, -10.7508,\n",
      "         -7.5383,  -5.5565,  -6.0907], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.022\n",
      "activated x value: tensor([-2.8348, -1.2928, -2.8382,  0.0278,  5.2368,  0.3403,  0.3771, -0.3489,\n",
      "         0.3901,  1.4715], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2928], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.1275, -6.5856, -8.1310, -5.2650, -0.0559, -4.9525, -4.9157, -5.6416,\n",
      "        -4.9026, -3.8212], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.056\n",
      "activated x value: tensor([-4.4396, -2.1019,  9.5261,  5.8288,  0.1871, -1.9341,  1.6074, -7.3244,\n",
      "        -0.7572, -1.2602], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5511], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.9907, -11.6530,  -0.0250,  -3.7223,  -9.3640, -11.4852,  -7.9437,\n",
      "        -16.8755, -10.3083, -10.8113], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([ 1.9847,  0.3243,  1.6213,  6.5933, -5.0022,  1.9387, -3.0292, -2.2787,\n",
      "         1.7123, -4.3789], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6288], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.6441,  -6.3045,  -5.0075,  -0.0355, -11.6310,  -4.6901,  -9.6580,\n",
      "         -8.9075,  -4.9165, -11.0077], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.035\n",
      "activated x value: tensor([-2.9909, -8.8159,  4.0229,  0.6225,  3.0575, -8.4411, -2.7949,  7.4720,\n",
      "        -0.5842,  7.2110], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0684], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.0593, -16.8843,  -4.0455,  -7.4459,  -5.0109, -16.5095, -10.8633,\n",
      "         -0.5964,  -8.6526,  -0.8574], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.857\n",
      "activated x value: tensor([10.2431, -9.0476,  1.5376,  0.7858, -6.3839,  3.8077, -6.3260,  0.3322,\n",
      "         4.6156,  0.8983], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2487], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.5666e-03, -1.9296e+01, -8.7111e+00, -9.4629e+00, -1.6633e+01,\n",
      "        -6.4410e+00, -1.6575e+01, -9.9165e+00, -5.6331e+00, -9.3504e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-4.5566, -4.3720, -2.9955, -6.1134, 10.0344, -1.9632,  2.8004,  2.0806,\n",
      "         1.6320,  3.3692], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0369], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4594e+01, -1.4409e+01, -1.3032e+01, -1.6150e+01, -2.5778e-03,\n",
      "        -1.2000e+01, -7.2365e+00, -7.9564e+00, -8.4049e+00, -6.6677e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-1.3383,  0.8949,  1.8939,  4.2090, -4.9756,  0.4923,  2.6500, -4.4305,\n",
      "         1.6551,  0.0496], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5925], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9307, -3.6975, -2.6986, -0.3835, -9.5681, -4.1001, -1.9424, -9.0230,\n",
      "        -2.9373, -4.5429], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.383\n",
      "activated x value: tensor([-1.8385, -1.1376,  1.9375,  0.8672, -0.6109,  0.1966,  2.0484, -7.0974,\n",
      "         6.9272, -2.0504], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9461], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.7846,  -8.0837,  -5.0087,  -6.0789,  -7.5570,  -6.7495,  -4.8977,\n",
      "        -14.0435,  -0.0189,  -8.9965], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-5.5719, -4.5175, -4.7366,  0.7097,  3.9457,  0.3842, -2.2662,  2.1347,\n",
      "         1.6358,  8.4315], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4464], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.0183, -12.9640, -13.1831,  -7.7368,  -4.5007,  -8.0622, -10.7126,\n",
      "         -6.3118,  -6.8107,  -0.0149], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-4.4494, -5.2539, -1.2065, -1.8901,  4.2659, -3.5316, -1.6836,  4.5414,\n",
      "         1.7600,  7.3474], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4523], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.9017, -12.7062,  -8.6587,  -9.3424,  -3.1864, -10.9839,  -9.1359,\n",
      "         -2.9109,  -5.6922,  -0.1048], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.105\n",
      "activated x value: tensor([-4.5160, -2.5107,  0.6884,  7.3411, -4.3010,  3.0663, -5.2326,  3.3924,\n",
      "         0.5291,  1.8644], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3802], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8961,  -9.8908,  -6.6917,  -0.0391, -11.6812,  -4.3139, -12.6127,\n",
      "         -3.9878,  -6.8511,  -5.5158], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.039\n",
      "activated x value: tensor([-4.4963,  0.3300, -3.2630,  1.2103, -0.3561,  0.2581, -1.9828,  4.2297,\n",
      "         0.3834,  3.5626], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7216], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2179, -4.3915, -7.9845, -3.5112, -5.0777, -4.4635, -6.7044, -0.4919,\n",
      "        -4.3382, -1.1590], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.159\n",
      "activated x value: tensor([-0.7577, -3.1831,  3.1388, -5.4697,  1.3143,  1.6232,  7.7840, -3.2964,\n",
      "         1.6077, -2.4937], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7995], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.5571, -10.9825,  -4.6607, -13.2692,  -6.4851,  -6.1763,  -0.0155,\n",
      "        -11.0959,  -6.1918, -10.2932], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-2.7589, -5.9257, -0.5333, -0.8175,  9.3504, -1.2034,  1.2876, -2.2655,\n",
      "        -1.3293,  3.5422], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.3539], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2113e+01, -1.5280e+01, -9.8872e+00, -1.0171e+01, -3.4647e-03,\n",
      "        -1.0557e+01, -8.0663e+00, -1.1619e+01, -1.0683e+01, -5.8117e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-8.5946, -2.3319, -3.8750,  0.2251, 10.2260,  0.5072,  0.4481,  0.6840,\n",
      "        -0.7360,  4.0358], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2283], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8823e+01, -1.2560e+01, -1.4103e+01, -1.0003e+01, -2.3022e-03,\n",
      "        -9.7212e+00, -9.7802e+00, -9.5443e+00, -1.0964e+01, -6.1925e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-0.6197, -9.9684, -2.5386,  0.9009,  9.0562,  3.2633, -0.7083, -5.0833,\n",
      "         0.6139,  4.5486], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0708], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.6905e+00, -1.9039e+01, -1.1609e+01, -8.1699e+00, -1.4600e-02,\n",
      "        -5.8075e+00, -9.7791e+00, -1.4154e+01, -8.4569e+00, -4.5222e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-3.5959,  0.5358,  1.4581, -0.0099, -1.2214,  1.7439,  7.4177, -6.3105,\n",
      "         2.8420, -1.5111], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4358], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.0317,  -6.9000,  -5.9777,  -7.4458,  -8.6572,  -5.6919,  -0.0181,\n",
      "        -13.7463,  -4.5938,  -8.9469], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([ 4.2183, -2.7626,  6.2786,  0.8519, -5.4796,  4.1542,  5.2399, -8.7647,\n",
      "         0.8393, -4.9424], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7547], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -2.5364,  -9.5173,  -0.4760,  -5.9028, -12.2343,  -2.6005,  -1.5148,\n",
      "        -15.5194,  -5.9153, -11.6970], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.476\n",
      "activated x value: tensor([-3.3089,  6.6751,  2.4718,  1.5611, -5.2874,  0.6004, -0.3194, -2.0453,\n",
      "         1.8136, -1.1366], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7072], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0160,  -0.0320,  -4.2354,  -5.1461, -11.9946,  -6.1068,  -7.0266,\n",
      "         -8.7525,  -4.8935,  -7.8437], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.032\n",
      "activated x value: tensor([-5.1958,  3.4855,  7.6367,  2.1701, -4.5232, -3.6565,  1.7073, -0.8666,\n",
      "        -0.4542, -0.8780], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6598], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.8557,  -4.1743,  -0.0231,  -5.4898, -12.1830, -11.3163,  -5.9525,\n",
      "         -8.5264,  -8.1140,  -8.5379], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-3.4789, -4.7396,  0.3345, -3.0370,  7.4035, -1.9492,  0.1843, -0.3901,\n",
      "         2.8714,  2.8880], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4271], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9060, -12.1666,  -7.0925, -10.4641,  -0.0236,  -9.3762,  -7.2428,\n",
      "         -7.8172,  -4.5556,  -4.5390], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-5.6997, -3.1898, -3.4918, -2.5285,  3.9905, -3.0580, -3.0253,  9.9776,\n",
      "         4.3054,  4.1376], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9865], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5686e+01, -1.3176e+01, -1.3478e+01, -1.2515e+01, -5.9959e+00,\n",
      "        -1.3044e+01, -1.3012e+01, -8.8320e-03, -5.6810e+00, -5.8489e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-1.1367, -3.3575, -1.5209,  4.2289, -1.0719,  4.8503, -2.7312,  0.7380,\n",
      "         0.2156, -0.6780], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3045], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4412, -8.6620, -6.8254, -1.0757, -6.3764, -0.4542, -8.0358, -4.5666,\n",
      "        -5.0889, -5.9825], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.076\n",
      "activated x value: tensor([-6.4399,  6.7097,  0.8721,  0.2403, -1.3008, -1.8850,  1.2637, -1.9377,\n",
      "         3.5907,  0.3431], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7636], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.2035,  -0.0539,  -5.8915,  -6.5233,  -8.0644,  -8.6486,  -5.4999,\n",
      "         -8.7013,  -3.1729,  -6.4205], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.054\n",
      "activated x value: tensor([ 1.1163, -4.8312,  7.5634,  3.1075, -4.6936, -4.2260,  1.1867,  2.8228,\n",
      "        -0.0889, -2.1435], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5872], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.4709, -12.4184,  -0.0239,  -4.4798, -12.2808, -11.8133,  -6.4005,\n",
      "         -4.7644,  -7.6761,  -9.7308], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-5.0845, -1.8498,  1.5661, -0.3154,  2.5061,  0.4721,  2.0531, -4.0760,\n",
      "         6.1108, -1.4904], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1702], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2547,  -8.0201,  -4.6041,  -6.4856,  -3.6641,  -5.6982,  -4.1172,\n",
      "        -10.2462,  -0.0594,  -7.6606], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.059\n",
      "activated x value: tensor([ 0.4729, -4.5820, -0.3031,  2.2419,  0.7808,  2.7963, -2.9022, -2.1384,\n",
      "         1.6063,  1.5031], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.6885], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.2156, -8.2705, -3.9916, -1.4466, -2.9077, -0.8922, -6.5906, -5.8269,\n",
      "        -2.0821, -2.1854], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.892\n",
      "activated x value: tensor([ 2.2614, -7.9505, -1.3056, -0.4828, -2.1339, -0.7957, -4.3076, 10.9122,\n",
      "         1.2005,  2.7557], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9128], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6513e+00, -1.8863e+01, -1.2218e+01, -1.1396e+01, -1.3047e+01,\n",
      "        -1.1708e+01, -1.5220e+01, -5.4932e-04, -9.7122e+00, -8.1571e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-0.0648, -0.8384,  1.7146,  4.5235, -6.7332,  2.8618,  2.3891, -0.4738,\n",
      "        -1.6931, -2.1263], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8552], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.9201,  -5.6936,  -3.1406,  -0.3317, -11.5884,  -1.9934,  -2.4661,\n",
      "         -5.3290,  -6.5483,  -6.9815], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.332\n",
      "activated x value: tensor([  0.6816, -12.5226,  -3.4635,  -1.8460,   2.0617,   1.6057,  -4.6969,\n",
      "          7.3542,   2.5771,   7.8863], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3550], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6734, -20.8777, -11.8186, -10.2010,  -6.2933,  -6.7493, -13.0520,\n",
      "         -1.0008,  -5.7779,  -0.4687], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.001\n",
      "activated x value: tensor([-2.3967, -8.8025,  3.2254, -1.7375,  3.7062, -4.3017, -0.7243, -1.2433,\n",
      "         3.3360,  8.7453], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7603], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1157e+01, -1.7563e+01, -5.5348e+00, -1.0498e+01, -5.0541e+00,\n",
      "        -1.3062e+01, -9.4845e+00, -1.0004e+01, -5.4243e+00, -1.5016e-02],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 9.1534, -9.4911, -1.4979,  4.8614, -4.7412,  3.6486, -5.3391,  2.7586,\n",
      "         0.2781,  0.7138], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1730], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0196, -18.6640, -10.6709,  -4.3116, -13.9141,  -5.5244, -14.5121,\n",
      "         -6.4144,  -8.8948,  -8.4592], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-6.2805,  7.5588,  1.7804,  0.5167, -3.6249, -1.2680,  2.5341, -3.6680,\n",
      "         3.8300, -0.3221], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5933], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.8738,  -0.0345,  -5.8129,  -7.0766, -11.2182,  -8.8613,  -5.0593,\n",
      "        -11.2613,  -3.7633,  -7.9155], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.035\n",
      "activated x value: tensor([-3.3370, -1.9106,  5.3046,  2.1590, -7.0531, -0.9388, -3.1007,  1.7864,\n",
      "         7.1430, -1.4527], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3011], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6381,  -9.2116,  -1.9965,  -5.1421, -14.3542,  -8.2399, -10.4018,\n",
      "         -5.5147,  -0.1581,  -8.7538], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.158\n",
      "activated x value: tensor([-0.7855,  0.6803,  1.9890, -1.0875, -2.5730,  1.8545,  7.4512, -7.0959,\n",
      "         2.9868, -2.9541], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4721], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.2576,  -6.7918,  -5.4831,  -8.5596, -10.0451,  -5.6176,  -0.0209,\n",
      "        -14.5680,  -4.4853, -10.4262], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.021\n",
      "activated x value: tensor([-3.4019, -3.5785, -2.1016,  3.4026,  6.9073, -2.0768,  0.2609, -1.1269,\n",
      "        -3.6881,  6.0664], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2880], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6898, -10.8665,  -9.3896,  -3.8854,  -0.3807,  -9.3648,  -7.0271,\n",
      "         -8.4149, -10.9761,  -1.2216], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.381\n",
      "activated x value: tensor([-4.1335,  3.6415,  2.3307,  4.3143, -3.2297, -0.9106, -2.5255,  0.9030,\n",
      "        -0.2333, -0.0432], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8516], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9851, -1.2101, -2.5209, -0.5373, -8.0813, -5.7623, -7.3771, -3.9487,\n",
      "        -5.0850, -4.8949], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -1.210\n",
      "activated x value: tensor([-2.9592, -8.1003,  0.1008,  4.0233, -2.8395, -2.8476, -9.2461, 15.5404,\n",
      "         0.6782,  4.9173], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.5405], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8500e+01, -2.3641e+01, -1.5440e+01, -1.1517e+01, -1.8380e+01,\n",
      "        -1.8388e+01, -2.4787e+01, -3.5286e-05, -1.4862e+01, -1.0623e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-2.3264, -2.9951,  0.3767, -4.0733,  2.0586,  0.2123,  8.3095, -1.5464,\n",
      "        -0.9714,  0.4662], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3127], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0639e+01, -1.1308e+01, -7.9360e+00, -1.2386e+01, -6.2540e+00,\n",
      "        -8.1004e+00, -3.1652e-03, -9.8591e+00, -9.2841e+00, -7.8464e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-2.4561,  1.1190,  3.0439, -0.0578, -0.8811, -1.6004,  0.8085, -0.5360,\n",
      "         1.4195, -1.0593], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.4967], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9528, -2.3777, -0.4528, -3.5545, -4.3779, -5.0971, -2.6882, -4.0327,\n",
      "        -2.0773, -4.5560], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -3.554\n",
      "activated x value: tensor([ 1.7523, -5.2782,  0.1934,  3.5996, -4.3737,  7.0067, -3.0146, -2.6684,\n",
      "         4.5456, -1.7136], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1246], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.3723, -12.4028,  -6.9312,  -3.5250, -11.4983,  -0.1179, -10.1392,\n",
      "         -9.7930,  -2.5790,  -8.8382], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.118\n",
      "activated x value: tensor([-3.2233, -7.0747,  2.8082, -2.6631,  5.0542, -0.4885,  1.0491,  0.3978,\n",
      "         0.5452,  4.7908], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7053], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.9286, -12.7800,  -2.8970,  -8.3684,  -0.6511,  -6.1938,  -4.6562,\n",
      "         -5.3075,  -5.1600,  -0.9145], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.914\n",
      "activated x value: tensor([-4.2904, -0.4546, -0.2805, -1.6034,  5.3091, -2.5109,  0.6244, -1.5056,\n",
      "        -0.1008,  5.4279], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0743], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3647,  -6.5289,  -6.3548,  -7.6777,  -0.7651,  -8.5851,  -5.4499,\n",
      "         -7.5799,  -6.1750,  -0.6463], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.765\n",
      "activated x value: tensor([-4.6209, -1.6802, -0.2895,  1.1694, -1.2599,  1.6582,  2.1874, -0.9026,\n",
      "         3.9994, -1.1271], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3028], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9237, -5.9830, -4.5923, -3.1334, -5.5626, -2.6446, -2.1154, -5.2054,\n",
      "        -0.3034, -5.4299], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.303\n",
      "activated x value: tensor([-6.3026, -0.0579, -0.6286,  4.6900, -0.3926, -1.1031, -5.0729, -0.2001,\n",
      "         2.9741,  5.9610], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2533], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.5559,  -6.3112,  -6.8819,  -1.5633,  -6.6459,  -7.3564, -11.3262,\n",
      "         -6.4534,  -3.2792,  -0.2923], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.563\n",
      "activated x value: tensor([-3.0019, -2.2580,  0.1214, -0.0935, -0.3274, -0.0318, -0.9996,  4.8759,\n",
      "        -1.5181,  3.7229], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1759], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.1777, -7.4339, -5.0545, -5.2694, -5.5033, -5.2076, -6.1754, -0.3000,\n",
      "        -6.6939, -1.4529], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -5.054\n",
      "activated x value: tensor([-2.1978, -5.9768,  1.1702,  0.1874,  2.0088,  1.6518, -2.0398,  1.9721,\n",
      "         0.2777,  4.4504], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7141], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9119, -10.6909,  -3.5439,  -4.5267,  -2.7053,  -3.0623,  -6.7539,\n",
      "         -2.7420,  -4.4364,  -0.2637], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.264\n",
      "activated x value: tensor([ 2.0721, -3.9289,  1.6833,  0.5892, -2.0839,  1.2199, -7.8629,  9.2198,\n",
      "        -0.1120, -1.1693], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2218], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.1496e+00, -1.3151e+01, -7.5385e+00, -8.6325e+00, -1.1306e+01,\n",
      "        -8.0019e+00, -1.7085e+01, -1.9655e-03, -9.3338e+00, -1.0391e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 0.6321, -2.1733,  2.4491, -2.6604, -0.6741,  2.9962,  5.4309, -4.4563,\n",
      "         0.8148, -2.5146], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5792], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.9471,  -7.7525,  -3.1301,  -8.2397,  -6.2533,  -2.5831,  -0.1483,\n",
      "        -10.0356,  -4.7644,  -8.0938], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.148\n",
      "activated x value: tensor([-1.1035, -4.1438,  2.8202, -1.8871,  1.3356, -1.9426,  0.2814,  3.1939,\n",
      "        -1.0270,  2.1268], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0196], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.1231, -8.1634, -1.1994, -5.9067, -2.6840, -5.9622, -3.7382, -0.8257,\n",
      "        -5.0466, -1.8928], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.893\n",
      "activated x value: tensor([-1.8859, -7.1367, -5.7709, -3.2114, 10.7045, -0.7110,  1.2038,  0.8177,\n",
      "         1.0989,  5.0537], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7082], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2594e+01, -1.7845e+01, -1.6479e+01, -1.3920e+01, -3.7165e-03,\n",
      "        -1.1419e+01, -9.5044e+00, -9.8905e+00, -9.6093e+00, -5.6545e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-1.8501, -2.7073,  1.2509, -3.1760,  1.4277, -2.4218,  7.3741, -0.0772,\n",
      "        -0.2833,  0.6348], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3813], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2314e+00, -1.0089e+01, -6.1304e+00, -1.0557e+01, -5.9536e+00,\n",
      "        -9.8031e+00, -7.2398e-03, -7.4585e+00, -7.6646e+00, -6.7465e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-0.1177, -7.0240, -4.5078,  1.6550,  0.0412, -0.1065, -7.4806, 11.5982,\n",
      "         0.5456,  4.5092], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([11.5991], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1717e+01, -1.8623e+01, -1.6107e+01, -9.9441e+00, -1.1558e+01,\n",
      "        -1.1706e+01, -1.9080e+01, -9.2411e-04, -1.1054e+01, -7.0899e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-7.0502,  5.5246, 10.4687,  6.5069, -9.1157, -0.2759,  3.8975, -6.3509,\n",
      "         0.9796, -3.4848], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.4960], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.5461,  -4.9714,  -0.0273,  -3.9890, -19.6116, -10.7719,  -6.5985,\n",
      "        -16.8469,  -9.5163, -13.9808], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.027\n",
      "activated x value: tensor([-7.0270,  6.5652, -0.7879,  1.4030, -2.0374,  1.9964, -0.7767, -1.9429,\n",
      "         2.1072, -0.3027], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5952], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.6221,  -0.0299,  -7.3831,  -5.1922,  -8.6326,  -4.5988,  -7.3719,\n",
      "         -8.5380,  -4.4879,  -6.8978], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.030\n",
      "activated x value: tensor([-0.6233, -2.0268, -1.9465,  3.4336, -2.5869,  5.7028, -4.0155, -4.1270,\n",
      "         6.8044, -0.1396], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1182], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.7415,  -9.1450,  -9.0647,  -3.6847,  -9.7051,  -1.4155, -11.1337,\n",
      "        -11.2452,  -0.3138,  -7.2578], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.314\n",
      "activated x value: tensor([-6.5051, -3.8424, -6.1456,  2.1069,  3.6774,  0.6911, -3.7667,  1.7143,\n",
      "         2.8554,  9.2573], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2642], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5769e+01, -1.3107e+01, -1.5410e+01, -7.1573e+00, -5.5868e+00,\n",
      "        -8.5731e+00, -1.3031e+01, -7.5499e+00, -6.4088e+00, -6.9170e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -5.587\n",
      "activated x value: tensor([-0.8261, -3.2144,  3.6613, -3.4956,  0.9560, -0.8054,  7.9755, -4.8121,\n",
      "         1.2789, -0.9727], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9914], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.8174, -11.2058,  -4.3300, -11.4869,  -7.0354,  -8.7968,  -0.0158,\n",
      "        -12.8035,  -6.7125,  -8.9641], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-2.5892, -1.7509,  1.5724, -2.1994,  1.3424,  2.4133,  4.6483, -8.0807,\n",
      "         8.2765, -3.5257], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3078], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8970, -10.0586,  -6.7354, -10.5072,  -6.9654,  -5.8945,  -3.6595,\n",
      "        -16.3884,  -0.0312, -11.8335], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.031\n",
      "activated x value: tensor([-7.4907,  8.3772, -0.3236,  2.9638, -2.8704, -0.1395, -0.7852, -0.7257,\n",
      "         0.2395,  0.5175], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3830], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5874e+01, -5.7144e-03, -8.7066e+00, -5.4191e+00, -1.1253e+01,\n",
      "        -8.5225e+00, -9.1682e+00, -9.1087e+00, -8.1435e+00, -7.8655e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-1.4449, -3.8583, -2.4900, -1.7276,  7.4217,  0.3643,  0.5622, -0.8002,\n",
      "        -0.0830,  2.0427], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4293], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8741e+00, -1.1288e+01, -9.9193e+00, -9.1569e+00, -7.6227e-03,\n",
      "        -7.0650e+00, -6.8671e+00, -8.2295e+00, -7.5123e+00, -5.3865e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-0.3875,  0.6448,  6.0330,  2.1185, -2.1115, -1.0227, -1.8946, -1.2676,\n",
      "         1.8478, -3.9401], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0757], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.4632,  -5.4310,  -0.0427,  -3.9572,  -8.1872,  -7.0984,  -7.9703,\n",
      "         -7.3433,  -4.2279, -10.0158], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([-4.8760e+00, -4.9382e+00,  2.8991e+00,  1.0553e+01,  1.4987e+00,\n",
      "        -1.0635e+00, -6.1412e+00, -2.0333e+00,  3.4874e+00, -2.0797e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.5545], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5431e+01, -1.5493e+01, -7.6555e+00, -1.4830e-03, -9.0558e+00,\n",
      "        -1.1618e+01, -1.6696e+01, -1.2588e+01, -7.0671e+00, -1.0557e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.5756, -2.5322, -2.0709,  0.8306,  4.9056, -0.9338, -1.8879,  1.4928,\n",
      "         1.5220,  3.1495], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1385], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.7141, -7.6706, -7.2094, -4.3079, -0.2329, -6.0723, -7.0264, -3.6457,\n",
      "        -3.6165, -1.9890], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.233\n",
      "activated x value: tensor([-2.6297, -3.7328, -2.7420, -0.2840, -0.4015, -1.0116, -5.8537, 10.3654,\n",
      "         2.2743,  3.6016], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3669], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2997e+01, -1.4100e+01, -1.3109e+01, -1.0651e+01, -1.0768e+01,\n",
      "        -1.1378e+01, -1.6221e+01, -1.5211e-03, -8.0925e+00, -6.7653e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 13.0185,  -9.5544,   4.9159,   0.5173, -10.4924,   5.2220,  -8.1801,\n",
      "         -0.0401,   5.2274,  -0.9278], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.0197], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1339e-03, -2.2574e+01, -8.1037e+00, -1.2502e+01, -2.3512e+01,\n",
      "        -7.7977e+00, -2.1200e+01, -1.3060e+01, -7.7923e+00, -1.3947e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-1.8996, -5.2783, -0.0093, -1.0707,  2.2536,  1.6395,  2.9019, -8.2519,\n",
      "         8.9890,  1.0773], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9936], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0893e+01, -1.4272e+01, -9.0029e+00, -1.0064e+01, -6.7400e+00,\n",
      "        -7.3541e+00, -6.0918e+00, -1.7246e+01, -4.6444e-03, -7.9163e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-1.9424, -6.4117, -3.3150, -5.3491,  8.4147, -0.7755,  0.5138,  2.3328,\n",
      "         1.5590,  4.5377], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4390], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3814, -14.8507, -11.7540, -13.7881,  -0.0243,  -9.2145,  -7.9252,\n",
      "         -6.1062,  -6.8800,  -3.9013], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-2.4805, -2.3100,  1.6940, -4.9942,  3.7072, -1.8712,  2.7762,  1.9532,\n",
      "        -0.0131,  1.0543], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2971], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.7777, -6.6071, -2.6032, -9.2913, -0.5900, -6.1684, -1.5209, -2.3440,\n",
      "        -4.3102, -3.2428], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.590\n",
      "activated x value: tensor([ 1.1264, -5.7312,  3.5704, -3.4052,  1.1713,  1.4694, 10.3286, -2.8936,\n",
      "        -1.5950, -3.7300], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3301], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2037e+00, -1.6061e+01, -6.7597e+00, -1.3735e+01, -9.1588e+00,\n",
      "        -8.8607e+00, -1.5192e-03, -1.3224e+01, -1.1925e+01, -1.4060e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-3.1550, -0.2289,  2.6364,  2.4042, -0.7007,  1.5951,  0.6949, -1.9706,\n",
      "        -0.9641,  0.0904], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5529], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.7079, -3.7818, -0.9165, -1.1487, -4.2535, -1.9578, -2.8580, -5.5235,\n",
      "        -4.5170, -3.4625], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.149\n",
      "activated x value: tensor([ 0.7517, -4.0912, -0.0391, -0.9827, -0.7807,  5.0915, -1.4201, -5.6833,\n",
      "         7.3628, -0.8707], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4637], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.7119, -11.5549,  -7.5027,  -8.4464,  -8.2444,  -2.3722,  -8.8838,\n",
      "        -13.1470,  -0.1008,  -8.3344], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.101\n",
      "activated x value: tensor([-2.1504, -3.9327, -0.2043, -1.7997,  6.5667, -3.8826, -0.0439, -0.1489,\n",
      "        -0.6599,  7.1269], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5804], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7308, -11.5131,  -7.7848,  -9.3801,  -1.0137, -11.4630,  -7.6243,\n",
      "         -7.7294,  -8.2403,  -0.4536], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.014\n",
      "activated x value: tensor([-4.4821,  3.3853,  0.0111,  0.5888, -1.1209,  3.0272, -0.8088, -2.2117,\n",
      "         3.3474, -2.4457], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4115], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8935, -1.0261, -4.4003, -3.8226, -5.5324, -1.3842, -5.2203, -6.6232,\n",
      "        -1.0640, -6.8571], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.064\n",
      "activated x value: tensor([-6.7618,  7.9545, -0.9524,  1.9247, -2.8534,  1.4090,  0.1275, -2.1756,\n",
      "         1.0966, -0.0672], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9603], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4722e+01, -5.7998e-03, -8.9126e+00, -6.0356e+00, -1.0814e+01,\n",
      "        -6.5512e+00, -7.8328e+00, -1.0136e+01, -6.8637e+00, -8.0275e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-5.0777, -1.0143,  1.5666,  0.3737,  0.3041, -2.9292, -0.0127,  5.0466,\n",
      "        -0.0665,  2.2350], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1636], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2413,  -6.1779,  -3.5970,  -4.7899,  -4.8595,  -8.0928,  -5.1763,\n",
      "         -0.1169,  -5.2301,  -2.9286], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.117\n",
      "activated x value: tensor([ 1.4478, -2.2105,  2.1899, -2.6577, -2.1643,  3.9570,  8.1450, -7.4675,\n",
      "         1.4855, -2.4327], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1652], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.7174, -10.3757,  -5.9753, -10.8229, -10.3295,  -4.2082,  -0.0202,\n",
      "        -15.6327,  -6.6797, -10.5979], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([ 1.3896, -3.3381,  1.3689,  1.7320, -2.2511,  6.0338, -1.5041, -5.7548,\n",
      "         3.3417, -1.8196], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1306], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.7410,  -9.4687,  -4.7617,  -4.3986,  -8.3817,  -0.0967,  -7.6347,\n",
      "        -11.8854,  -2.7889,  -7.9502], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.097\n",
      "activated x value: tensor([-2.4512, -2.3302, -1.9995,  2.4558,  0.8236,  4.0175,  0.9946, -3.2772,\n",
      "         2.4546, -1.5531], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4356], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8868, -6.7658, -6.4351, -1.9799, -3.6121, -0.4182, -3.4410, -7.7128,\n",
      "        -1.9811, -5.9887], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-8.8837,  5.6254, -0.5094,  3.0937, -0.8826,  2.7637, -0.2660, -3.4593,\n",
      "         1.3966, -0.0677], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7748], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.6585,  -0.1494,  -6.2842,  -2.6811,  -6.6574,  -3.0111,  -6.0408,\n",
      "         -9.2340,  -4.3782,  -5.8425], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.149\n",
      "activated x value: tensor([-2.2640, -5.8118,  1.3290,  3.7531,  0.3543,  2.4830, -2.6571, -5.2661,\n",
      "         8.7454, -1.5297], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7550], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1019e+01, -1.4567e+01, -7.4259e+00, -5.0018e+00, -8.4007e+00,\n",
      "        -6.2720e+00, -1.1412e+01, -1.4021e+01, -9.5425e-03, -1.0285e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-0.5353, -3.1996,  0.1044,  2.0303, -2.2069,  5.2457,  5.7570, -4.7395,\n",
      "         0.7736, -3.9262], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2496], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.7849,  -9.4492,  -6.1452,  -4.2193,  -8.4565,  -1.0039,  -0.4926,\n",
      "        -10.9891,  -5.4760, -10.1758], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.004\n",
      "activated x value: tensor([-0.5234, -6.3380, -4.5540,  4.7112, -3.2085,  7.9813, -5.7229,  2.1821,\n",
      "         4.7899,  0.1741], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0609], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.5842, -14.3989, -12.6149,  -3.3497, -11.2693,  -0.0795, -13.7838,\n",
      "         -5.8787,  -3.2710,  -7.8867], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.080\n",
      "activated x value: tensor([-6.4045,  8.2589,  0.2369,  0.9873, -4.1636,  0.7837,  0.9771, -2.3144,\n",
      "         2.4760, -0.5054], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2644], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4669e+01, -5.5285e-03, -8.0275e+00, -7.2772e+00, -1.2428e+01,\n",
      "        -7.4807e+00, -7.2873e+00, -1.0579e+01, -5.7885e+00, -8.7698e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-5.3606,  9.0097,  1.8123,  0.2938, -5.0951, -0.7366,  0.5039, -1.1632,\n",
      "         2.4930, -0.7250], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0125], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4373e+01, -2.7466e-03, -7.2002e+00, -8.7187e+00, -1.4108e+01,\n",
      "        -9.7491e+00, -8.5085e+00, -1.0176e+01, -6.5195e+00, -9.7374e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-8.0702,  9.9537, -1.0558,  2.1806, -3.9339, -0.3977, -1.9292,  0.9421,\n",
      "         0.9252,  1.7000], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9547], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8025e+01, -9.7942e-04, -1.1011e+01, -7.7741e+00, -1.3889e+01,\n",
      "        -1.0352e+01, -1.1884e+01, -9.0125e+00, -9.0294e+00, -8.2546e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 1.8327, -1.5303, -2.8629, -3.6980,  0.9173,  6.0898,  0.6304, -1.6245,\n",
      "         1.4572, -0.8831], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1251], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.2924, -7.6554, -8.9880, -9.8230, -5.2078, -0.0353, -5.4947, -7.7495,\n",
      "        -4.6678, -7.0081], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.035\n",
      "activated x value: tensor([ -0.5488,   5.3357,   8.8212,   3.9312, -10.8674,  -0.5483,   3.0245,\n",
      "         -6.6081,   2.5377,  -3.9177], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8636], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4123,  -3.5279,  -0.0423,  -4.9324, -19.7310,  -9.4118,  -5.8391,\n",
      "        -15.4717,  -6.3258, -12.7813], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([-2.8440, -2.3283, -1.3102,  5.4488, -1.9147,  3.6072, -3.9611, -4.2658,\n",
      "         8.6832, -1.2530], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7280], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.5720, -11.0563, -10.0382,  -3.2793, -10.6427,  -5.1208, -12.6891,\n",
      "        -12.9938,  -0.0448,  -9.9810], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-0.0953, -7.0331, -0.2261, -0.8301,  5.6625, -3.1196,  0.3986, -1.6381,\n",
      "         1.0302,  4.4805], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9476], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.0429, -12.9807,  -6.1737,  -6.7777,  -0.2851,  -9.0672,  -5.5490,\n",
      "         -7.5857,  -4.9174,  -1.4671], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.285\n",
      "activated x value: tensor([-2.1387, -6.6984,  1.3638,  4.2793, -0.5437,  3.4803, -1.9827, -7.6316,\n",
      "         9.4754, -0.2482], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4838], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1623e+01, -1.6182e+01, -8.1201e+00, -5.2046e+00, -1.0028e+01,\n",
      "        -6.0036e+00, -1.1467e+01, -1.7115e+01, -8.4171e-03, -9.7320e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-7.5203, -2.1559, -3.1014,  2.5695,  1.5604,  1.5040, -3.5579, -1.6563,\n",
      "         2.8832, 10.0889], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0906], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7611e+01, -1.2246e+01, -1.3192e+01, -7.5210e+00, -8.5301e+00,\n",
      "        -8.5865e+00, -1.3648e+01, -1.1747e+01, -7.2073e+00, -1.6842e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 3.8466, -7.0036,  6.8515,  9.0120, -8.4160,  1.9649, -3.6425,  1.1992,\n",
      "         2.4158, -6.7805], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1286], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.2820, -16.1322,  -2.2770,  -0.1166, -17.5446,  -7.1637, -12.7711,\n",
      "         -7.9294,  -6.7128, -15.9090], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -2.277\n",
      "activated x value: tensor([-5.3923,  5.5902,  8.6838,  4.3169, -6.6915, -1.0789,  0.2513, -6.9588,\n",
      "         3.7933, -2.5483], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7476], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.1399,  -3.1574,  -0.0638,  -4.4306, -15.4391,  -9.8265,  -8.4962,\n",
      "        -15.7064,  -4.9542, -11.2958], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.064\n",
      "activated x value: tensor([-3.9958,  3.5287,  5.1842,  0.6096, -1.5683,  0.6147,  2.4189, -5.7520,\n",
      "         1.3782, -2.3969], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4455], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4413,  -1.9168,  -0.2613,  -4.8359,  -7.0138,  -4.8308,  -3.0266,\n",
      "        -11.1975,  -4.0673,  -7.8424], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.261\n",
      "activated x value: tensor([-1.4918, -5.7459,  4.0667, -1.1732, -2.7451,  4.1469, -1.8938,  0.1598,\n",
      "         3.2000,  1.3397], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0231], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.5148, -10.7690,  -0.9564,  -6.1962,  -7.7682,  -0.8762,  -6.9169,\n",
      "         -4.8633,  -1.8231,  -3.6834], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.956\n",
      "activated x value: tensor([ 3.5558,  0.3934,  2.6360,  3.6749, -3.2144,  5.5007,  0.3884, -7.4808,\n",
      "         1.0483, -7.1063], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8264], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -2.2706,  -5.4330,  -3.1904,  -2.1514,  -9.0407,  -0.3257,  -5.4380,\n",
      "        -13.3072,  -4.7781, -12.9326], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -3.190\n",
      "activated x value: tensor([  5.2196, -12.7726,  13.5475,   4.1702,  -3.7495,   2.9782,   1.2621,\n",
      "         -8.6552,   4.8902,  -8.1155], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.5481], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.3284e+00, -2.6321e+01, -5.3024e-04, -9.3778e+00, -1.7298e+01,\n",
      "        -1.0570e+01, -1.2286e+01, -2.2203e+01, -8.6579e+00, -2.1664e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 0.5958, -4.8938, -1.8054,  1.3320, -0.8489, -0.2286, -4.5852,  3.6418,\n",
      "         0.7248,  5.5887], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7513], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.1555, -10.6451,  -7.5567,  -4.4193,  -6.6002,  -5.9799, -10.3365,\n",
      "         -2.1096,  -5.0265,  -0.1627], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.163\n",
      "activated x value: tensor([-0.6409, -4.5802,  1.1479, -2.7776,  2.4161,  1.5149,  8.7969, -7.0230,\n",
      "         2.9082, -0.8693], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8026], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4436e+00, -1.3383e+01, -7.6548e+00, -1.1580e+01, -6.3865e+00,\n",
      "        -7.2878e+00, -5.7669e-03, -1.5826e+01, -5.8944e+00, -9.6719e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-1.4249, -0.7066, -0.7724,  0.7074,  0.2973,  3.1359, -1.6644, -2.0381,\n",
      "         2.5461, -1.2461], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7122], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.1371, -4.4189, -4.4846, -3.0048, -3.4149, -0.5763, -5.3767, -5.7503,\n",
      "        -1.1661, -4.9584], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.166\n",
      "activated x value: tensor([-6.5111,  5.9362,  0.4636,  1.9234, -2.0253, -1.9100, -2.1768,  2.8066,\n",
      "         1.3551,  0.9830], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0172], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.5283,  -0.0810,  -5.5536,  -4.0938,  -8.0425,  -7.9272,  -8.1940,\n",
      "         -3.2106,  -4.6621,  -5.0342], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([ 3.2226, -3.8659,  2.4045,  2.0830, -0.7703,  1.4193,  0.1271, -1.1448,\n",
      "        -3.3211,  0.7842], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9606], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-0.7381, -7.8265, -1.5562, -1.8777, -4.7310, -2.5414, -3.8336, -5.1055,\n",
      "        -7.2817, -3.1765], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.556\n",
      "activated x value: tensor([-3.0818, -1.1654, -8.6479,  0.6878,  2.0951,  1.6901, -4.0560,  6.0778,\n",
      "         1.2053,  5.0087], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4053], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4870,  -7.5706, -15.0531,  -5.7174,  -4.3101,  -4.7151, -10.4612,\n",
      "         -0.3275,  -5.1999,  -1.3965], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.327\n",
      "activated x value: tensor([ 2.9898, -5.1279, 11.5707, -1.9100, -0.9242,  2.5939,  3.1199, -6.9296,\n",
      "         1.5516, -7.9083], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5713], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.5815e+00, -1.6699e+01, -5.7697e-04, -1.3481e+01, -1.2495e+01,\n",
      "        -8.9774e+00, -8.4514e+00, -1.8501e+01, -1.0020e+01, -1.9480e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-8.6474,  7.6070,  0.5059,  1.4233, -3.4727, -0.4071, -0.2143, -0.6372,\n",
      "         3.7575,  0.7208], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6329], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.2803,  -0.0259,  -7.1270,  -6.2096, -11.1056,  -8.0400,  -7.8472,\n",
      "         -8.2701,  -3.8754,  -6.9121], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.026\n",
      "activated x value: tensor([ 1.2992, -9.9199,  4.1148, -4.1976,  7.9525, -5.8622,  3.8795, -0.1801,\n",
      "        -0.2287,  2.4061], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9959], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6967, -17.9158,  -3.8811, -12.1935,  -0.0434, -13.8581,  -4.1164,\n",
      "         -8.1760,  -8.2246,  -5.5898], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([ 0.2105, -8.1511,  3.0636, -2.1884,  2.9493,  2.1212,  8.7953, -4.1958,\n",
      "        -1.3106, -1.4499], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8029], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.5925e+00, -1.6954e+01, -5.7393e+00, -1.0991e+01, -5.8536e+00,\n",
      "        -6.6817e+00, -7.6504e-03, -1.2999e+01, -1.0114e+01, -1.0253e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-5.0231,  6.3705,  1.2866,  1.4827, -4.6051,  0.1983, -1.1552,  0.0349,\n",
      "         2.7539, -0.4545], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4155], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.4386,  -0.0451,  -5.1290,  -4.9328, -11.0206,  -6.2173,  -7.5707,\n",
      "         -6.3807,  -3.6617,  -6.8700], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-7.1415,  7.4667, -0.6973,  1.8955, -2.4383,  1.2245, -0.5561, -1.6695,\n",
      "         1.5000,  0.4303], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4766], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4618e+01, -9.9144e-03, -8.1739e+00, -5.5811e+00, -9.9150e+00,\n",
      "        -6.2521e+00, -8.0328e+00, -9.1461e+00, -5.9767e+00, -7.0463e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-1.3604, -1.0623, -0.3284, -0.4146,  0.3695,  4.4156,  1.2283, -2.9860,\n",
      "         2.4378, -1.9232], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6173], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9777, -5.6796, -4.9457, -5.0319, -4.2478, -0.2017, -3.3890, -7.6033,\n",
      "        -2.1795, -6.5405], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.202\n",
      "activated x value: tensor([ 1.4138, -4.0634,  1.3554, -1.8441, -0.6120,  1.6980, -1.2088, -0.8184,\n",
      "         2.8924,  1.1194], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5838], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.1700, -7.6472, -2.2284, -5.4279, -4.1958, -1.8858, -4.7926, -4.4022,\n",
      "        -0.6914, -2.4644], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.886\n",
      "activated x value: tensor([-1.7464, -9.4002,  8.8551,  3.0815, -0.2711, -2.2023,  0.6579, -3.2647,\n",
      "         1.0686,  2.3227], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8605], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0607e+01, -1.8261e+01, -5.3949e-03, -5.7790e+00, -9.1316e+00,\n",
      "        -1.1063e+01, -8.2026e+00, -1.2125e+01, -7.7920e+00, -6.5378e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-5.1675, -1.6591,  6.4412,  1.4295, -0.2257, -2.5452,  0.7271, -2.1899,\n",
      "         1.1242,  0.2428], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4598], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.6273,  -8.1189,  -0.0186,  -5.0302,  -6.6855,  -9.0050,  -5.7326,\n",
      "         -8.6497,  -5.3356,  -6.2169], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([ 2.2267, -3.0551, -0.6563,  3.9560, -2.2950,  4.7574,  0.0771, -7.1597,\n",
      "         4.8724, -3.3379], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7378], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.5110,  -8.7929,  -6.3941,  -1.7818,  -8.0328,  -0.9804,  -5.6607,\n",
      "        -12.8975,  -0.8654,  -9.0757], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.980\n",
      "activated x value: tensor([-5.0447, -0.5215,  2.0305, -0.1345,  0.3123,  0.2926, -0.7117, -2.2958,\n",
      "         5.2181,  0.3157], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2900], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3347,  -5.8115,  -3.2594,  -5.4245,  -4.9777,  -4.9973,  -6.0017,\n",
      "         -7.5857,  -0.0719,  -4.9743], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.072\n",
      "activated x value: tensor([-3.2391,  5.6207,  1.2955,  0.5777, -3.3523,  0.1769, -0.4092, -0.0679,\n",
      "         0.9129, -0.9548], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6604], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8994, -0.0397, -4.3648, -5.0827, -9.0127, -5.4835, -6.0696, -5.7282,\n",
      "        -4.7475, -6.6152], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.040\n",
      "activated x value: tensor([-0.5158,  2.7852,  1.7979,  7.1867, -6.7522,  1.3811, -1.5275, -1.9445,\n",
      "         1.3304, -2.9040], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2099], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.7257,  -4.4247,  -5.4120,  -0.0232, -13.9621,  -5.8288,  -8.7374,\n",
      "         -9.1544,  -5.8795, -10.1139], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-0.2204, -1.9019,  1.2764,  0.9674, -3.1184,  1.6452, -2.1939, -2.1529,\n",
      "         6.9294, -0.5865], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9422], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1626,  -8.8441,  -5.6658,  -5.9748, -10.0606,  -5.2970,  -9.1361,\n",
      "         -9.0951,  -0.0128,  -7.5287], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([ 1.5329, -8.5625,  9.8425,  6.6883, -1.8805, -0.9025, -1.3180, -4.2841,\n",
      "         1.9025, -3.4590], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8849], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3519, -18.4474,  -0.0424,  -3.1966, -11.7654, -10.7874, -11.2029,\n",
      "        -14.1690,  -7.9824, -13.3439], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([-5.5019,  7.4952,  1.5934,  1.5021, -4.4389, -0.7228, -0.0691, -0.5037,\n",
      "         2.3446, -0.6519], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5076], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3010e+01, -1.2372e-02, -5.9142e+00, -6.0055e+00, -1.1947e+01,\n",
      "        -8.2305e+00, -7.5767e+00, -8.0113e+00, -5.1630e+00, -8.1595e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([  0.5984,   0.4252,  14.5774,   8.6174,  -9.7344,   1.0451,  -2.3027,\n",
      "        -11.3410,   7.4119,  -8.2289], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.5808], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3982e+01, -1.4156e+01, -3.3503e-03, -5.9634e+00, -2.4315e+01,\n",
      "        -1.3536e+01, -1.6883e+01, -2.5922e+01, -7.1689e+00, -2.2810e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 7.4905, -9.2366,  1.5207,  0.5492, -2.0845,  4.0305,  1.1176, -2.4544,\n",
      "         0.9107, -0.9977], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5281], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0377, -16.7647,  -6.0075,  -6.9789,  -9.6126,  -3.4976,  -6.4106,\n",
      "         -9.9825,  -6.6174,  -8.5258], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.038\n",
      "activated x value: tensor([-2.8991, -1.6252, -2.8170,  0.7010, -2.1217,  3.8223, -0.7432, -1.1096,\n",
      "         3.2100,  4.3069], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9969], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8960, -6.6221, -7.8139, -4.2959, -7.1186, -1.1746, -5.7401, -6.1065,\n",
      "        -1.7869, -0.6900], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.175\n",
      "activated x value: tensor([-8.2130e-03, -3.3127e+00,  1.1471e+01,  1.1131e+00,  9.3577e-03,\n",
      "        -3.2017e+00,  2.5297e+00, -6.0031e+00, -2.0863e-01, -2.5729e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.4714], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1480e+01, -1.4784e+01, -1.9360e-04, -1.0358e+01, -1.1462e+01,\n",
      "        -1.4673e+01, -8.9417e+00, -1.7475e+01, -1.1680e+01, -1.4044e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-3.8588,  7.2018,  2.2117,  1.8306, -6.3425,  1.3950,  1.1251, -5.2337,\n",
      "         4.5058, -1.5866], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2828], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.1416,  -0.0810,  -5.0711,  -5.4522, -13.6253,  -5.8878,  -6.1577,\n",
      "        -12.5165,  -2.7770,  -8.8694], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([-1.5275, -5.6587,  0.7960, -0.4146, -0.1181, -1.0227, -2.9553,  5.5550,\n",
      "         0.5624,  4.4431], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8571], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.3846, -11.5158,  -5.0611,  -6.2717,  -5.9752,  -6.8798,  -8.8124,\n",
      "         -0.3021,  -5.2947,  -1.4140], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.302\n",
      "activated x value: tensor([-4.9491, -2.2287,  2.0530,  1.4860,  5.7319, -2.4790, -0.3496, -2.4724,\n",
      "         0.8827,  3.3504], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8656], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8146,  -8.0943,  -3.8126,  -4.3795,  -0.1337,  -8.3446,  -6.2152,\n",
      "         -8.3380,  -4.9829,  -2.5152], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.134\n",
      "activated x value: tensor([-1.5829, -2.7474, -1.5372, 12.2365, -0.7947,  3.0042, -5.9218, -3.4026,\n",
      "         0.8714,  0.0548], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.2366], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3819e+01, -1.4984e+01, -1.3774e+01, -1.1921e-04, -1.3031e+01,\n",
      "        -9.2324e+00, -1.8158e+01, -1.5639e+01, -1.1365e+01, -1.2182e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 3.2728, -4.9988, -1.4378,  2.4567,  0.0624,  6.9103,  3.5803, -9.1211,\n",
      "         4.0301, -5.2957], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0335], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.7607, -12.0323,  -8.4714,  -4.5769,  -6.9711,  -0.1233,  -3.4532,\n",
      "        -16.1546,  -3.0035, -12.3293], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.123\n",
      "activated x value: tensor([-0.8913, -1.6277,  3.6171,  3.2598, -1.7491,  3.0152, -0.0549, -9.6655,\n",
      "         8.6693, -4.5536], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6838], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.5751e+00, -1.0312e+01, -5.0667e+00, -5.4240e+00, -1.0433e+01,\n",
      "        -5.6687e+00, -8.7387e+00, -1.8349e+01, -1.4565e-02, -1.3237e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-3.3973,  6.0448,  0.9919,  1.5736, -5.4326,  0.3980, -1.1134, -1.2728,\n",
      "         2.4708,  0.1168], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0970], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4943,  -0.0522,  -5.1051,  -4.5235, -11.5296,  -5.6990,  -7.2105,\n",
      "         -7.3698,  -3.6263,  -5.9802], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.052\n",
      "activated x value: tensor([-3.5156, -0.7037, -1.6213, -0.0229, -1.2229, -1.3357, -8.3969, 11.5112,\n",
      "         1.1235,  4.2453], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5119], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5028e+01, -1.2216e+01, -1.3133e+01, -1.1535e+01, -1.2735e+01,\n",
      "        -1.2848e+01, -1.9909e+01, -7.5245e-04, -1.0388e+01, -7.2666e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-1.1232,  1.8311, -0.5187,  0.6671, -2.7567,  3.0345,  0.5302, -3.9466,\n",
      "         3.7031, -0.1996], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2915], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.4147, -2.4604, -4.8101, -3.6244, -7.0482, -1.2569, -3.7613, -8.2381,\n",
      "        -0.5884, -4.4911], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.588\n",
      "activated x value: tensor([-2.2383, -7.7589, -3.2574,  0.6432,  2.0355,  0.0748, -2.7081,  4.0456,\n",
      "         1.8600,  6.9330], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0031], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2413, -14.7619, -10.2604,  -6.3598,  -4.9675,  -6.9282,  -9.7112,\n",
      "         -2.9574,  -5.1430,  -0.0701], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.070\n",
      "activated x value: tensor([-2.4309, -0.3338, -1.6113,  2.1664, -2.8287,  3.1211, -2.3059, -1.2335,\n",
      "         4.7051,  1.0448], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9850], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.4158, -5.3188, -6.5963, -2.8185, -7.8137, -1.8639, -7.2909, -6.2184,\n",
      "        -0.2799, -3.9402], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.280\n",
      "activated x value: tensor([-0.5063, -4.6939,  3.8446,  9.1261,  0.2677,  1.7984, -5.2972, -8.9525,\n",
      "         5.9925, -1.8973], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1744], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.6807, -13.8683,  -5.3298,  -0.0483,  -8.9067,  -7.3760, -14.4716,\n",
      "        -18.1269,  -3.1819, -11.0717], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.048\n",
      "activated x value: tensor([ 13.5419, -10.3494,  -0.3324,   1.6247,  -7.4723,   6.6818,  -2.5340,\n",
      "         -0.6528,   3.4546,  -2.6094], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.5430], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0986e-03, -2.3892e+01, -1.3875e+01, -1.1918e+01, -2.1015e+01,\n",
      "        -6.8612e+00, -1.6077e+01, -1.4196e+01, -1.0088e+01, -1.6152e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-3.6561, -0.3885, -2.1439,  6.3435, -2.2513,  3.3486, -2.8824, -1.0450,\n",
      "         1.3055,  1.7803], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4105], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0666,  -6.7990,  -8.5544,  -0.0670,  -8.6618,  -3.0619,  -9.2929,\n",
      "         -7.4555,  -5.1050,  -4.6302], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target index: 3\n",
      "\n",
      "loss value: -0.067\n",
      "activated x value: tensor([-6.3034, -5.7110, -5.7895, -2.3321,  5.7041,  0.1123, -4.5990,  6.7085,\n",
      "         3.1135,  9.4483], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5346], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.8381, -15.2456, -15.3241, -11.8667,  -3.8306,  -9.4223, -14.1336,\n",
      "         -2.8261,  -6.4211,  -0.0863], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.086\n",
      "activated x value: tensor([ -0.7860, -10.5381,   0.4757,   5.5910,  -2.9950,  -1.3213,  -7.8425,\n",
      "         11.1836,   0.1644,   4.8768], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1891], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1975e+01, -2.1727e+01, -1.0713e+01, -5.5982e+00, -1.4184e+01,\n",
      "        -1.2510e+01, -1.9032e+01, -5.5828e-03, -1.1025e+01, -6.3123e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-5.8712, -1.5669,  1.6056, -1.2020,  4.8559, -0.8770,  3.7697, -6.8809,\n",
      "         2.8669,  2.4260], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3312], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2024,  -6.8980,  -3.7255,  -6.5332,  -0.4752,  -6.2081,  -1.5614,\n",
      "        -12.2120,  -2.4643,  -2.9052], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.475\n",
      "activated x value: tensor([ 1.7470, -7.2780, -3.1131,  7.2600, -3.9550,  7.9908, -4.2640, -1.3032,\n",
      "         2.9464, -0.0754], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3898], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6428, -15.6678, -11.5029,  -1.1298, -12.3448,  -0.3990, -12.6538,\n",
      "         -9.6930,  -5.4433,  -8.4652], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.399\n",
      "activated x value: tensor([-1.6267, -5.7349, -0.8256,  0.9391, -0.6050,  4.1864, -2.2560, -0.7344,\n",
      "         3.5081,  3.0657], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8279], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.4546, -10.5628,  -5.6534,  -3.8888,  -5.4328,  -0.6415,  -7.0838,\n",
      "         -5.5623,  -1.3198,  -1.7622], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.641\n",
      "activated x value: tensor([-3.2965, -4.2784,  0.7973,  3.0487, -1.8247, -1.9052, -6.3380, 10.0370,\n",
      "        -0.1622,  4.1308], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0408], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3337e+01, -1.4319e+01, -9.2434e+00, -6.9921e+00, -1.1865e+01,\n",
      "        -1.1946e+01, -1.6379e+01, -3.7880e-03, -1.0203e+01, -5.9099e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 1.9480, -8.7848,  9.6633,  8.9223, -0.9546,  1.0172, -1.7364, -8.1958,\n",
      "         2.6808, -5.1845], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0542], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.1061, -18.8390,  -0.3908,  -1.1319, -11.0088,  -9.0369, -11.7906,\n",
      "        -18.2500,  -7.3734, -15.2387], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.391\n",
      "activated x value: tensor([-4.7388,  7.5820,  4.1077,  0.0576, -2.9006, -3.1011, -0.2990, -2.0311,\n",
      "         3.6935, -1.9028], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6332], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.3720,  -0.0512,  -3.5255,  -7.5757, -10.5339, -10.7343,  -7.9322,\n",
      "         -9.6643,  -3.9397,  -9.5361], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.051\n",
      "activated x value: tensor([-0.9836, -2.6258,  1.5222,  0.9162,  2.4283,  3.8868,  0.3925, -7.9736,\n",
      "         6.7737, -2.8006], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8498], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.8335,  -9.4756,  -5.3276,  -5.9336,  -4.4215,  -2.9630,  -6.4573,\n",
      "        -14.8235,  -0.0761,  -9.6504], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.076\n",
      "activated x value: tensor([-4.7505, -1.4921, -0.4057,  1.7534, -0.8330,  0.1085, -3.9293,  6.3174,\n",
      "        -0.5750,  4.1279], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4377], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.1882,  -7.9298,  -6.8435,  -4.6843,  -7.2707,  -6.3292, -10.3670,\n",
      "         -0.1203,  -7.0127,  -2.3098], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.120\n",
      "activated x value: tensor([-1.3113, -6.3501, -1.7004, -2.3748,  2.3988, -1.6721, -3.7727,  6.8915,\n",
      "         1.2883,  6.8300], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5624], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.8737, -13.9124,  -9.2628,  -9.9371,  -5.1635,  -9.2345, -11.3351,\n",
      "         -0.6709,  -6.2741,  -0.7324], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.671\n",
      "activated x value: tensor([ 1.1311, -4.7885, -0.3546, -0.5599, -0.1917,  5.1855,  3.8568, -5.5822,\n",
      "         3.2144, -1.4837], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5464], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.4153, -10.3349,  -5.9010,  -6.1062,  -5.7381,  -0.3608,  -1.6896,\n",
      "        -11.1286,  -2.3319,  -7.0301], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.361\n",
      "activated x value: tensor([-5.0123,  2.2978,  9.7862,  3.7366, -2.5835, -0.3061,  2.0245, -8.5835,\n",
      "         2.7322, -4.4327], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7905], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4803e+01, -7.4927e+00, -4.2458e-03, -6.0539e+00, -1.2374e+01,\n",
      "        -1.0097e+01, -7.7659e+00, -1.8374e+01, -7.0583e+00, -1.4223e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 0.7311, -2.7625, -6.0166, -0.8348, -0.1682,  1.8935, -1.9148,  5.6001,\n",
      "         0.9874,  2.7226], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6990], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.9679,  -8.4616, -11.7156,  -6.5338,  -5.8672,  -3.8056,  -7.6139,\n",
      "         -0.0989,  -4.7116,  -2.9765], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.099\n",
      "activated x value: tensor([-3.8535, -7.1706,  1.9535, -2.6994,  5.8768,  0.5147, 10.9879, -6.4385,\n",
      "         1.3600, -0.5444], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9941], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4848e+01, -1.8165e+01, -9.0406e+00, -1.3693e+01, -5.1173e+00,\n",
      "        -1.0479e+01, -6.2351e-03, -1.7433e+01, -9.6341e+00, -1.1538e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 4.2582, -4.8856,  1.1710, -2.1393, -1.6232,  0.4000,  4.6189, -2.2012,\n",
      "         2.5133, -1.4358], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2460], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.9878, -10.1316,  -4.0750,  -7.3853,  -6.8692,  -4.8460,  -0.6270,\n",
      "         -7.4472,  -2.7326,  -6.6818], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.627\n",
      "activated x value: tensor([-0.9689, -5.1082, -7.6253, -1.5756,  1.6012,  0.6318, -1.9222,  8.6315,\n",
      "         1.5438,  4.5281], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6500], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.6189, -13.7582, -16.2753, -10.2256,  -7.0488,  -8.0182, -10.5722,\n",
      "         -0.0185,  -7.1062,  -4.1219], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-4.8389,  5.1551, -0.9349,  0.2348, -2.1400,  0.8063, -0.4993,  1.0037,\n",
      "         0.5527,  0.7458], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2178], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0567,  -0.0626,  -6.1526,  -4.9829,  -7.3578,  -4.4114,  -5.7171,\n",
      "         -4.2141,  -4.6651,  -4.4719], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.063\n",
      "activated x value: tensor([-5.3899,  6.5924,  1.2434,  1.1808, -3.2626, -1.8375, -0.1525,  1.1336,\n",
      "         0.5328,  0.6281], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6121], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.0020,  -0.0196,  -5.3687,  -5.4313,  -9.8747,  -8.4496,  -6.7646,\n",
      "         -5.4784,  -6.0793,  -5.9839], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-3.5010, -0.8400, -0.6079, -4.0228,  7.3710, -2.5766,  3.7496,  0.5578,\n",
      "        -1.1126,  1.7082], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4028], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9038,  -8.2427,  -8.0106, -11.4256,  -0.0317,  -9.9794,  -3.6532,\n",
      "         -6.8449,  -8.5153,  -5.6946], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.032\n",
      "activated x value: tensor([-6.4147,  7.2375, -0.7696,  0.3053, -1.8964,  0.9561,  0.5585, -1.4335,\n",
      "         2.0607, -0.8140], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2481], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3663e+01, -1.0625e-02, -8.0178e+00, -6.9428e+00, -9.1446e+00,\n",
      "        -6.2921e+00, -6.6896e+00, -8.6816e+00, -5.1875e+00, -8.0622e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-7.1183, -3.5208,  0.5458,  0.8456,  2.9763, -2.1618, -1.0611,  2.7149,\n",
      "        -0.0227,  6.4114], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4755], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.5938,  -9.9963,  -5.9297,  -5.6298,  -3.4991,  -8.6372,  -7.5366,\n",
      "         -3.7606,  -6.4981,  -0.0640], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.064\n",
      "activated x value: tensor([ 15.6129, -10.6650,  -1.7779,   2.6590,  -7.9343,   7.7192,  -3.6535,\n",
      "         -3.4277,   6.1442,  -3.7349], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.6134], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.5300e-04, -2.6278e+01, -1.7391e+01, -1.2954e+01, -2.3548e+01,\n",
      "        -7.8942e+00, -1.9267e+01, -1.9041e+01, -9.4692e+00, -1.9348e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-4.0682, -0.8225, -1.0271,  1.4032, -1.5842, -1.5689, -5.8878,  9.9691,\n",
      "         0.3511,  3.6812], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9712], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4039e+01, -1.0794e+01, -1.0998e+01, -8.5681e+00, -1.1555e+01,\n",
      "        -1.1540e+01, -1.5859e+01, -2.1715e-03, -9.6201e+00, -6.2900e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 0.7654, -5.1597,  6.1104, -0.5208, -2.4597, -0.2938, -0.6735, -0.9212,\n",
      "         2.9703, -0.7223], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1633], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.3979, -11.3230,  -0.0529,  -6.6841,  -8.6230,  -6.4571,  -6.8368,\n",
      "         -7.0845,  -3.1929,  -6.8856], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.053\n",
      "activated x value: tensor([-6.2390, -2.0234, -2.8755,  0.7709,  4.0347, -1.5712, -1.6647, -0.0367,\n",
      "         2.4238,  6.4886], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5918], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.8309,  -8.6152,  -9.4673,  -5.8210,  -2.5572,  -8.1631,  -8.2566,\n",
      "         -6.6286,  -4.1681,  -0.1033], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.103\n",
      "activated x value: tensor([-7.5394, -1.5543, -3.3151, -1.0689,  4.3287,  4.2859, -0.8039,  0.6139,\n",
      "         5.4236, -1.4980], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9357], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.4751,  -7.4901,  -9.2509,  -7.0047,  -1.6071,  -1.6499,  -6.7397,\n",
      "         -5.3218,  -0.5121,  -7.4338], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.512\n",
      "activated x value: tensor([-7.5500,  8.8440, -0.4254,  2.9810, -3.1511, -0.5305, -0.5850, -0.2988,\n",
      "         0.6188,  0.5229], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8478], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6398e+01, -3.7193e-03, -9.2731e+00, -5.8668e+00, -1.1999e+01,\n",
      "        -9.3782e+00, -9.4327e+00, -9.1465e+00, -8.2290e+00, -8.3249e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 0.5446, -4.7979,  8.0361,  5.7929, -3.4104, -1.6805, -0.9668, -0.0090,\n",
      "        -1.4594, -2.9499], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1380], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5934, -12.9359,  -0.1019,  -2.3451, -11.5484,  -9.8185,  -9.1048,\n",
      "         -8.1471,  -9.5974, -11.0879], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.102\n",
      "activated x value: tensor([-2.7133, -4.0518,  2.4616, -0.5528,  7.0884, -5.5004,  0.8892,  1.0334,\n",
      "        -1.5429,  3.0314], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1201], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.8334, -11.1719,  -4.6585,  -7.6729,  -0.0317, -12.6205,  -6.2309,\n",
      "         -6.0867,  -8.6630,  -4.0887], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.032\n",
      "activated x value: tensor([  4.6892, -10.3065,  -5.1565,   5.4460,  -6.3416,   2.5768,  -6.2804,\n",
      "         13.8773,   1.7964,   1.2438], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.8776], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1884e+00, -2.4184e+01, -1.9034e+01, -8.4316e+00, -2.0219e+01,\n",
      "        -1.1301e+01, -2.0158e+01, -3.4142e-04, -1.2081e+01, -1.2634e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-0.8345, -0.7031,  1.6982,  5.0861, -2.3048,  2.6155, -2.5744, -1.9831,\n",
      "         1.0600, -2.8928], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2208], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.0553, -5.9239, -3.5226, -0.1347, -7.5256, -2.6053, -7.7952, -7.2039,\n",
      "        -4.1608, -8.1136], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.135\n",
      "activated x value: tensor([-0.5854,  3.6681,  5.7174,  2.1954, -6.2369, -1.7125,  0.5819, -6.9114,\n",
      "         6.5650, -3.5107], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9704], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5558,  -3.3023,  -1.2530,  -4.7750, -13.2074,  -8.6829,  -6.3885,\n",
      "        -13.8818,  -0.4054, -10.4811], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.253\n",
      "activated x value: tensor([-2.0276, -7.9915, -1.1101,  3.2023, -1.9541,  7.6805, -3.3673, -1.3629,\n",
      "         3.9363,  3.0931], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7250], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7526, -15.7165,  -8.8351,  -4.5228,  -9.6791,  -0.0446, -11.0924,\n",
      "         -9.0880,  -3.7888,  -4.6320], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-1.0339, -8.9438, -1.7476, -2.8995,  1.2940,  2.1972, -3.2584,  2.3403,\n",
      "         6.5253,  6.1196], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0566], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.0905, -16.0004,  -8.8042,  -9.9561,  -5.7626,  -4.8594, -10.3150,\n",
      "         -4.7163,  -0.5313,  -0.9370], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.531\n",
      "activated x value: tensor([-3.6401,  2.7049,  1.3368, -1.4944, -0.5591,  0.5795, -0.6482, -0.2086,\n",
      "         1.2599, -0.1725], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.2983], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9385, -0.5935, -1.9615, -4.7928, -3.8575, -2.7189, -3.9465, -3.5069,\n",
      "        -2.0385, -3.4708], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.038\n",
      "activated x value: tensor([ 17.4378, -12.0007,   1.1869,  -0.4568, -12.2426,   7.7897,  -1.0518,\n",
      "         -2.1523,   6.2252,  -4.1978], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([17.4379], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8201e-05, -2.9439e+01, -1.6251e+01, -1.7895e+01, -2.9680e+01,\n",
      "        -9.6482e+00, -1.8490e+01, -1.9590e+01, -1.1213e+01, -2.1636e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-3.8302, -3.4999, -3.0426, -1.0468,  5.0091,  1.0786, -1.8831,  1.7226,\n",
      "         1.0087,  3.8644], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3439], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1741, -8.8438, -8.3865, -6.3907, -0.3348, -4.2653, -7.2270, -3.6213,\n",
      "        -4.3352, -1.4795], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.335\n",
      "activated x value: tensor([-0.2667, -2.8900,  0.0155,  2.7515,  1.3788,  3.0550, -0.6562, -4.7233,\n",
      "         2.0203, -0.8049], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9359], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.2027, -6.8259, -3.9204, -1.1844, -2.5571, -0.8810, -4.5921, -8.6592,\n",
      "        -1.9156, -4.7408], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.916\n",
      "activated x value: tensor([-3.0336, -2.4884,  4.1062, -0.5412,  0.1580,  2.6477, -1.0694, -6.9236,\n",
      "         9.2455, -2.9819], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2529], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2287e+01, -1.1741e+01, -5.1467e+00, -9.7941e+00, -9.0949e+00,\n",
      "        -6.6052e+00, -1.0322e+01, -1.6176e+01, -7.4177e-03, -1.2235e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([ 2.8141, -9.9851, -0.4852,  4.4977,  2.3466,  4.2174, -3.4123, -5.7190,\n",
      "         6.0842, -1.0524], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4372], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.6231, -16.4223,  -6.9224,  -1.9395,  -4.0906,  -2.2198,  -9.8495,\n",
      "        -12.1562,  -0.3530,  -7.4896], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.353\n",
      "activated x value: tensor([-2.5678, -6.6756, -3.7369, -2.2944,  2.2713,  3.9259, -3.5861,  2.6400,\n",
      "         7.5007,  1.4187], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5433], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1111, -14.2189, -11.2802,  -9.8377,  -5.2721,  -3.6174, -11.1294,\n",
      "         -4.9033,  -0.0426,  -6.1246], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([ 2.5449, -6.4085, -4.3331,  7.6739, -5.4281,  7.2149, -3.2356, -2.4359,\n",
      "         3.9404,  0.5783], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1823], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6374, -14.5908, -12.5154,  -0.5084, -13.6104,  -0.9674, -11.4179,\n",
      "        -10.6182,  -4.2419,  -7.6040], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.967\n",
      "activated x value: tensor([-1.0045, -5.0227, -0.1928,  4.5559, -0.3473,  5.4045, -1.4531, -4.5702,\n",
      "         2.7485,  0.3892], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8196], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.8241, -10.8423,  -6.0124,  -1.2637,  -6.1669,  -0.4151,  -7.2727,\n",
      "        -10.3898,  -3.0711,  -5.4304], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.264\n",
      "activated x value: tensor([ 0.3531, -6.7760,  6.1768, -1.9680,  1.2659, -3.3407, 11.7078, -3.7650,\n",
      "        -1.5567, -2.8811], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7118], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1359e+01, -1.8488e+01, -5.5350e+00, -1.3680e+01, -1.0446e+01,\n",
      "        -1.5052e+01, -3.9988e-03, -1.5477e+01, -1.3269e+01, -1.4593e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-1.1273,  0.3972, -1.7340,  3.4272, -2.5715,  3.1440, -2.7643, -0.0794,\n",
      "         0.9978,  0.4885], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1171], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2444, -3.7199, -5.8511, -0.6899, -6.6886, -0.9731, -6.8814, -4.1965,\n",
      "        -3.1193, -3.6286], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.973\n",
      "activated x value: tensor([-7.3301e+00, -5.3825e+00, -3.9439e+00,  5.5162e+00,  3.5960e+00,\n",
      "         3.6726e-03, -5.9907e+00,  4.5030e+00,  1.6756e+00,  6.6698e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0648], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.3949, -12.4472, -11.0086,  -1.5486,  -3.4688,  -7.0611, -13.0554,\n",
      "         -2.5618,  -5.3891,  -0.3950], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-3.2597, -2.2078,  1.6072, 11.4741, -4.5240,  0.0351, -4.9310,  2.5596,\n",
      "        -0.2661, -1.0566], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.4743], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4734e+01, -1.3682e+01, -9.8671e+00, -2.1076e-04, -1.5998e+01,\n",
      "        -1.1439e+01, -1.6405e+01, -8.9147e+00, -1.1740e+01, -1.2531e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-1.2587, -5.1117,  2.1139,  0.9374,  0.5950, -2.9670, -5.5478, 10.0850,\n",
      "        -0.8010,  0.9485], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0857], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1344e+01, -1.5197e+01, -7.9718e+00, -9.1483e+00, -9.4907e+00,\n",
      "        -1.3053e+01, -1.5633e+01, -6.6757e-04, -1.0887e+01, -9.1372e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.2500, -3.7006, -1.4075, -0.7054,  0.6198, -0.6344, -3.3792,  6.6291,\n",
      "         0.8790,  4.1339], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7153], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.9653, -10.4159,  -8.1228,  -7.4206,  -6.0954,  -7.3497, -10.0944,\n",
      "         -0.0862,  -5.8363,  -2.5813], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.086\n",
      "activated x value: tensor([ 0.5690, -6.7963,  5.0017,  0.0088,  1.1481,  3.8120,  5.5848, -7.0776,\n",
      "         0.9044, -2.6363], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1500], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.5811, -12.9463,  -1.1483,  -6.1412,  -5.0019,  -2.3380,  -0.5652,\n",
      "        -13.2276,  -5.2456,  -8.7863], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.338\n",
      "activated x value: tensor([ 11.0584, -12.7040,   2.0198,  -0.4172,  -4.9335,   3.9384,  -2.0045,\n",
      "         -1.5123,   5.8339,  -0.3937], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.0647], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.3171e-03, -2.3769e+01, -9.0449e+00, -1.1482e+01, -1.5998e+01,\n",
      "        -7.1263e+00, -1.3069e+01, -1.2577e+01, -5.2308e+00, -1.1458e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 2.3595, -7.1866,  0.0932,  4.2858, -1.8611,  8.6574,  0.1271, -7.9384,\n",
      "         3.0038, -2.0927], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6756], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.3161, -15.8622,  -8.5825,  -4.3898, -10.5367,  -0.0182,  -8.5485,\n",
      "        -16.6140,  -5.6718, -10.7684], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([-1.7742, -8.6597, -3.2982,  1.6556,  1.0034,  1.2233, -4.4058, 10.6614,\n",
      "        -0.8053,  3.8006], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6627], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2437e+01, -1.9322e+01, -1.3961e+01, -9.0071e+00, -9.6593e+00,\n",
      "        -9.4394e+00, -1.5069e+01, -1.3294e-03, -1.1468e+01, -6.8621e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([  0.5134, -12.4882,   3.8099,  -3.7206,   8.0736,  -0.4291,   3.4681,\n",
      "         -1.2885,   1.1008,  -0.9811], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0992], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5858, -20.5874,  -4.2893, -11.8198,  -0.0256,  -8.5283,  -4.6311,\n",
      "         -9.3877,  -6.9984,  -9.0803], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.026\n",
      "activated x value: tensor([ 2.0722, -2.9153,  0.6717,  3.4198, -8.5734,  6.0268, -7.1765, -0.7669,\n",
      "         7.5501, -0.2366], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7652], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6930, -10.6805,  -7.0935,  -4.3454, -16.3386,  -1.7384, -14.9417,\n",
      "         -8.5321,  -0.2151,  -8.0018], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.215\n",
      "activated x value: tensor([-8.7385, -0.4700,  2.1216,  5.6414, -3.4240, -0.5832, -5.8732,  6.5417,\n",
      "         1.9251,  3.1689], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9232], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.6617,  -7.3932,  -4.8016,  -1.2818, -10.3472,  -7.5063, -12.7964,\n",
      "         -0.3815,  -4.9981,  -3.7542], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.282\n",
      "activated x value: tensor([ 6.5315, -5.8003,  7.1549,  2.3028, -6.5834,  2.0401, -1.2370, -2.3957,\n",
      "         2.4914, -4.8087], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5994], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.0679, -13.3997,  -0.4445,  -5.2965, -14.1828,  -5.5592,  -8.8364,\n",
      "         -9.9951,  -5.1080, -12.4081], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -1.068\n",
      "activated x value: tensor([-5.8017,  0.9268,  2.3996,  1.4407,  1.3580, -3.3768, -0.7121,  4.2374,\n",
      "        -0.8444,  1.2155], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5561], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3578,  -3.6293,  -2.1565,  -3.1154,  -3.1981,  -7.9329,  -5.2682,\n",
      "         -0.3187,  -5.4005,  -3.3406], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.319\n",
      "activated x value: tensor([-4.4218,  1.1782, -3.1728,  2.0403,  4.5193, -2.7975, -0.2277, -2.0054,\n",
      "         1.3481,  4.0902], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1201], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.5419, -3.9419, -8.2929, -3.0798, -0.6009, -7.9177, -5.3479, -7.1255,\n",
      "        -3.7720, -1.0299], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.601\n",
      "activated x value: tensor([-4.3983,  6.0296,  0.0077,  1.6521, -4.6829,  0.9758, -0.8181, -0.5350,\n",
      "         2.3390,  0.4561], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0809], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.4793,  -0.0513,  -6.0732,  -4.4289, -10.7639,  -5.1052,  -6.8991,\n",
      "         -6.6159,  -3.7420,  -5.6248], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.051\n",
      "activated x value: tensor([-5.6189, -7.7759,  1.2424, -1.8106, 12.4258, -4.2726,  3.3120, -1.0312,\n",
      "        -0.2309,  3.5673], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4261], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8045e+01, -2.0202e+01, -1.1184e+01, -1.4237e+01, -2.7180e-04,\n",
      "        -1.6699e+01, -9.1141e+00, -1.3457e+01, -1.2657e+01, -8.8587e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 4.5731, -4.2156,  4.2201,  8.0187, -9.3593,  6.3273, -3.1441, -4.1390,\n",
      "         4.5065, -7.1907], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2565], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.6834, -12.4721,  -4.0364,  -0.2378, -17.6158,  -1.9292, -11.4006,\n",
      "        -12.3955,  -3.7500, -15.4472], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.238\n",
      "activated x value: tensor([-2.7760, -1.4363,  1.6862,  2.0850, -1.5179,  6.3174,  6.6525, -9.0319,\n",
      "         3.9117, -5.6755], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2391], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0151,  -8.6754,  -5.5529,  -5.1540,  -8.7569,  -0.9216,  -0.5866,\n",
      "        -16.2710,  -3.3274, -12.9146], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.922\n",
      "activated x value: tensor([-6.8524, -6.5638, -0.3640,  0.9598, 11.2640, -3.7266, -2.7147, -1.2954,\n",
      "         3.2330,  6.9886], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2781], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8131e+01, -1.7842e+01, -1.1642e+01, -1.0318e+01, -1.4178e-02,\n",
      "        -1.5005e+01, -1.3993e+01, -1.2574e+01, -8.0451e+00, -4.2896e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([-0.4357,  0.8809,  2.1880,  6.6808, -7.3352,  1.2278, -0.2607,  0.5978,\n",
      "        -0.9464, -2.5886], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7036], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1393,  -5.8228,  -4.5157,  -0.0229, -14.0388,  -5.4758,  -6.9643,\n",
      "         -6.1058,  -7.6500,  -9.2923], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([ 3.1661, -3.0980,  7.4247,  7.2155, -7.3840,  3.2308, -1.5490, -8.4145,\n",
      "         4.2390, -5.8739], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0570], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.8909, -11.1549,  -0.6323,  -0.8415, -15.4410,  -4.8262,  -9.6060,\n",
      "        -16.4715,  -3.8180, -13.9309], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.632\n",
      "activated x value: tensor([-1.4130, -5.0566,  0.1247,  0.5254,  2.5695,  4.5259,  5.1804, -6.5575,\n",
      "         1.4479, -1.7782], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6723], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0853, -10.7289,  -5.5476,  -5.1468,  -3.1028,  -1.1464,  -0.4919,\n",
      "        -12.2298,  -4.2244,  -7.4505], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.146\n",
      "activated x value: tensor([-6.5689,  5.0212,  1.1139,  1.8880, -2.4019,  3.2808, -1.6143, -5.0373,\n",
      "         3.5950,  0.4939], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4214], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.9904,  -0.4002,  -4.3076,  -3.5335,  -7.8233,  -2.1406,  -7.0357,\n",
      "        -10.4587,  -1.8264,  -4.9275], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.400\n",
      "activated x value: tensor([-8.9544,  9.0811,  0.0976,  3.3236, -3.5192, -1.5676, -1.9825,  0.9636,\n",
      "         1.2830,  2.1377], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0861], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8040e+01, -4.9887e-03, -8.9884e+00, -5.7624e+00, -1.2605e+01,\n",
      "        -1.0654e+01, -1.1069e+01, -8.1225e+00, -7.8031e+00, -6.9484e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-0.9353, -5.4021, -1.7339,  3.0632,  2.6007,  5.9166,  2.0136, -5.7800,\n",
      "         3.2500, -3.5701], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0865], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0218, -11.4886,  -7.8204,  -3.0233,  -3.4858,  -0.1700,  -4.0729,\n",
      "        -11.8666,  -2.8365,  -9.6567], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.170\n",
      "activated x value: tensor([-4.6108, -1.3065, -3.8578,  1.4532,  2.6150,  0.3625, -3.1484,  2.5371,\n",
      "         0.2290,  5.8670], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9580], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-10.5688,  -7.2645,  -9.8158,  -4.5047,  -3.3430,  -5.5954,  -9.1064,\n",
      "         -3.4209,  -5.7289,  -0.0909], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.091\n",
      "activated x value: tensor([-6.7643,  0.2840, -3.0023,  1.2889,  2.2529,  3.2246,  0.7503, -4.2680,\n",
      "         4.2641,  2.1795], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8019], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.5662,  -4.5179,  -7.8042,  -3.5130,  -2.5490,  -1.5773,  -4.0517,\n",
      "         -9.0700,  -0.5378,  -2.6224], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.538\n",
      "activated x value: tensor([-7.1789, -0.7290, -2.2979,  1.5197,  2.1656,  0.7085, -2.9888,  1.2045,\n",
      "         1.7461,  5.8332], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9040], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.0828,  -6.6330,  -8.2019,  -4.3842,  -3.7383,  -5.1954,  -8.8928,\n",
      "         -4.6995,  -4.1579,  -0.0707], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.071\n",
      "activated x value: tensor([-2.6988, -6.6675, -0.8956, -3.0375,  7.0153, -2.0192,  0.8597,  0.5714,\n",
      "         1.7955,  4.4023], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0951], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7938, -13.7626,  -7.9907, -10.1326,  -0.0798,  -9.1143,  -6.2354,\n",
      "         -6.5237,  -5.2996,  -2.6927], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.080\n",
      "activated x value: tensor([-3.1717, -5.9971,  4.5014, -2.7879,  2.7352,  2.8958,  8.0848, -3.5481,\n",
      "        -0.9720, -1.8624], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1224], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2941, -14.1195,  -3.6210, -10.9103,  -5.3872,  -5.2266,  -0.0376,\n",
      "        -11.6705,  -9.0944,  -9.9848], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.038\n",
      "activated x value: tensor([-1.7595, -4.5654, -1.6036,  8.8462, -4.2647,  4.8550, -7.1053, -0.4665,\n",
      "         3.2921,  2.7922], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8707], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6302, -13.4361, -10.4743,  -0.0245, -13.1354,  -4.0157, -15.9760,\n",
      "         -9.3372,  -5.5786,  -6.0785], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([-7.0862, -9.0714,  3.7667, -2.5622, 10.1316, -7.9991,  8.1591,  1.0713,\n",
      "         0.1122,  2.7308], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2640], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.3503, -19.3355,  -6.4973, -12.8262,  -0.1324, -18.2632,  -2.1049,\n",
      "         -9.1928, -10.1518,  -7.5332], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -2.105\n",
      "activated x value: tensor([-2.6735, -8.4271, -5.7902,  2.6205, -0.6476,  1.7751, -5.7979,  8.2241,\n",
      "         2.4255,  7.4531], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6100], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2836, -17.0371, -14.4003,  -5.9895,  -9.2577,  -6.8350, -14.4080,\n",
      "         -0.3859,  -6.1845,  -1.1570], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.157\n",
      "activated x value: tensor([ 14.0341, -12.5085,   2.6378,   5.9666, -11.1177,   9.4654,  -6.4871,\n",
      "         -2.0380,   6.9039,  -6.8434], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.0455], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1432e-02, -2.6554e+01, -1.1408e+01, -8.0789e+00, -2.5163e+01,\n",
      "        -4.5801e+00, -2.0533e+01, -1.6083e+01, -7.1416e+00, -2.0889e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-2.2178, -3.7643, 14.2381,  2.9680, -2.5429, -1.7783,  2.8587, -7.6100,\n",
      "         1.4086, -4.3748], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.2381], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6456e+01, -1.8002e+01, -2.6703e-05, -1.1270e+01, -1.6781e+01,\n",
      "        -1.6016e+01, -1.1379e+01, -2.1848e+01, -1.2830e+01, -1.8613e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-1.4044, -9.6615, -0.9639, -1.8995,  2.5448, -1.7617, -2.1352,  5.3383,\n",
      "         1.2363,  8.2109], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2704], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.6747, -17.9319,  -9.2343, -10.1699,  -5.7256, -10.0321, -10.4056,\n",
      "         -2.9321,  -7.0340,  -0.0594], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.059\n",
      "activated x value: tensor([ 2.5239, -1.4012,  1.6327,  7.2094, -5.0847,  2.6048, -5.1904, -0.5953,\n",
      "         1.7087, -2.4220], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2368], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.7129,  -8.6380,  -5.6041,  -0.0274, -12.3215,  -4.6320, -12.4272,\n",
      "         -7.8321,  -5.5281,  -9.6588], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.027\n",
      "activated x value: tensor([10.5867, -7.6765,  2.9195,  5.9469, -6.7482,  3.4229, -3.6375, -0.5651,\n",
      "         0.1132, -3.5097], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.5976], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0885e-02, -1.8274e+01, -7.6781e+00, -4.6507e+00, -1.7346e+01,\n",
      "        -7.1748e+00, -1.4235e+01, -1.1163e+01, -1.0484e+01, -1.4107e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-3.9441, -2.4456,  0.2542, -0.3597,  4.3095, -1.4830,  0.3375, -1.4129,\n",
      "         0.3470,  3.4337], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7075], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6516, -7.1531, -4.4533, -5.0672, -0.3980, -6.1905, -4.3700, -6.1204,\n",
      "        -4.3605, -1.2738], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.274\n",
      "activated x value: tensor([-6.2954, -0.8397, -3.3691,  4.5360,  0.7121,  0.8384, -3.1817, -0.7713,\n",
      "         3.6753,  4.7438], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5333], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8287,  -6.3729,  -8.9024,  -0.9972,  -4.8212,  -4.6949,  -8.7149,\n",
      "         -6.3045,  -1.8580,  -0.7895], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.789\n",
      "activated x value: tensor([ 11.1791, -12.4568,   0.0137,   1.5035,  -6.1147,   5.1718,  -4.0967,\n",
      "         -1.4577,   5.3678,   0.9615], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1847], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.5561e-03, -2.3641e+01, -1.1171e+01, -9.6811e+00, -1.7299e+01,\n",
      "        -6.0129e+00, -1.5281e+01, -1.2642e+01, -5.8168e+00, -1.0223e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-6.2369,  0.7190,  4.3189,  3.1479, -4.2952, -5.3551, -5.2604,  6.9017,\n",
      "         1.1700,  4.9232], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1189], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.3558,  -6.3999,  -2.8000,  -3.9710, -11.4141, -12.4740, -12.3793,\n",
      "         -0.2172,  -5.9489,  -2.1957], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.217\n",
      "activated x value: tensor([-1.9365, -5.8199,  0.7946,  0.2774,  0.8864,  0.4269, -3.0059,  1.7552,\n",
      "         4.9433,  0.8119], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0496], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9861, -10.8695,  -4.2549,  -4.7722,  -4.1632,  -4.6227,  -8.0555,\n",
      "         -3.2944,  -0.1063,  -4.2377], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.106\n",
      "activated x value: tensor([  5.7970, -10.7206,   1.2650,   0.9986,  -1.8306,   2.8095,  -3.8319,\n",
      "          0.7771,   1.9001,   2.1065], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9119], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1150, -16.6325,  -4.6469,  -4.9134,  -7.7426,  -3.1024,  -9.7438,\n",
      "         -5.1348,  -4.0119,  -3.8055], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.115\n",
      "activated x value: tensor([-5.5438, -1.5342,  3.8325,  6.9787, -3.5711,  3.1204, -3.5838, -1.9760,\n",
      "         3.0107, -0.5479], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0594], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.6032,  -8.5935,  -3.2268,  -0.0806, -10.6304,  -3.9390, -10.6432,\n",
      "         -9.0354,  -4.0487,  -7.6072], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([-2.5315, -3.9343,  2.2250, -3.2104,  2.9367, -3.3695, 10.3923, -0.4582,\n",
      "        -0.7277, -0.3974], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3932], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2925e+01, -1.4327e+01, -8.1682e+00, -1.3604e+01, -7.4565e+00,\n",
      "        -1.3763e+01, -9.2220e-04, -1.0851e+01, -1.1121e+01, -1.0791e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-7.3183, -0.9861, -1.9521,  1.6420,  4.8688,  0.9012, -1.2835, -1.5421,\n",
      "         0.7985,  3.1190], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0977], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.4160,  -6.0838,  -7.0498,  -3.4557,  -0.2289,  -4.1965,  -6.3812,\n",
      "         -6.6398,  -4.2992,  -1.9787], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.979\n",
      "activated x value: tensor([ 1.0472, -7.0509,  7.6989,  1.7369,  2.8681,  3.3153,  2.9457, -8.4664,\n",
      "         0.0293, -4.8064], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7318], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6846, -14.7827,  -0.0329,  -5.9949,  -4.8636,  -4.4165,  -4.7861,\n",
      "        -16.1982,  -7.7025, -12.5381], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([-4.2838, -3.2674,  9.1858,  4.9409, -2.2885, -4.5644,  5.0657, -0.1176,\n",
      "        -1.5791, -2.4237], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2160], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.4998, -12.4834,  -0.0303,  -4.2751, -11.5045, -13.7804,  -4.1503,\n",
      "         -9.3336, -10.7951, -11.6398], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.030\n",
      "activated x value: tensor([-7.2901, -0.0740,  3.0028,  3.1090, -0.4519, -1.4594,  0.7303, -3.0047,\n",
      "         6.1519,  0.0405], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2483], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.5384,  -6.3222,  -3.2455,  -3.1393,  -6.7001,  -7.7076,  -5.5179,\n",
      "         -9.2530,  -0.0964,  -6.2078], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.096\n",
      "activated x value: tensor([-4.7516,  0.8736,  1.2430,  5.7857, -2.9837,  0.0914, -5.9151,  0.4267,\n",
      "         3.2520,  1.5677], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8993], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6509,  -5.0257,  -4.6564,  -0.1136,  -8.8831,  -5.8079, -11.8145,\n",
      "         -5.4726,  -2.6474,  -4.3317], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.114\n",
      "activated x value: tensor([-3.6397,  5.2644, 11.6985,  6.1854, -8.9489, -0.5604,  1.9178, -7.1185,\n",
      "         3.6846, -8.1180], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([11.7045], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5344e+01, -6.4401e+00, -6.0139e-03, -5.5191e+00, -2.0653e+01,\n",
      "        -1.2265e+01, -9.7867e+00, -1.8823e+01, -8.0200e+00, -1.9822e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-0.5586, -4.5307, -1.0163,  4.6847, -6.0617,  4.9759, -4.8378,  2.4203,\n",
      "         3.3103,  0.7001], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6862], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.2448, -10.2169,  -6.7024,  -1.0015, -11.7478,  -0.7103, -10.5239,\n",
      "         -3.2658,  -2.3759,  -4.9861], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.710\n",
      "activated x value: tensor([-5.4665e+00, -4.0443e+00, -1.1313e+00,  9.1517e-01,  4.3959e+00,\n",
      "        -4.4869e-03,  1.2021e-01, -6.0693e-01,  6.6907e-03,  5.8730e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0934], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.5599, -10.1378,  -7.2248,  -5.1783,  -1.6975,  -6.0979,  -5.9732,\n",
      "         -6.7004,  -6.0867,  -0.2205], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.220\n",
      "activated x value: tensor([ 1.0302, -0.4072, -1.4833,  7.2089, -3.6998,  4.3289, -4.8222, -1.6221,\n",
      "         2.9600, -4.3374], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2796], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.2494,  -7.6869,  -8.7630,  -0.0708, -10.9794,  -2.9508, -12.1018,\n",
      "         -8.9018,  -4.3196, -11.6171], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.071\n",
      "activated x value: tensor([-3.8009,  0.9331,  6.3393,  4.0283, -7.3054, -2.0819,  2.2629,  0.3008,\n",
      "         0.8308, -1.8665], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4594], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2603,  -5.5262,  -0.1201,  -2.4311, -13.7648,  -8.5413,  -4.1964,\n",
      "         -6.1586,  -5.6286,  -8.3258], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.120\n",
      "activated x value: tensor([-3.5805, -1.1338,  2.4999, -0.4451,  1.0203,  0.3122,  3.5122, -3.5990,\n",
      "         0.1225,  0.6529], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9874], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5679, -5.1211, -1.4875, -4.4325, -2.9671, -3.6752, -0.4752, -7.5863,\n",
      "        -3.8648, -3.3344], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -2.967\n",
      "activated x value: tensor([-1.3533, -2.8793, -3.4315,  1.1244,  3.1573,  0.4776, -3.3006,  2.6822,\n",
      "        -1.0135,  4.4660], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8719], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.2252, -7.7512, -8.3034, -3.7474, -1.7145, -4.3943, -8.1724, -2.1897,\n",
      "        -5.8853, -0.4059], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.406\n",
      "activated x value: tensor([ 1.1701, -3.3982,  1.7195, -0.4845,  1.6117,  4.3161,  4.3941, -7.0146,\n",
      "         0.9538, -2.8390], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1532], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.9831,  -8.5514,  -3.4337,  -5.6377,  -3.5415,  -0.8371,  -0.7591,\n",
      "        -12.1678,  -4.1994,  -7.9922], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.837\n",
      "activated x value: tensor([-2.5038, -4.6952, -0.1928, -0.5090,  0.9541,  0.5319, -1.8176,  4.4688,\n",
      "        -0.2199,  4.0606], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0241], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5280, -9.7193, -5.2169, -5.5331, -4.0700, -4.4922, -6.8417, -0.5554,\n",
      "        -5.2441, -0.9635], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.555\n",
      "activated x value: tensor([-5.0995, -6.0449, -0.1422,  3.4422, -0.2171, -3.2400, -7.9966, 12.2852,\n",
      "         1.3564,  5.4997], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.2865], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7386e+01, -1.8331e+01, -1.2429e+01, -8.8443e+00, -1.2504e+01,\n",
      "        -1.5527e+01, -2.0283e+01, -1.2999e-03, -1.0930e+01, -6.7868e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.1145, -0.1542,  0.6963,  0.4885, -2.1859,  2.9231,  2.0322, -2.4138,\n",
      "         1.2860, -1.3279], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5533], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.6678, -3.7075, -2.8570, -3.0648, -5.7392, -0.6302, -1.5211, -5.9671,\n",
      "        -2.2673, -4.8812], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.630\n",
      "activated x value: tensor([-6.6082,  6.4715,  0.2255,  0.7464, -1.3008, -1.0304, -0.5028,  1.1928,\n",
      "         0.7612,  0.5908], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4897], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.0978,  -0.0181,  -6.2642,  -5.7433,  -7.7905,  -7.5201,  -6.9925,\n",
      "         -5.2968,  -5.7285,  -5.8989], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([-1.3578, -2.9373, -2.7728,  5.8932, -2.1492,  4.6340, -4.8378, -0.6553,\n",
      "         2.2068,  2.7175], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1959], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5537,  -9.1332,  -8.9687,  -0.3027,  -8.3451,  -1.5619, -11.0337,\n",
      "         -6.8513,  -3.9891,  -3.4784], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.303\n",
      "activated x value: tensor([ 5.5958, -6.2054, -2.5344,  2.5289, -4.1941,  4.3356, -2.9532, -0.7351,\n",
      "         2.8851,  2.4208], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9610], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.3652, -12.1664,  -8.4954,  -3.4321, -10.1551,  -1.6254,  -8.9142,\n",
      "         -6.6961,  -3.0759,  -3.5402], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.365\n",
      "activated x value: tensor([ 13.9913, -12.0449,  -0.1927,   3.3094,  -7.6459,   6.8685, -10.0541,\n",
      "          1.2036,   5.8840,  -0.1197], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.9924], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1349e-03, -2.6037e+01, -1.4185e+01, -1.0683e+01, -2.1638e+01,\n",
      "        -7.1239e+00, -2.4047e+01, -1.2789e+01, -8.1084e+00, -1.4112e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 9.7283, -8.7042,  1.7588,  1.9760, -4.5517,  3.0496, -2.7212, -2.0556,\n",
      "         3.8212, -1.8751], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7331], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.7626e-03, -1.8437e+01, -7.9743e+00, -7.7571e+00, -1.4285e+01,\n",
      "        -6.6835e+00, -1.2454e+01, -1.1789e+01, -5.9119e+00, -1.1608e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([ -1.3001, -10.0651,  -6.2251,  -0.1635,   7.4013,   0.7248,   1.6969,\n",
      "          2.3778,   0.5949,   4.5719], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4708], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.7710, -17.5359, -13.6959,  -7.6343,  -0.0695,  -6.7461,  -5.7739,\n",
      "         -5.0930,  -6.8759,  -2.8989], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.070\n",
      "activated x value: tensor([-3.6376, -4.2516, -0.5570, -0.6023,  6.4019, -0.7620, -0.8065,  1.0082,\n",
      "        -0.0242,  2.9948], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4438], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0814, -10.6954,  -7.0008,  -7.0460,  -0.0419,  -7.2057,  -7.2503,\n",
      "         -5.4355,  -6.4680,  -3.4490], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([-0.1579, -3.1846,  1.9308,  0.2423, -0.8704,  2.2233,  7.5659, -7.0994,\n",
      "         1.4348, -1.7327], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5778], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7356e+00, -1.0762e+01, -5.6469e+00, -7.3355e+00, -8.4482e+00,\n",
      "        -5.3545e+00, -1.1889e-02, -1.4677e+01, -6.1430e+00, -9.3105e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-1.6802,  2.2404,  2.4168,  6.8572, -5.6364,  3.2644, -1.0116, -4.6510,\n",
      "         2.9474, -4.0356], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9247], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.6049,  -4.6844,  -4.5079,  -0.0675, -12.5611,  -3.6603,  -7.9363,\n",
      "        -11.5757,  -3.9773, -10.9603], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.068\n",
      "activated x value: tensor([ 1.0172, -4.3837,  3.9688,  5.2086, -6.3530,  5.0584,  2.0531, -8.0106,\n",
      "         3.7876, -2.8180], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1045], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.0873, -10.4882,  -2.1358,  -0.8959, -12.4576,  -1.0461,  -4.0514,\n",
      "        -14.1151,  -2.3169,  -8.9226], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.317\n",
      "activated x value: tensor([-2.7125, -5.7456,  0.2663, -0.5060,  5.1972,  0.6540,  0.7343,  0.0477,\n",
      "         0.0718,  2.2079], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2881], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.0006, -11.0337,  -5.0218,  -5.7941,  -0.0909,  -4.6341,  -4.5538,\n",
      "         -5.2404,  -5.2163,  -3.0802], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.091\n",
      "activated x value: tensor([-5.9728, -5.1830, -1.9332,  6.5998, -1.2801,  6.7617, -4.9305, -2.2516,\n",
      "         5.5020,  1.4230], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5224], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.4952, -12.7053,  -9.4556,  -0.9225,  -8.8025,  -0.7607, -12.4528,\n",
      "         -9.7740,  -2.0204,  -6.0994], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.923\n",
      "activated x value: tensor([10.8398, -8.3160,  2.1365,  1.6827, -7.9621,  7.0096,  4.4687, -5.6603,\n",
      "         3.3838, -7.2851], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.8638], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0240, -19.1798,  -8.7273,  -9.1811, -18.8259,  -3.8542,  -6.3951,\n",
      "        -16.5241,  -7.4800, -18.1490], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-2.7683, -9.3927, -0.1560,  3.8306, -2.5095,  7.3002, -6.3047, -5.7317,\n",
      "        14.7721, -0.6262], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.7727], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-1.7541e+01, -2.4165e+01, -1.4929e+01, -1.0942e+01, -1.7282e+01,\n",
      "        -7.4724e+00, -2.1077e+01, -2.0504e+01, -5.8746e-04, -1.5399e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-9.6026,  1.2210,  0.3540,  2.7873, -3.1211,  2.1518, -2.9042,  0.5760,\n",
      "         7.0001,  0.9772], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0308], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.6333,  -5.8098,  -6.6768,  -4.2435, -10.1519,  -4.8790,  -9.9350,\n",
      "         -6.4548,  -0.0307,  -6.0536], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.031\n",
      "activated x value: tensor([-5.0807,  2.4709, 12.4159,  4.3009, -5.4926, -3.2353,  4.6742, -8.7200,\n",
      "         3.2578, -4.0505], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4168], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7498e+01, -9.9459e+00, -8.8692e-04, -8.1159e+00, -1.7909e+01,\n",
      "        -1.5652e+01, -7.7426e+00, -2.1137e+01, -9.1590e+00, -1.6467e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([  3.8618, -12.0513,  -2.8682,   8.5756,  -2.7174,   5.4810,  -8.0424,\n",
      "          0.4545,   5.2926,   1.8684], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6649], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.8031, -20.7162, -11.5331,  -0.0892, -11.3823,  -3.1838, -16.7073,\n",
      "         -8.2104,  -3.3722,  -6.7965], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -6.796\n",
      "activated x value: tensor([-8.6617,  0.6189, -2.2553,  1.4008,  5.6682,  1.8146, -1.1961, -1.2756,\n",
      "         1.0599,  2.3211], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7536], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.4153,  -5.1347,  -8.0089,  -4.3528,  -0.0854,  -3.9390,  -6.9497,\n",
      "         -7.0292,  -4.6937,  -3.4325], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.085\n",
      "activated x value: tensor([-1.2021, -3.2870,  6.0764,  0.0572, -0.2203,  3.7063,  5.9653, -9.1201,\n",
      "         3.2815, -5.0806], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7964], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9985, -10.0835,  -0.7200,  -6.7392,  -7.0167,  -3.0901,  -0.8312,\n",
      "        -15.9166,  -3.5149, -11.8770], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -3.090\n",
      "activated x value: tensor([  0.9213,  -3.5537,   2.3735,   0.4151,  -0.2907,   7.4247,   3.1321,\n",
      "        -12.5053,   6.1851,  -3.5441], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6966], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.7754, -11.2503,  -5.3232,  -7.2815,  -7.9873,  -0.2719,  -4.5645,\n",
      "        -20.2019,  -1.5115, -11.2407], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.272\n",
      "activated x value: tensor([ -4.5107,   1.8666,  12.3786,   5.8850, -11.1438,   1.8391,   2.2850,\n",
      "         -9.2414,   3.7751,  -4.3151], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.3804], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6891e+01, -1.0514e+01, -1.7900e-03, -6.4954e+00, -2.3524e+01,\n",
      "        -1.0541e+01, -1.0095e+01, -2.1622e+01, -8.6053e+00, -1.6695e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-2.2280,  0.8032,  1.1992,  0.5935, -1.4837,  3.1606, -1.3476, -3.3192,\n",
      "         4.4192, -2.2880], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7423], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9703, -3.9391, -3.5431, -4.1488, -6.2260, -1.5818, -6.0900, -8.0615,\n",
      "        -0.3232, -7.0303], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.323\n",
      "activated x value: tensor([-8.4433, -2.2421,  1.8164,  0.0269,  1.2680, -4.5276, -2.9148,  9.2056,\n",
      "         1.2700,  4.9865], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2217], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7665e+01, -1.1464e+01, -7.4053e+00, -9.1948e+00, -7.9537e+00,\n",
      "        -1.3749e+01, -1.2137e+01, -1.6035e-02, -7.9517e+00, -4.2352e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([ 3.4533, -8.3563, -4.2454,  0.1264, -3.3734,  2.2508, -5.6168, 11.0095,\n",
      "         2.8768,  2.9550], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.0108], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5575e+00, -1.9367e+01, -1.5256e+01, -1.0884e+01, -1.4384e+01,\n",
      "        -8.7600e+00, -1.6628e+01, -1.3103e-03, -8.1340e+00, -8.0558e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-9.2449,  8.3504,  0.7899,  3.1606, -2.9673, -1.6588, -0.9994,  0.6299,\n",
      "         0.9318,  1.7919], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3591], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7604e+01, -8.6613e-03, -7.5691e+00, -5.1985e+00, -1.1326e+01,\n",
      "        -1.0018e+01, -9.3585e+00, -7.7292e+00, -7.4272e+00, -6.5671e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([  8.1590, -11.7808,   4.8114,   0.2080,  -2.9543,   4.1118,   5.1240,\n",
      "         -6.5060,   2.9136,  -3.6329], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2601], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1011, -20.0409,  -3.4486,  -8.0521, -11.2143,  -4.1482,  -3.1361,\n",
      "        -14.7661,  -5.3465, -11.8930], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.101\n",
      "activated x value: tensor([ 7.2296e-03, -7.4359e+00, -1.2376e+00, -7.7150e-01, -5.4253e-01,\n",
      "        -8.9517e-02, -5.5255e+00,  9.2010e+00,  7.1928e-01,  5.2846e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2213], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2140, -16.6572, -10.4589,  -9.9928,  -9.7638,  -9.3108, -14.7467,\n",
      "         -0.0202,  -8.5020,  -3.9366], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-10.1200,   3.4489,   0.4523,   0.1889,   1.9497,   1.2877,  -1.4930,\n",
      "          1.5207,   5.7873,  -3.1782], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9293], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.0493,  -2.4804,  -5.4770,  -5.7404,  -3.9795,  -4.6416,  -7.4223,\n",
      "         -4.4085,  -0.1419,  -9.1075], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.142\n",
      "activated x value: tensor([-1.4367, -4.9553,  0.5198,  3.6966,  0.5343,  4.5517, -1.3681, -3.5041,\n",
      "         2.2436, -0.9544], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0029], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4395, -9.9582, -4.4830, -1.3062, -4.4685, -0.4511, -6.3709, -8.5070,\n",
      "        -2.7593, -5.9573], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.451\n",
      "activated x value: tensor([ 0.1539, -3.2730,  0.7669,  0.1222,  0.4631,  1.4126,  4.0222, -3.1139,\n",
      "        -0.4008, -0.2043], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2126], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.0588, -7.4856, -3.4457, -4.0904, -3.7495, -2.8001, -0.1905, -7.3266,\n",
      "        -4.6134, -4.4170], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.190\n",
      "activated x value: tensor([  7.2030, -10.4407,   0.5565,   2.0222,  -3.3423,   0.8957,  -4.4712,\n",
      "          0.9389,   1.4774,   4.9152], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3122], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1092, -17.7529,  -6.7557,  -5.2900, -10.6545,  -6.4165, -11.7834,\n",
      "         -6.3733,  -5.8348,  -2.3970], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.109\n",
      "activated x value: tensor([-3.5112, -3.6044,  3.1371, -4.2250,  2.1144, -1.9350, 11.7086, -6.7376,\n",
      "         2.6540,  0.7467], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7090], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5220e+01, -1.5313e+01, -8.5718e+00, -1.5934e+01, -9.5945e+00,\n",
      "        -1.3644e+01, -3.9387e-04, -1.8447e+01, -9.0550e+00, -1.0962e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-3.7549, -1.1234,  7.0188,  1.4318,  3.3200, -1.8764,  2.7241, -7.7522,\n",
      "         1.2471, -1.4146], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0637], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8187,  -8.1872,  -0.0449,  -5.6319,  -3.7438,  -8.9401,  -4.3397,\n",
      "        -14.8159,  -5.8166,  -8.4783], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-5.1926, -7.4671,  3.1425,  2.4321,  2.7966, -3.6306, -3.1943,  5.1083,\n",
      "         0.6000,  5.8118], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3143], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.5069, -13.7815,  -3.1719,  -3.8822,  -3.5177,  -9.9449,  -9.5086,\n",
      "         -1.2061,  -5.7143,  -0.5025], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.206\n",
      "activated x value: tensor([-2.2477, -3.8410,  2.2229, -2.8461,  3.7186,  5.4678,  1.0302, -7.0158,\n",
      "         4.9735, -0.6488], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0763], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3240,  -9.9173,  -3.8534,  -8.9224,  -2.3577,  -0.6085,  -5.0461,\n",
      "        -13.0921,  -1.1028,  -6.7251], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.609\n",
      "activated x value: tensor([-12.5700,   7.3068,   2.0587,   2.3077,  -2.2666,   0.5223,   0.5395,\n",
      "         -2.4043,   3.3470,   0.3557], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3406], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-19.9106,  -0.0339,  -5.2819,  -5.0329,  -9.6072,  -6.8184,  -6.8011,\n",
      "         -9.7450,  -3.9936,  -6.9849], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.034\n",
      "activated x value: tensor([-7.8253,  8.0238,  1.4362,  1.2880, -3.1092,  1.5093,  0.8273, -3.6611,\n",
      "         3.5508, -1.7449], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0400], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.8653,  -0.0162,  -6.6038,  -6.7520, -11.1492,  -6.5307,  -7.2127,\n",
      "        -11.7011,  -4.4892,  -9.7849], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([ 4.8901, -5.0413,  3.9142,  2.2024, -7.5250,  5.4572, -3.4121, -0.3921,\n",
      "         3.0703, -2.5070], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1068], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.2167, -11.1481,  -2.1926,  -3.9044, -13.6318,  -0.6496,  -9.5190,\n",
      "         -6.4989,  -3.0365,  -8.6138], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.650\n",
      "activated x value: tensor([ 3.0217, -6.9635,  6.2837, -0.2996, -2.6216, -0.9013,  1.1622,  3.1868,\n",
      "         0.1427, -2.6300], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3736], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.3518, -13.3371,  -0.0899,  -6.6731,  -8.9952,  -7.2748,  -5.2114,\n",
      "         -3.1867,  -6.2308,  -9.0035], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.090\n",
      "activated x value: tensor([ 0.3026, -6.4567,  9.7194,  1.7251, -1.8293, -1.5308, -0.1492, -2.2331,\n",
      "         1.6957, -2.5063], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7202], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4176e+00, -1.6177e+01, -8.3160e-04, -7.9951e+00, -1.1550e+01,\n",
      "        -1.1251e+01, -9.8694e+00, -1.1953e+01, -8.0245e+00, -1.2227e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-3.6894, -1.6172, -0.9200,  0.1116,  4.4805, -0.5858,  0.1723,  0.5922,\n",
      "         0.3231,  2.2405], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6478], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.3372, -6.2649, -5.5677, -4.5361, -0.1673, -5.2336, -4.4755, -4.0555,\n",
      "        -4.3246, -2.4073], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.167\n",
      "activated x value: tensor([-4.2781, -5.0424, -1.6217, -2.1500,  3.3966, -2.9310, -2.0811,  2.3201,\n",
      "         3.1659,  9.1585], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1653], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3443e+01, -1.4208e+01, -1.0787e+01, -1.1315e+01, -5.7687e+00,\n",
      "        -1.2096e+01, -1.1246e+01, -6.8452e+00, -5.9994e+00, -6.7453e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([ 1.9216, -4.8494, -1.0310,  4.9233, -6.0278,  6.6194, -2.7679,  1.3823,\n",
      "         0.8093, -1.1495], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8032], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.8817, -11.6527,  -7.8342,  -1.8799, -12.8310,  -0.1838,  -9.5711,\n",
      "         -5.4209,  -5.9939,  -7.9527], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.184\n",
      "activated x value: tensor([ 3.2128, -8.4161,  0.6826, -5.7873,  4.2095,  1.4687,  1.5798, -1.3834,\n",
      "         1.1785,  1.2760], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7044], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.4916, -13.1205,  -4.0218, -10.4917,  -0.4949,  -3.2356,  -3.1245,\n",
      "         -6.0878,  -3.5259,  -3.4284], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.495\n",
      "activated x value: tensor([-8.5466,  9.4946,  1.2946,  2.6722, -3.0120, -0.7774, -0.6843, -3.2000,\n",
      "         3.7477,  0.2826], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4993], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8046e+01, -4.7245e-03, -8.2048e+00, -6.8271e+00, -1.2511e+01,\n",
      "        -1.0277e+01, -1.0184e+01, -1.2699e+01, -5.7516e+00, -9.2167e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([ 11.5318, -11.4569,   1.2287,  -0.2207,  -2.7820,   4.4908,   3.7442,\n",
      "         -4.1690,   1.0381,  -1.5912], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5331], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3609e-03, -2.2990e+01, -1.0304e+01, -1.1754e+01, -1.4315e+01,\n",
      "        -7.0423e+00, -7.7890e+00, -1.5702e+01, -1.0495e+01, -1.3124e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.6618,  3.4945,  2.2647,  0.4320, -2.8886,  1.1383,  3.8486, -5.9132,\n",
      "         3.1512, -1.8499], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7690], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4308,  -1.2745,  -2.5043,  -4.3370,  -7.6576,  -3.6307,  -0.9204,\n",
      "        -10.6822,  -1.6178,  -6.6188], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.920\n",
      "activated x value: tensor([ 11.9588, -10.7914,   2.9415,   0.6732,  -6.7151,   4.7223,  -0.2453,\n",
      "         -4.2003,   2.9811,  -0.8705], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.9597], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8705e-04, -2.2751e+01, -9.0182e+00, -1.1287e+01, -1.8675e+01,\n",
      "        -7.2374e+00, -1.2205e+01, -1.6160e+01, -8.9786e+00, -1.2830e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-6.3289, -0.8954, -1.7299, -1.4724,  4.4436, -1.6243, -2.0017,  6.2420,\n",
      "         0.9323,  2.5033], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4215], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7504,  -7.3168,  -8.1514,  -7.8939,  -1.9779,  -8.0458,  -8.4232,\n",
      "         -0.1794,  -5.4892,  -3.9182], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.179\n",
      "activated x value: tensor([-5.5921, -0.9447,  8.6375,  1.3989,  2.1200, -6.1495, -0.9671, -2.5056,\n",
      "         3.3014,  0.0872], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6448], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4237e+01, -9.5895e+00, -7.3290e-03, -7.2460e+00, -6.5248e+00,\n",
      "        -1.4794e+01, -9.6120e+00, -1.1150e+01, -5.3435e+00, -8.5576e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([ 1.9584, -7.4822, -0.9879,  4.0438, -2.8800,  7.6386, -7.5520,  1.4298,\n",
      "         4.8851, -0.1603], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7314], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.7730, -15.2136,  -8.7193,  -3.6876, -10.6113,  -0.0928, -15.2834,\n",
      "         -6.3015,  -2.8462,  -7.8916], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.093\n",
      "activated x value: tensor([-5.4366, -2.2355, -5.9693,  0.7904,  4.6427,  2.8779, -2.8672,  3.5404,\n",
      "         1.1496,  2.4818], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1566], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5932,  -7.3921, -11.1259,  -4.3661,  -0.5139,  -2.2787,  -8.0238,\n",
      "         -1.6162,  -4.0069,  -2.6748], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.514\n",
      "activated x value: tensor([ 0.5668, -3.7825, -8.3048, -0.2051, -1.6964,  1.2216, -4.7337, 11.3058,\n",
      "         2.1830,  4.4203], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.3071], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0740e+01, -1.5090e+01, -1.9612e+01, -1.1512e+01, -1.3003e+01,\n",
      "        -1.0085e+01, -1.6041e+01, -1.2074e-03, -9.1240e+00, -6.8867e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 2.7034e-01, -4.3969e+00,  2.5386e-03,  2.0343e+00, -1.2365e+00,\n",
      "        -2.8530e+00, -3.9897e+00,  4.1509e+00,  1.5147e+00,  4.7668e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2777], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.0073, -9.6745, -5.2751, -3.2433, -6.5141, -8.1307, -9.2674, -1.1268,\n",
      "        -3.7630, -0.5109], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.511\n",
      "activated x value: tensor([ 1.3524, -3.4417, -1.2631,  1.6085,  0.3108,  6.5054,  0.4791, -6.2554,\n",
      "         3.5712, -4.0080], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5743], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.2220, -10.0160,  -7.8374,  -4.9658,  -6.2635,  -0.0689,  -6.0952,\n",
      "        -12.8297,  -3.0031, -10.5823], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.069\n",
      "activated x value: tensor([-1.6389, -0.3849,  0.4200,  3.6782, -5.7730,  3.4061,  0.3005, -0.3292,\n",
      "         1.2985, -1.4319], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3579], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.9968,  -4.7428,  -3.9379,  -0.6797, -10.1310,  -0.9519,  -4.0574,\n",
      "         -4.6871,  -3.0595,  -5.7899], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.952\n",
      "activated x value: tensor([ -2.6947, -12.0392,  -2.6857,  -8.4758,   7.3226,   2.5475,   4.8044,\n",
      "         -2.2818,   6.6826,   6.2071], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9875], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6821, -20.0267, -10.6732, -16.4633,  -0.6649,  -5.4400,  -3.1831,\n",
      "        -10.2693,  -1.3048,  -1.7804], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.665\n",
      "activated x value: tensor([ 1.3027, -7.1426, -1.9463,  0.7584,  0.7943, 13.0269, -2.3335, -7.6667,\n",
      "         6.2764, -1.9327], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.0281], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1725e+01, -2.0171e+01, -1.4974e+01, -1.2270e+01, -1.2234e+01,\n",
      "        -1.1883e-03, -1.5362e+01, -2.0695e+01, -6.7517e+00, -1.4961e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.4205, -6.2708,  2.4810,  0.6085,  3.5072,  3.8053,  0.6317, -2.5834,\n",
      "         0.8958,  1.2497], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6051], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.0256, -10.8759,  -2.1241,  -3.9966,  -1.0979,  -0.7998,  -3.9734,\n",
      "         -7.1885,  -3.7093,  -3.3554], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.800\n",
      "activated x value: tensor([-2.8750, -1.7431,  0.1946,  0.6554,  1.9160,  0.5912, -1.5290,  0.2394,\n",
      "        -0.1745,  2.7588], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.4038], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.2788, -5.1470, -3.2093, -2.7484, -1.4879, -2.8126, -4.9329, -3.1644,\n",
      "        -3.5784, -0.6451], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -3.164\n",
      "activated x value: tensor([ 11.7549, -10.3471,   2.7835,   2.1107,  -5.8761,   5.1111,   1.9368,\n",
      "         -5.4337,   2.0382,  -3.2501], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7565], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6079e-03, -2.2104e+01, -8.9730e+00, -9.6458e+00, -1.7633e+01,\n",
      "        -6.6454e+00, -9.8198e+00, -1.7190e+01, -9.7183e+00, -1.5007e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 0.5876, -9.8192, -3.1151,  2.0268, -1.0466,  1.5046, -6.1799,  9.1124,\n",
      "         0.3474,  5.8981], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1534], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.5659, -18.9727, -12.2685,  -7.1267, -10.2000,  -7.6489, -15.3333,\n",
      "         -0.0411,  -8.8060,  -3.2554], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.041\n",
      "activated x value: tensor([-3.4901, -4.8617, -0.6001, -1.6059,  7.0588, -1.5581,  0.3707, -0.0393,\n",
      "         0.9037,  3.4882], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0915], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5816, -11.9532,  -7.6916,  -8.6974,  -0.0327,  -8.6496,  -6.7208,\n",
      "         -7.1308,  -6.1878,  -3.6033], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([-5.9926, -2.9569,  1.1203,  2.4445,  1.3497,  3.6343, -3.4819, -1.0009,\n",
      "         4.1349,  0.5499], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7957], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7883,  -7.7526,  -3.6754,  -2.3512,  -3.4460,  -1.1614,  -8.2776,\n",
      "         -5.7966,  -0.6608,  -4.2458], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.661\n",
      "activated x value: tensor([-2.9188, -5.9878, -2.8428, -2.7751,  5.5858, -1.0002,  1.5063,  0.1248,\n",
      "         1.5554,  5.8849], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4569], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.3757, -12.4447,  -9.2997,  -9.2320,  -0.8711,  -7.4571,  -4.9506,\n",
      "         -6.3321,  -4.9015,  -0.5721], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-8.3730,  7.8169,  0.5383,  1.6787, -4.2137,  1.7364,  0.3877, -2.6515,\n",
      "         3.3922, -0.7211], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8347], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.2076,  -0.0178,  -7.2964,  -6.1560, -12.0484,  -6.0983,  -7.4469,\n",
      "        -10.4862,  -4.4425,  -8.5558], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([ 3.7014, -5.9368,  4.3466, -3.1297,  0.6414,  3.6453,  6.4613, -5.0064,\n",
      "        -0.2261, -4.3601], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6829], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -2.9815, -12.6197,  -2.3364,  -9.8126,  -6.0415,  -3.0376,  -0.2216,\n",
      "        -11.6893,  -6.9091, -11.0430], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.222\n",
      "activated x value: tensor([ 6.7104, -6.0761,  2.3789,  3.6492, -7.5573,  3.0580, -2.5360, -2.6801,\n",
      "         3.5791, -0.0924], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8334], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1230, -12.9095,  -4.4545,  -3.1842, -14.3908,  -3.7754,  -9.3694,\n",
      "         -9.5135,  -3.2543,  -6.9258], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.123\n",
      "activated x value: tensor([ 17.8950, -10.4187,  -0.9436,   2.5809, -10.6723,   7.3923,   0.4945,\n",
      "         -1.7834,   1.4864,  -4.4302], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([17.8950], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.8610e-05, -2.8314e+01, -1.8839e+01, -1.5314e+01, -2.8567e+01,\n",
      "        -1.0503e+01, -1.7401e+01, -1.9678e+01, -1.6409e+01, -2.2325e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-6.3816, -1.6759, -3.3600, -0.5343,  3.2511,  0.5341, -3.1805,  3.5054,\n",
      "         0.7600,  6.6081], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6907], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.0722,  -8.3666, -10.0507,  -7.2250,  -3.4395,  -6.1566,  -9.8712,\n",
      "         -3.1853,  -5.9307,  -0.0826], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.083\n",
      "activated x value: tensor([-8.9564,  2.0791,  0.3177, -0.0490,  2.7240,  0.6988,  5.1175, -4.6771,\n",
      "         1.9120,  0.4078], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3121], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.2685,  -3.2330,  -4.9943,  -5.3610,  -2.5881,  -4.6132,  -0.1946,\n",
      "         -9.9892,  -3.4001,  -4.9042], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.195\n",
      "activated x value: tensor([-0.9277, -4.7969,  2.2741,  1.8008,  2.9001,  4.1734, -0.5028, -9.7210,\n",
      "         6.5419, -2.4125], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6766], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6043, -11.4735,  -4.4025,  -4.8758,  -3.7765,  -2.5032,  -7.1795,\n",
      "        -16.3976,  -0.1347,  -9.0892], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.135\n",
      "activated x value: tensor([-6.3146,  0.9741,  3.8924,  3.4054, -2.3453, -1.1815, -0.1103, -3.0373,\n",
      "         4.0662,  1.0730], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9726], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2873,  -3.9985,  -1.0803,  -1.5673,  -7.3179,  -6.1542,  -5.0830,\n",
      "         -8.0100,  -0.9065,  -3.8997], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.080\n",
      "activated x value: tensor([-7.9677, -3.4000, -0.5105,  0.5020,  4.8447, -1.2074, -2.1079,  0.0901,\n",
      "         2.1354,  8.4890], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5173], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.4850, -11.9173,  -9.0278,  -8.0153,  -3.6726,  -9.7247, -10.6251,\n",
      "         -8.4272,  -6.3818,  -0.0283], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-3.1386, -3.3789,  0.2908,  1.4876, -1.4205, -1.0225, -4.9499,  7.6840,\n",
      "         0.4776,  4.0451], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7135], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8522, -11.0925,  -7.4227,  -6.2260,  -9.1340,  -8.7360, -12.6635,\n",
      "         -0.0296,  -7.2360,  -3.6684], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.030\n",
      "activated x value: tensor([  9.9832, -12.3688,   3.9211,   3.7421,  -4.0935,   2.1663,   0.9219,\n",
      "         -4.0785,   2.1325,  -2.4640], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9884], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.1775e-03, -2.2357e+01, -6.0674e+00, -6.2463e+00, -1.4082e+01,\n",
      "        -7.8221e+00, -9.0666e+00, -1.4067e+01, -7.8559e+00, -1.2452e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-4.4696, -4.5613, -0.8003,  0.0451,  6.3726,  0.9467, -0.0662,  0.8667,\n",
      "        -0.0304,  2.3825], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4049], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8745, -10.9662,  -7.2052,  -6.3598,  -0.0323,  -5.4582,  -6.4711,\n",
      "         -5.5382,  -6.4353,  -4.0224], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.032\n",
      "activated x value: tensor([-5.3117, -5.7609, -3.6617,  0.0667,  7.7728, -0.4164, -2.9510,  4.2342,\n",
      "         2.1869,  4.7369], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8512], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.1629, -13.6121, -11.5129,  -7.7845,  -0.0784,  -8.2676, -10.8022,\n",
      "         -3.6170,  -5.6643,  -3.1143], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.078\n",
      "activated x value: tensor([-1.2074, -8.0018,  0.6501, -1.2469,  2.3463,  6.5287, -4.2242, -0.4861,\n",
      "         4.2614,  2.2556], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6574], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.8648, -14.6592,  -6.0073,  -7.9043,  -4.3111,  -0.1287, -10.8816,\n",
      "         -7.1435,  -2.3960,  -4.4017], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.129\n",
      "activated x value: tensor([-3.0227, -3.2589, -1.8271,  4.8521, -4.2276,  6.0077, -1.8401,  0.9931,\n",
      "         2.4095, -0.6840], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3086], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.3314,  -9.5675,  -8.1357,  -1.4566, -10.5362,  -0.3010,  -8.1488,\n",
      "         -5.3155,  -3.8992,  -6.9926], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.301\n",
      "activated x value: tensor([-9.8605,  8.6223,  0.9984,  5.0344, -4.7256,  0.7924, -0.3534, -2.4691,\n",
      "         1.8887, -0.3978], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6518], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-18.5123,  -0.0296,  -7.6534,  -3.6174, -13.3774,  -7.8594,  -9.0052,\n",
      "        -11.1209,  -6.7631,  -9.0497], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.030\n",
      "activated x value: tensor([-6.5948, -1.1219,  1.3571,  1.9585,  2.7385,  0.0417,  5.0045, -3.1195,\n",
      "         1.7072, -1.7494], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2074], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8022,  -6.3293,  -3.8503,  -3.2489,  -2.4689,  -5.1657,  -0.2029,\n",
      "         -8.3269,  -3.5002,  -6.9568], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.203\n",
      "activated x value: tensor([-6.2750, -7.4894, -5.1272, -3.0002, 11.2792,  1.0076,  0.8548,  0.5799,\n",
      "         2.5587,  4.9362], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2813], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7556e+01, -1.8771e+01, -1.6409e+01, -1.4281e+01, -2.0075e-03,\n",
      "        -1.0274e+01, -1.0426e+01, -1.0701e+01, -8.7226e+00, -6.3450e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 12.5943, -14.9173,  -0.7808,   0.3521,  -3.0656,   6.6791,  -1.5835,\n",
      "         -2.2173,   3.3626,  -0.2766], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.5971], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.8019e-03, -2.7514e+01, -1.3378e+01, -1.2245e+01, -1.5663e+01,\n",
      "        -5.9180e+00, -1.4181e+01, -1.4814e+01, -9.2345e+00, -1.2874e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-6.3401,  6.8305, -0.8358,  1.7361, -2.8523,  1.5835, -0.0956, -2.1699,\n",
      "         2.5142, -0.8477], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8570], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-13.1971,  -0.0265,  -7.6928,  -5.1209,  -9.7092,  -5.2735,  -6.9526,\n",
      "         -9.0269,  -4.3428,  -7.7047], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.026\n",
      "activated x value: tensor([-3.0435, -5.3200, -2.5150,  1.5605,  0.4917, -0.5759, -5.5305,  9.4725,\n",
      "         0.3217,  4.9497], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4839], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2527e+01, -1.4804e+01, -1.1999e+01, -7.9234e+00, -8.9922e+00,\n",
      "        -1.0060e+01, -1.5014e+01, -1.1445e-02, -9.1622e+00, -4.5342e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-2.1506, -0.0229,  3.7947, 15.4708, -5.2723,  1.9821, -7.6923, -3.6955,\n",
      "         1.4295, -4.0231], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.4708], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7621e+01, -1.5494e+01, -1.1676e+01, -1.0490e-05, -2.0743e+01,\n",
      "        -1.3489e+01, -2.3163e+01, -1.9166e+01, -1.4041e+01, -1.9494e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ -4.7095,  -0.0153,   2.0183,  -2.0425,   6.8544, -11.2809,   5.1416,\n",
      "          1.7499,   0.9752,   1.5576], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0395], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.7490,  -7.0547,  -5.0212,  -9.0820,  -0.1851, -18.3204,  -1.8979,\n",
      "         -5.2896,  -6.0643,  -5.4819], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -1.898\n",
      "activated x value: tensor([ 15.2869, -12.1637,   1.3042,   2.0393,  -5.8977,   5.7520,   1.0182,\n",
      "         -5.9450,   3.0529,  -3.2308], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.2870], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0109e-05, -2.7451e+01, -1.3983e+01, -1.3248e+01, -2.1185e+01,\n",
      "        -9.5350e+00, -1.4269e+01, -2.1232e+01, -1.2234e+01, -1.8518e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-6.3903, -2.3718, -1.9629,  2.7023, -1.6628, -3.0338, -8.3961, 12.2766,\n",
      "         2.1921,  6.4842], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.2798], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8670e+01, -1.4652e+01, -1.4243e+01, -9.5775e+00, -1.3943e+01,\n",
      "        -1.5314e+01, -2.0676e+01, -3.1586e-03, -1.0088e+01, -5.7956e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-5.7500, -0.0606,  1.5652,  0.0929,  2.5332, -2.3408,  1.8789, -3.6656,\n",
      "         1.8974,  2.7343], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8744], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.6244, -3.9350, -2.3092, -3.7816, -1.3412, -6.2152, -1.9955, -7.5400,\n",
      "        -1.9770, -1.1401], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.341\n",
      "activated x value: tensor([ 1.8825,  1.1057,  0.6784,  0.3562, -4.5984,  2.7421,  6.5483, -4.8225,\n",
      "         1.1615, -3.7455], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5928], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.7103,  -5.4871,  -5.9144,  -6.2366, -11.1912,  -3.8507,  -0.0445,\n",
      "        -11.4153,  -5.4313, -10.3383], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.044\n",
      "activated x value: tensor([ 0.8847,  1.1740, 10.4746,  6.7801, -8.0624,  1.1402, -3.0115, -8.1690,\n",
      "         6.5000, -7.5437], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.5175], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.6329,  -9.3435,  -0.0430,  -3.7375, -18.5800,  -9.3773, -13.5291,\n",
      "        -18.6865,  -4.0176, -18.0612], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([ 1.3875, -2.0977, -0.5846,  6.8886, -1.5835,  4.3457, -5.7469, -4.1345,\n",
      "         3.9612, -3.4562], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0172], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6297,  -9.1149,  -7.6017,  -0.1286,  -8.6007,  -2.6714, -12.7641,\n",
      "        -11.1517,  -3.0559, -10.4734], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.129\n",
      "activated x value: tensor([ 15.7601, -11.5669,   2.9547,   1.8993, -11.2124,   5.1994,  -5.1615,\n",
      "         -1.0138,   5.0696,  -1.7778], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.7602], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2452e-05, -2.7327e+01, -1.2805e+01, -1.3861e+01, -2.6973e+01,\n",
      "        -1.0561e+01, -2.0922e+01, -1.6774e+01, -1.0691e+01, -1.7538e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 4.0946, -6.4136,  2.0061, -1.3153,  0.8330,  5.0088,  0.6925, -7.8861,\n",
      "         3.6124, -1.4222], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5570], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.4624, -11.9706,  -3.5509,  -6.8723,  -4.7240,  -0.5482,  -4.8646,\n",
      "        -13.4431,  -1.9446,  -6.9792], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -4.865\n",
      "activated x value: tensor([-8.0066,  4.6813, -0.0090,  4.5104, -3.8384, -1.2070, -2.2378,  3.2536,\n",
      "         0.2128,  3.2674], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5360], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.5426,  -0.8546,  -5.5450,  -1.0256,  -9.3743,  -6.7429,  -7.7737,\n",
      "         -2.2823,  -5.3232,  -2.2685], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.855\n",
      "activated x value: tensor([-3.4738, -2.2493,  2.2404, -0.9230,  1.6016,  3.4743,  6.6854, -7.8775,\n",
      "         3.1135, -2.2417], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7689], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2427,  -9.0182,  -4.5286,  -7.6919,  -5.1674,  -3.2946,  -0.0836,\n",
      "        -14.6465,  -3.6555,  -9.0106], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.084\n",
      "activated x value: tensor([ 1.4014, -7.1200,  0.4429,  0.3496, -0.6010,  3.7935, -3.0336, -4.5553,\n",
      "         6.7392,  2.5435], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8131], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.4117, -13.9331,  -6.3702,  -6.4636,  -7.4142,  -3.0196,  -9.8467,\n",
      "        -11.3685,  -0.0739,  -4.2696], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.074\n",
      "activated x value: tensor([-0.0798, -2.5882,  3.1930,  1.9629, -2.3953,  5.7911,  4.8806, -8.1082,\n",
      "         2.2886, -4.9519], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2177], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.2975,  -8.8059,  -3.0247,  -4.2548,  -8.6130,  -0.4265,  -1.3371,\n",
      "        -14.3258,  -3.9291, -11.1695], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.427\n",
      "activated x value: tensor([-4.9442, -2.8115,  8.9435,  1.9772,  0.8038, -4.2259,  2.4656, -0.8854,\n",
      "        -1.4292,  0.1719], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9466], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3891e+01, -1.1758e+01, -3.0184e-03, -6.9694e+00, -8.1427e+00,\n",
      "        -1.3172e+01, -6.4809e+00, -9.8319e+00, -1.0376e+01, -8.7747e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 18.0194, -14.5796,   4.2637,  -0.1902,  -9.5376,   4.5892,  -2.1212,\n",
      "         -4.4714,   7.2825,  -2.7590], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([18.0194], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.4796e-05, -3.2599e+01, -1.3756e+01, -1.8210e+01, -2.7557e+01,\n",
      "        -1.3430e+01, -2.0141e+01, -2.2491e+01, -1.0737e+01, -2.0778e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-6.0433,  0.5193,  0.4096,  2.0916, -2.5186, -0.4487, -2.3766,  5.6615,\n",
      "         0.1771,  3.1610], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7822], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8255,  -5.2629,  -5.3726,  -3.6906,  -8.3007,  -6.2309,  -8.1588,\n",
      "         -0.1207,  -5.6051,  -2.6212], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.121\n",
      "activated x value: tensor([-2.6309, -6.0141,  2.7296,  0.1631,  0.3064, -3.9017, -3.4024,  4.5720,\n",
      "        -0.6566,  7.9737], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0126], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6434, -14.0267,  -5.2830,  -7.8495,  -7.7062, -11.9143, -11.4150,\n",
      "         -3.4406,  -8.6692,  -0.0389], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.039\n",
      "activated x value: tensor([-2.8833, -7.3750, -0.9928, -0.6683,  1.8821,  4.4298, -2.3070, -0.4790,\n",
      "         6.5176,  0.8202], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6481], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([ -9.5314, -14.0231,  -7.6410,  -7.3164,  -4.7660,  -2.2183,  -8.9552,\n",
      "         -7.1272,  -0.1306,  -5.8279], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.131\n",
      "activated x value: tensor([-1.3151, -9.1139,  0.2272, -4.4562,  4.0041, -3.5599, -0.3801,  3.4645,\n",
      "         1.9980,  8.4767], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4966], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.8117, -17.6105,  -8.2693, -12.9528,  -4.4925, -12.0565,  -8.8767,\n",
      "         -5.0320,  -6.4986,  -0.0199], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-3.9853, -4.7730,  8.7317,  2.2455, -2.8464, -0.9038,  2.9840, -1.8254,\n",
      "         1.6379, -2.2469], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7374], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2723e+01, -1.3510e+01, -5.6505e-03, -6.4919e+00, -1.1584e+01,\n",
      "        -9.6412e+00, -5.7534e+00, -1.0563e+01, -7.0995e+00, -1.0984e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-9.8607,  7.4663, -0.3367,  4.4220, -3.5997, -2.9684, -3.0571,  2.5572,\n",
      "         2.5069,  3.6851], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5481], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.4088,  -0.0819,  -7.8848,  -3.1261, -11.1478, -10.5165, -10.6052,\n",
      "         -4.9909,  -5.0412,  -3.8630], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.082\n",
      "activated x value: tensor([-3.9411, -1.9672, -0.7689, -0.4567,  5.3840,  1.0054, -0.1896, -0.2324,\n",
      "         0.1831,  1.4025], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4327], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.3738, -7.3999, -6.2016, -5.8894, -0.0487, -4.4273, -5.6223, -5.6651,\n",
      "        -5.2496, -4.0302], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.049\n",
      "activated x value: tensor([ 15.5953, -11.6043,  -0.6193,   1.7202,  -9.4386,   7.2370,  -6.3431,\n",
      "          0.3298,   6.2373,  -1.2892], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.5956], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.2234e-04, -2.7200e+01, -1.6215e+01, -1.3875e+01, -2.5034e+01,\n",
      "        -8.3586e+00, -2.1939e+01, -1.5266e+01, -9.3583e+00, -1.6885e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-4.4544, -0.1760,  3.2802,  8.4591, -2.0077, -0.1576, -6.4921, -0.1288,\n",
      "         1.6645,  0.0679], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4667], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2921e+01, -8.6427e+00, -5.1865e+00, -7.5283e-03, -1.0474e+01,\n",
      "        -8.6243e+00, -1.4959e+01, -8.5954e+00, -6.8022e+00, -8.3988e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-2.7375, -4.8195,  2.2141, -1.0770,  2.1550,  4.5381,  1.7351, -5.7724,\n",
      "         2.7742,  1.1487], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9167], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6543,  -9.7362,  -2.7026,  -5.9937,  -2.7617,  -0.3787,  -3.1817,\n",
      "        -10.6891,  -2.1425,  -3.7680], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.379\n",
      "activated x value: tensor([ 3.0943, -7.3435, -4.4428, -3.2794, -1.7653,  8.9358, -2.8048,  4.7840,\n",
      "         2.5685,  0.6336], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9562], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8619, -16.2997, -13.3990, -12.2356, -10.7215,  -0.0204, -11.7610,\n",
      "         -4.1723,  -6.3877,  -8.3226], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-9.1725, -1.9114, -0.6617,  2.7489,  4.3193,  0.1103, -1.4574, -2.9964,\n",
      "         2.3900,  7.3873], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4495], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.6221,  -9.3609,  -8.1112,  -4.7006,  -3.1302,  -7.3392,  -8.9069,\n",
      "        -10.4460,  -5.0595,  -0.0622], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.062\n",
      "activated x value: tensor([10.1553, -8.6733,  5.6031,  2.4100, -7.8952,  2.5846,  2.3473, -3.9730,\n",
      "         0.9548, -2.4594], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1672], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1932e-02, -1.8840e+01, -4.5641e+00, -7.7572e+00, -1.8062e+01,\n",
      "        -7.5826e+00, -7.8199e+00, -1.4140e+01, -9.2124e+00, -1.2627e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-4.2832, -6.1534,  1.4510,  4.0047, -2.2897, -3.1094, -8.5267, 11.8598,\n",
      "         2.0896,  4.6781], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.8610], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6144e+01, -1.8014e+01, -1.0410e+01, -7.8563e+00, -1.4151e+01,\n",
      "        -1.4970e+01, -2.0388e+01, -1.2360e-03, -9.7715e+00, -7.1830e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-0.9264, -2.4187, -0.0898,  5.8580,  0.6400,  3.3506, -4.5548, -2.6689,\n",
      "         1.9690, -1.7528], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9643], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.8907,  -8.3830,  -6.0540,  -0.1062,  -5.3243,  -2.6136, -10.5190,\n",
      "         -8.6332,  -3.9953,  -7.7171], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.106\n",
      "activated x value: tensor([ 1.2475, -4.3846,  0.4064,  2.2168,  0.4317,  4.4997,  2.9873, -8.9656,\n",
      "         1.8809, -1.2288], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8858], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.6383,  -9.2704,  -4.4793,  -2.6690,  -4.4541,  -0.3860,  -1.8984,\n",
      "        -13.8514,  -3.0049,  -6.1145], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -1.898\n",
      "activated x value: tensor([-8.7924, -4.2341,  4.5204, 11.5432, -1.2693, -1.5639, -8.1301,  1.5645,\n",
      "         3.3020,  2.7840], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5446], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0337e+01, -1.5779e+01, -7.0242e+00, -1.3618e-03, -1.2814e+01,\n",
      "        -1.3108e+01, -1.9675e+01, -9.9800e+00, -8.2425e+00, -8.7606e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.3764, -0.8382, -5.3200,  0.6718, -0.8610,  2.2485, -4.8567,  7.1612,\n",
      "         1.3037,  2.9172], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1877], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.5641,  -8.0259, -12.5077,  -6.5159,  -8.0487,  -4.9392, -12.0444,\n",
      "         -0.0265,  -5.8840,  -4.2705], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.026\n",
      "activated x value: tensor([-2.9809, -1.6092,  1.1508, -0.2615,  0.1785,  1.8671, -0.2190, -2.6562,\n",
      "         4.3477,  0.3560], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5158], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.4966, -6.1249, -3.3649, -4.7772, -4.3373, -2.6487, -4.7347, -7.1719,\n",
      "        -0.1681, -4.1598], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.168\n",
      "activated x value: tensor([ 1.5968, -8.6621, -2.1195,  0.0115,  2.3453,  6.8011, -0.8194, -3.9605,\n",
      "         3.3988,  2.3888], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8634], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.2666, -15.5254,  -8.9828,  -6.8519,  -4.5181,  -0.0623,  -7.6827,\n",
      "        -10.8239,  -3.4646,  -4.4746], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.062\n",
      "activated x value: tensor([ 13.5263, -16.7607,   0.6415,   0.7330,  -6.4940,   9.2213,  -2.1841,\n",
      "         -3.3914,   7.1897,  -1.4273], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.5415], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5162e-02, -3.0302e+01, -1.2900e+01, -1.2808e+01, -2.0036e+01,\n",
      "        -4.3202e+00, -1.5726e+01, -1.6933e+01, -6.3518e+00, -1.4969e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-1.2200,  0.2549, -0.4341,  5.7330, -2.3065,  2.1813, -5.9541, -0.5760,\n",
      "         3.9534, -1.9112], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9213], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1413,  -5.6664,  -6.3554,  -0.1883,  -8.2278,  -3.7401, -11.8754,\n",
      "         -6.4973,  -1.9679,  -7.8325], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.188\n",
      "activated x value: tensor([-9.0293, -1.9550,  3.6088,  2.7680,  0.8225, -1.5607,  4.1266, -5.5195,\n",
      "         8.3919, -1.4339], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4182], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.4476, -10.3733,  -4.8094,  -5.6502,  -7.5957,  -9.9790,  -4.2916,\n",
      "        -13.9378,  -0.0263,  -9.8522], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.026\n",
      "activated x value: tensor([ -5.1018, -10.8125,  -8.2756,  -1.6064,   1.5560,   3.2149,  -5.5980,\n",
      "         12.8692,   6.9077,   5.0574], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.8722], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7974e+01, -2.3685e+01, -2.1148e+01, -1.4479e+01, -1.1316e+01,\n",
      "        -9.6574e+00, -1.8470e+01, -3.0527e-03, -5.9645e+00, -7.8148e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-2.2660, -6.3130,  1.9943,  0.0161,  2.1008,  3.6553, -1.2132, -6.1220,\n",
      "         8.9797, -2.8191], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9867], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1253e+01, -1.5300e+01, -6.9925e+00, -8.9706e+00, -6.8859e+00,\n",
      "        -5.3314e+00, -1.0200e+01, -1.5109e+01, -6.9876e-03, -1.1806e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([ 1.6867, -2.7284,  0.0784, -1.4830, -2.3278,  2.7537, -0.2085, -0.4651,\n",
      "        -0.1218,  2.2198], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.5294], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8427, -6.2578, -3.4509, -5.0124, -5.8572, -0.7757, -3.7379, -3.9945,\n",
      "        -3.6512, -1.3096], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-3.8581, -4.8715,  2.7494,  3.0696, -3.2225, -0.8255, -4.4977,  6.2283,\n",
      "         1.7203,  3.2409], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3557], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2137, -11.2272,  -3.6062,  -3.2860,  -9.5782,  -7.1811, -10.8534,\n",
      "         -0.1273,  -4.6354,  -3.1148], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.127\n",
      "activated x value: tensor([-0.6604, -6.6713, -0.0836,  2.2356, -1.6828, -0.1588, -4.3924,  6.5568,\n",
      "        -0.4133,  5.4161], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8475], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5078, -13.5187,  -6.9310,  -4.6119,  -8.5302,  -7.0063, -11.2399,\n",
      "         -0.2907,  -7.2608,  -1.4313], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.291\n",
      "activated x value: tensor([  2.6881,  -7.5945,   1.8427,  -2.0496,  -0.7214,   7.0305,   2.3858,\n",
      "        -11.3632,   8.2997,  -0.7994], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5538], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8656, -16.1483,  -6.7111, -10.6034,  -9.2752,  -1.5233,  -6.1680,\n",
      "        -19.9170,  -0.2541,  -9.3532], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -6.168\n",
      "activated x value: tensor([-1.0711,  1.7802,  0.4476,  2.1998, -6.2661,  5.0010, -3.3050, -5.4771,\n",
      "         6.6105, -1.3279], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8119], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.8830,  -5.0317,  -6.3643,  -4.6121, -13.0780,  -1.8109, -10.1169,\n",
      "        -12.2890,  -0.2014,  -8.1398], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.201\n",
      "activated x value: tensor([-4.1496,  5.9769,  0.8199,  0.9324, -3.4324,  0.9254,  0.3182, -0.5260,\n",
      "         0.3806, -0.5519], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0054], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1550,  -0.0285,  -5.1855,  -5.0729,  -9.4378,  -5.0799,  -5.6872,\n",
      "         -6.5314,  -5.6248,  -6.5572], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-6.7715,  8.1946,  0.7347,  2.4751, -3.6632, -0.8625, -0.4691,  0.5917,\n",
      "         0.3135,  0.2362], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2000], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4971e+01, -5.3654e-03, -7.4653e+00, -5.7249e+00, -1.1863e+01,\n",
      "        -9.0625e+00, -8.6691e+00, -7.6083e+00, -7.8865e+00, -7.9638e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([ 8.3653, -7.5258,  1.0745,  0.4756, -3.6710,  4.5896,  0.9050, -3.5038,\n",
      "         1.0411, -1.1916], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3903], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0250, -15.9161,  -7.3158,  -7.9146, -12.0613,  -3.8007,  -7.4853,\n",
      "        -11.8941,  -7.3492,  -9.5819], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([-6.6740,  3.8627, 11.6701, 10.7606, -8.4500, -4.4634,  1.8359, -4.8601,\n",
      "         1.2194, -4.2497], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.0089], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-18.6829,  -8.1462,  -0.3388,  -1.2483, -20.4589, -16.4723, -10.1730,\n",
      "        -16.8690, -10.7895, -16.2586], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.339\n",
      "activated x value: tensor([-2.6843e+00, -7.0192e-01,  4.3567e-03,  5.2105e+00, -9.6689e-01,\n",
      "         2.1746e+00, -3.8650e+00,  1.0009e+00,  6.9928e-01, -5.5622e-01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2946], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.9789, -5.9965, -5.2902, -0.0841, -6.2615, -3.1200, -9.1596, -4.2936,\n",
      "        -4.5953, -5.8508], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.084\n",
      "activated x value: tensor([-2.4585,  1.8110,  4.8875, -1.2893,  0.2891, -2.8420,  3.6721, -2.4707,\n",
      "        -0.0675, -2.0704], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1984], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.6569, -3.3874, -0.3108, -6.4877, -4.9093, -8.0404, -1.5262, -7.6691,\n",
      "        -5.2659, -7.2688], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.311\n",
      "activated x value: tensor([-9.7319,  4.7923,  8.7516,  3.5294, -8.9649,  0.0397,  0.3375, -2.2044,\n",
      "         3.0362, -0.1463], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7795], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-18.5114,  -3.9872,  -0.0279,  -5.2501, -17.7444,  -8.7398,  -8.4420,\n",
      "        -10.9839,  -5.7433,  -8.9258], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-7.8107,  8.8811,  1.7754,  1.4194, -4.0589, -2.2842, -0.2955,  1.2066,\n",
      "         2.3439, -0.3610], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8846], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6695e+01, -3.5191e-03, -7.1092e+00, -7.4652e+00, -1.2944e+01,\n",
      "        -1.1169e+01, -9.1801e+00, -7.6780e+00, -6.5407e+00, -9.2456e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-7.6964,  2.1059, -7.6143,  2.8336,  1.3384,  2.5948, -4.0583,  4.6662,\n",
      "         1.2336,  4.5533], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5099], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.2063,  -3.4040, -13.1242,  -2.6763,  -4.1714,  -2.9150,  -9.5682,\n",
      "         -0.8436,  -4.2762,  -0.9566], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.957\n",
      "activated x value: tensor([-5.5067, -0.0822, -0.1363, -2.1919,  5.0939, -4.1534, -0.7067,  2.2602,\n",
      "         2.9966,  2.1889], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3179], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8247,  -5.4002,  -5.4543,  -7.5098,  -0.2241,  -9.4713,  -6.0246,\n",
      "         -3.0577,  -2.3213,  -3.1290], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.224\n",
      "activated x value: tensor([13.1693, -9.4512,  0.1879,  1.4572, -6.3784,  7.3639, -6.2199, -3.1767,\n",
      "         4.4474, -1.4095], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.1725], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.1805e-03, -2.2624e+01, -1.2985e+01, -1.1715e+01, -1.9551e+01,\n",
      "        -5.8086e+00, -1.9392e+01, -1.6349e+01, -8.7251e+00, -1.4582e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-3.8043,  4.0951,  3.9141,  0.7551, -4.5932,  0.8465,  5.7599, -5.6490,\n",
      "         2.3940, -2.7816], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0935], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.8979,  -1.9984,  -2.1795,  -5.3385, -10.6867,  -5.2470,  -0.3336,\n",
      "        -11.7426,  -3.6996,  -8.8752], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.334\n",
      "activated x value: tensor([-2.2125, -4.8474,  0.1114,  2.9291, -1.4986, -0.6407, -5.5296,  9.3221,\n",
      "         0.2370,  2.4307], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.3251], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1538e+01, -1.4172e+01, -9.2136e+00, -6.3959e+00, -1.0824e+01,\n",
      "        -9.9658e+00, -1.4855e+01, -2.9764e-03, -9.0881e+00, -6.8943e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-2.5263, -1.4565,  1.1803, 11.9717, -5.8186,  1.4021, -3.9553, -0.8170,\n",
      "         0.2431, -0.4596], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.9718], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4498e+01, -1.3428e+01, -1.0791e+01, -6.2943e-05, -1.7790e+01,\n",
      "        -1.0570e+01, -1.5927e+01, -1.2789e+01, -1.1729e+01, -1.2431e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-2.6330, -6.8850, -0.2286, -4.4625,  8.9492, -4.2721,  1.7149,  1.8290,\n",
      "         1.9226,  3.2847], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9552], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1588e+01, -1.5840e+01, -9.1838e+00, -1.3418e+01, -5.9834e-03,\n",
      "        -1.3227e+01, -7.2403e+00, -7.1262e+00, -7.0326e+00, -5.6705e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-4.0461, -3.0698,  2.1563, -0.3641,  0.7694,  2.5804,  9.5632, -8.4121,\n",
      "         2.7047, -1.4402], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5660], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3612e+01, -1.2636e+01, -7.4097e+00, -9.9301e+00, -8.7966e+00,\n",
      "        -6.9856e+00, -2.8028e-03, -1.7978e+01, -6.8613e+00, -1.1006e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 0.4746, -4.2769, -7.9877,  4.4775, -1.1640,  6.4306,  1.4947, -0.8258,\n",
      "         0.2000,  1.3623], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5800], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.1053, -10.8568, -14.5677,  -2.1024,  -7.7440,  -0.1494,  -5.0852,\n",
      "         -7.4057,  -6.3799,  -5.2177], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -2.102\n",
      "activated x value: tensor([ 7.6635, -4.9856,  4.7708,  3.9613, -7.1115,  2.7104, -5.5639, -0.6005,\n",
      "         2.0392, -2.4125], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7507], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0872, -12.7363,  -2.9799,  -3.7894, -14.8622,  -5.0403, -13.3146,\n",
      "         -8.3512,  -5.7114, -10.1632], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -5.040\n",
      "activated x value: tensor([-0.5560, -1.2322,  0.0198,  8.5632, -2.2853,  3.9191, -3.8450, -2.2323,\n",
      "         0.7005, -2.8996], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5735], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1295e+00, -9.8057e+00, -8.5537e+00, -1.0364e-02, -1.0859e+01,\n",
      "        -4.6544e+00, -1.2419e+01, -1.0806e+01, -7.8730e+00, -1.1473e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-1.6488,  1.2516,  2.1331,  3.9187, -5.6778,  1.7559, -0.2665, -3.5660,\n",
      "         4.1746, -0.9219], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9013], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.5501,  -3.6497,  -2.7681,  -0.9826, -10.5791,  -3.1453,  -5.1678,\n",
      "         -8.4672,  -0.7267,  -5.8232], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.727\n",
      "activated x value: tensor([-6.0521,  8.2563,  2.1903,  1.0608, -5.7536,  0.2291,  1.0094, -2.4068,\n",
      "         3.2632, -1.2408], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2672], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4319e+01, -1.0934e-02, -6.0769e+00, -7.2065e+00, -1.4021e+01,\n",
      "        -8.0381e+00, -7.2579e+00, -1.0674e+01, -5.0040e+00, -9.5080e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([ 1.3693e-01, -6.9825e+00,  7.1317e+00, -4.3773e+00,  1.7845e+00,\n",
      "         8.2799e-03,  1.0916e+01, -5.1654e+00,  7.9291e-02, -3.2760e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9384], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8015, -17.9210,  -3.8068, -15.3157,  -9.1539, -10.9302,  -0.0226,\n",
      "        -16.1038, -10.8592, -14.2145], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([  2.1110,  -7.3628,   4.5543,   1.5490,  -1.2543,   3.4530,   4.1796,\n",
      "        -10.4357,   4.2233,  -1.7552], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6119], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.5009, -12.9747,  -1.0576,  -4.0629,  -6.8662,  -2.1588,  -1.4323,\n",
      "        -16.0476,  -1.3886,  -7.3671], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.389\n",
      "activated x value: tensor([-0.8277, -2.2729,  1.2051,  0.1359,  0.6817,  2.1740, -3.8546, -0.3572,\n",
      "         1.7391,  0.7865], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.1947], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.0224, -5.4676, -1.9896, -3.0587, -2.5129, -1.0206, -7.0493, -3.5519,\n",
      "        -1.4556, -2.4082], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.021\n",
      "activated x value: tensor([-4.8796, -6.2517, -1.9343,  0.2233,  5.7415,  2.2018, -1.5827,  0.5721,\n",
      "         1.9874,  3.3640], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8865], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7661, -12.1382,  -7.8208,  -5.6632,  -0.1450,  -3.6847,  -7.4692,\n",
      "         -5.3144,  -3.8991,  -2.5225], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.145\n",
      "activated x value: tensor([-4.3429,  0.1443,  9.6637,  1.5434, -2.5396, -1.9582,  2.7506, -4.7808,\n",
      "         2.5439, -3.5640], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6659], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-1.4009e+01, -9.5216e+00, -2.1887e-03, -8.1225e+00, -1.2206e+01,\n",
      "        -1.1624e+01, -6.9153e+00, -1.4447e+01, -7.1220e+00, -1.3230e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-7.7943,  8.1176,  0.3324,  2.8926, -3.2812, -0.9395, -1.0809,  0.6126,\n",
      "         0.4048,  1.5053], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1259], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5920e+01, -8.3323e-03, -7.7935e+00, -5.2333e+00, -1.1407e+01,\n",
      "        -9.0654e+00, -9.2068e+00, -7.5133e+00, -7.7211e+00, -6.6206e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-0.8648,  0.0647,  0.7958,  2.2543, -4.4191,  4.3125, -3.0239, -4.2107,\n",
      "         6.0126,  0.9511], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2127], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0775,  -6.1480,  -5.4169,  -3.9584, -10.6318,  -1.9002,  -9.2366,\n",
      "        -10.4234,  -0.2002,  -5.2617], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.200\n",
      "activated x value: tensor([ 9.1912, -7.4453,  0.4577,  1.2211, -5.1872,  5.1078, -3.6880, -1.5532,\n",
      "         4.1707, -0.6575], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2150], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0238, -16.6603,  -8.7573,  -7.9938, -14.4022,  -4.1072, -12.9030,\n",
      "        -10.7682,  -5.0442,  -9.8725], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-3.2329, -4.9887,  2.1433,  1.6031, -2.3529, -2.1836, -3.3227,  6.9387,\n",
      "         1.6530,  3.0744], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9774], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2103, -11.9661,  -4.8341,  -5.3743,  -9.3303,  -9.1610, -10.3001,\n",
      "         -0.0387,  -5.3244,  -3.9030], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.039\n",
      "activated x value: tensor([-7.2968, -3.0900, -4.1852,  1.8661,  2.5216, -0.1368, -5.1541,  3.2867,\n",
      "         4.2633,  7.7751], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8233], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.1201, -10.9133, -12.0085,  -5.9572,  -5.3017,  -7.9602, -12.9775,\n",
      "         -4.5367,  -3.5600,  -0.0482], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.048\n",
      "activated x value: tensor([-0.4198, -2.1476,  4.3410, -2.2651, -2.5832, -1.5200,  9.9702, -6.6764,\n",
      "         4.4383, -2.6878], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9777], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0398e+01, -1.2125e+01, -5.6368e+00, -1.2243e+01, -1.2561e+01,\n",
      "        -1.1498e+01, -7.5798e-03, -1.6654e+01, -5.5395e+00, -1.2666e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-7.1395, -2.8408,  0.6760,  5.1550, -0.8699, -2.9498, -6.3650,  4.3431,\n",
      "         3.1876,  6.3298], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7310], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.8705,  -9.5718,  -6.0550,  -1.5760,  -7.6009,  -9.6808, -13.0960,\n",
      "         -2.3879,  -3.5434,  -0.4012], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -2.388\n",
      "activated x value: tensor([-4.3636, -5.9313, -1.7403, -0.6260, -0.3393,  4.9262, -2.8257, -3.1924,\n",
      "        11.2974,  2.2899], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2992], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5663e+01, -1.7230e+01, -1.3040e+01, -1.1925e+01, -1.1639e+01,\n",
      "        -6.3730e+00, -1.4125e+01, -1.4492e+01, -1.8501e-03, -9.0093e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-8.5557,  1.6570, -3.9540,  0.4568, -0.7593,  1.4070, -3.0497,  2.0619,\n",
      "         4.4584,  5.9150], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1659], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.7215,  -4.5088, -10.1199,  -5.7091,  -6.9252,  -4.7588,  -9.2155,\n",
      "         -4.1039,  -1.7075,  -0.2508], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.251\n",
      "activated x value: tensor([ 13.7731, -14.4026,   2.7368,  -1.4441,  -6.5293,   2.8550,  -0.3383,\n",
      "          0.7194,   3.0704,   1.0518], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.7731], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.2943e-05, -2.8176e+01, -1.1036e+01, -1.5217e+01, -2.0302e+01,\n",
      "        -1.0918e+01, -1.4111e+01, -1.3054e+01, -1.0703e+01, -1.2721e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 0.9354, -3.9175,  0.4390, -1.1481, -0.3595,  1.1939,  7.7698, -4.5203,\n",
      "         1.6779, -1.5414], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7757], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8403e+00, -1.1693e+01, -7.3367e+00, -8.9237e+00, -8.1351e+00,\n",
      "        -6.5818e+00, -5.9009e-03, -1.2296e+01, -6.0977e+00, -9.3170e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 3.1098, -5.8869, -3.6220,  4.2710, -4.8177,  8.6413, -5.3511, -0.1953,\n",
      "         2.6043,  0.0124], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6605], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.5507, -14.5474, -12.2825,  -4.3895, -13.4782,  -0.0191, -14.0116,\n",
      "         -8.8558,  -6.0562,  -8.6480], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-1.6732, -2.7163, -0.1100,  4.5308, -0.3008,  2.0453, -1.9336, -3.2801,\n",
      "         1.7892,  1.7845], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7412], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4145, -7.4575, -4.8512, -0.2105, -5.0420, -2.6959, -6.6748, -8.0213,\n",
      "        -2.9521, -2.9567], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.210\n",
      "activated x value: tensor([-4.8263, -3.5803,  3.5188, -0.1237, -1.9545, -4.0029, -2.8876,  7.5676,\n",
      "         2.5440,  4.7211], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6470], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.4733, -11.2272,  -4.1282,  -7.7706,  -9.6015, -11.6499, -10.5346,\n",
      "         -0.0794,  -5.1029,  -2.9259], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.079\n",
      "activated x value: tensor([ 1.3609, -2.6880,  0.8278,  2.0316, -2.1237,  3.8342, -1.3918,  0.0697,\n",
      "         1.2434, -3.1620], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1758], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.8148, -6.8637, -3.3480, -2.1441, -6.2995, -0.3416, -5.5675, -4.1061,\n",
      "        -2.9323, -7.3377], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.342\n",
      "activated x value: tensor([ 1.2560, -7.7769,  0.7043, -3.2357,  2.1615, -0.5696,  4.4629, -0.2844,\n",
      "         1.1692,  2.2895], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7485], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.4925, -12.5254,  -4.0442,  -7.9841,  -2.5870,  -5.3181,  -0.2855,\n",
      "         -5.0329,  -3.5792,  -2.4590], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.286\n",
      "activated x value: tensor([-5.4868, -5.7175, -1.1355, -1.8911,  5.1571, -2.8779, -1.7829,  3.6972,\n",
      "         1.3159,  8.2231], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2800], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.7669, -13.9976,  -9.4155, -10.1711,  -3.1230, -11.1579, -10.0629,\n",
      "         -4.5828,  -6.9641,  -0.0570], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.057\n",
      "activated x value: tensor([-5.6753,  9.1696,  4.2596,  1.5230, -5.9934, -2.6386, -0.6338, -0.8623,\n",
      "         2.7911, -0.3998], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1793], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4855e+01, -9.6779e-03, -4.9197e+00, -7.6563e+00, -1.5173e+01,\n",
      "        -1.1818e+01, -9.8132e+00, -1.0042e+01, -6.3882e+00, -9.5791e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([ 1.4421, -9.2483,  3.2591,  2.5000, -5.1480, -3.0217, -7.8107, 14.1053,\n",
      "        -0.4037,  3.9539], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.1054], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2663e+01, -2.3354e+01, -1.0846e+01, -1.1605e+01, -1.9253e+01,\n",
      "        -1.7127e+01, -2.1916e+01, -7.1526e-05, -1.4509e+01, -1.0151e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 0.4145,  1.8920,  6.0865,  1.7751, -6.7061,  1.5827, -0.5453, -4.1414,\n",
      "         4.2548, -5.0515], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2725], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8580,  -4.3806,  -0.1861,  -4.4974, -12.9787,  -4.6898,  -6.8178,\n",
      "        -10.4139,  -2.0177, -11.3241], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.186\n",
      "activated x value: tensor([-5.7022,  6.6347,  1.2055,  0.9253, -0.4158, -2.0058,  0.2494, -3.8382,\n",
      "         3.2111,  1.1634], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6809], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.3830,  -0.0462,  -5.4753,  -5.7556,  -7.0967,  -8.6867,  -6.4314,\n",
      "        -10.5191,  -3.4697,  -5.5174], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.046\n",
      "activated x value: tensor([-3.7223, -7.5535,  0.7413, -2.0988,  8.4880, -2.1086, -0.1250, -0.0350,\n",
      "         2.5927,  3.7884], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5006], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2223e+01, -1.6054e+01, -7.7593e+00, -1.0599e+01, -1.2639e-02,\n",
      "        -1.0609e+01, -8.6256e+00, -8.5356e+00, -5.9079e+00, -4.7122e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-5.9834, -3.4055, -2.4715, -0.4480,  6.2688, -1.9194, -0.2465,  0.2427,\n",
      "         2.8305,  4.9725], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5398], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.5232,  -9.9453,  -9.0113,  -6.9879,  -0.2710,  -8.4592,  -6.7863,\n",
      "         -6.2971,  -3.7093,  -1.5673], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.271\n",
      "activated x value: tensor([ 12.4472, -14.5975,   4.9522,   1.2972,  -3.5035,   2.8376,   3.1994,\n",
      "         -5.4983,   1.7161,  -2.0557], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4480], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5626e-04, -2.7045e+01, -7.4957e+00, -1.1151e+01, -1.5951e+01,\n",
      "        -9.6104e+00, -9.2486e+00, -1.7946e+01, -1.0732e+01, -1.4504e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.6610,  1.8336,  8.8949,  4.4020, -5.9885, -2.0790,  0.2111,  0.2220,\n",
      "        -0.2127, -2.9510], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9074], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3568e+01, -7.0738e+00, -1.2445e-02, -4.5053e+00, -1.4896e+01,\n",
      "        -1.0986e+01, -8.6962e+00, -8.6853e+00, -9.1201e+00, -1.1858e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-3.0291, -2.6972,  3.6821, -4.1818,  2.6201, -0.7242,  9.7000, -3.1710,\n",
      "        -0.3898, -2.1427], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7034], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2732e+01, -1.2401e+01, -6.0212e+00, -1.3885e+01, -7.0833e+00,\n",
      "        -1.0428e+01, -3.3598e-03, -1.2874e+01, -1.0093e+01, -1.1846e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ -0.0706,  -3.0514,   2.0137,   2.8861,  -3.3443,   3.7955,   2.9565,\n",
      "        -10.0675,   6.4765,  -1.3535], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6068], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6774,  -9.6582,  -4.5931,  -3.7207,  -9.9511,  -2.8113,  -3.6503,\n",
      "        -16.6743,  -0.1303,  -7.9603], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 3.0824, -7.0531,  2.3593,  1.8244, -4.9116,  2.1579, -3.4415, -5.6691,\n",
      "         7.3235,  3.1703], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3693], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.2869, -14.4225,  -5.0100,  -5.5450, -12.2810,  -5.2114, -10.8109,\n",
      "        -13.0385,  -0.0459,  -4.1990], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.046\n",
      "activated x value: tensor([-7.0014,  4.5929,  0.0523, -0.2068,  2.8249, -1.3269,  0.8211,  0.2676,\n",
      "        -0.2321,  0.6023], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8201], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8215,  -0.2271,  -4.7678,  -5.0269,  -1.9952,  -6.1470,  -3.9990,\n",
      "         -4.5525,  -5.0522,  -4.2178], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.995\n",
      "activated x value: tensor([-0.5965, -4.6885,  3.5811, -2.8780,  1.9433,  1.5844, 11.0832, -7.8991,\n",
      "         0.6671, -2.4052], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.0839], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1680e+01, -1.5772e+01, -7.5029e+00, -1.3962e+01, -9.1406e+00,\n",
      "        -9.4995e+00, -7.7438e-04, -1.8983e+01, -1.0417e+01, -1.3489e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-0.7303, -4.3473,  5.8991,  0.4360, -0.5451,  4.3834,  5.2685, -9.6025,\n",
      "         3.0353, -3.5783], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4959], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.2262, -10.8432,  -0.5968,  -6.0599,  -7.0410,  -2.1125,  -1.2274,\n",
      "        -16.0984,  -3.4606, -10.0741], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.112\n",
      "activated x value: tensor([-2.0840, -5.2086,  2.4946,  2.5059, -0.1814,  1.4451, -0.8208, -4.8563,\n",
      "         5.4531,  1.0900], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5853], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6692, -10.7938,  -3.0907,  -3.0793,  -5.7666,  -4.1402,  -6.4061,\n",
      "        -10.4416,  -0.1322,  -4.4952], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.132\n",
      "activated x value: tensor([-2.7609,  1.7979,  0.0855, -3.6942,  7.0105, -6.2527,  5.8163, -5.6743,\n",
      "        -0.2072,  4.4246], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3365], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0975,  -5.5387,  -7.2511, -11.0307,  -0.3261, -13.5893,  -1.5203,\n",
      "        -13.0109,  -7.5437,  -2.9119], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -7.251\n",
      "activated x value: tensor([-0.8888, -6.6368,  2.1670, -3.4748,  6.9820, -1.4301,  3.3547, -2.5224,\n",
      "         0.5017,  1.8174], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0238], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9126, -13.6606,  -4.8568, -10.4986,  -0.0418,  -8.4539,  -3.6690,\n",
      "         -9.5462,  -6.5221,  -5.2064], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([-5.7884, -0.8262, 15.0528,  3.9354, -3.6124, -6.2067,  3.3455, -7.7264,\n",
      "         2.6172, -0.6479], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.0528], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0841e+01, -1.5879e+01, -2.7657e-05, -1.1117e+01, -1.8665e+01,\n",
      "        -2.1260e+01, -1.1707e+01, -2.2779e+01, -1.2436e+01, -1.5701e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-1.7438, -2.1945,  2.2156,  4.9648, -7.0479,  5.4833,  5.8143, -6.2531,\n",
      "         1.7757, -2.6200], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5991], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3428,  -8.7935,  -4.3835,  -1.6343, -13.6470,  -1.1157,  -0.7848,\n",
      "        -12.8521,  -4.8233,  -9.2190], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.634\n",
      "activated x value: tensor([-5.4379, -5.7112, -5.7268,  1.8049,  4.4319,  1.9055, -5.5130,  2.4562,\n",
      "         3.0480,  7.9350], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9804], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.4184, -13.6916, -13.7072,  -6.1755,  -3.5485,  -6.0749, -13.4934,\n",
      "         -5.5243,  -4.9324,  -0.0454], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-2.9750,  0.8079,  0.3198,  2.7850, -2.5296,  2.2946, -5.3636, -1.2233,\n",
      "         4.9074,  1.1923], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1285], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.1035,  -4.3206,  -4.8087,  -2.3434,  -7.6580,  -2.8339, -10.4920,\n",
      "         -6.3518,  -0.2210,  -3.9362], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.221\n",
      "activated x value: tensor([-6.3105,  5.6306,  0.8908,  3.4225, -3.2731, -2.2623, -3.3380,  2.8321,\n",
      "         0.6890,  2.9148], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8565], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.1670,  -0.2259,  -4.9657,  -2.4340,  -9.1296,  -8.1189,  -9.1945,\n",
      "         -3.0244,  -5.1675,  -2.9418], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.226\n",
      "activated x value: tensor([-3.8688, -4.8804, -1.5098, -0.6710,  7.3545, -0.3454, -1.4998,  2.4556,\n",
      "         0.3106,  2.7672], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3739], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2427, -12.2543,  -8.8837,  -8.0449,  -0.0194,  -7.7193,  -8.8737,\n",
      "         -4.9184,  -7.0633,  -4.6067], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-2.5071, -9.6491,  0.9709, -3.9470, 10.5068, -3.2897,  1.0059, -2.0833,\n",
      "         4.0403,  5.9140], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.5186], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3026e+01, -2.0168e+01, -9.5476e+00, -1.4466e+01, -1.1765e-02,\n",
      "        -1.3808e+01, -9.5127e+00, -1.2602e+01, -6.4782e+00, -4.6045e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-2.8051,  3.9356, -3.8459,  1.4552, -1.7043,  2.2781, -2.4144,  1.5754,\n",
      "         1.5282,  0.5897], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3416], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.1467, -0.4061, -8.1875, -2.8865, -6.0460, -2.0635, -6.7561, -2.7663,\n",
      "        -2.8134, -3.7520], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.406\n",
      "activated x value: tensor([-3.4980, -1.4456, -0.7913,  0.2953,  2.1266, -2.8352, -1.8243,  2.9070,\n",
      "         0.6719,  5.0322], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2160], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.7140, -6.6616, -6.0074, -4.9207, -3.0894, -8.0512, -7.0403, -2.3090,\n",
      "        -4.5441, -0.1838], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.184\n",
      "activated x value: tensor([11.9066, -8.5190, -0.1534,  1.3908, -6.6519,  3.2461, -1.3501, -1.1279,\n",
      "         3.2980, -0.8314], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.9070], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.9577e-04, -2.0426e+01, -1.2060e+01, -1.0516e+01, -1.8559e+01,\n",
      "        -8.6609e+00, -1.3257e+01, -1.3035e+01, -8.6090e+00, -1.2738e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([  7.9672, -13.1986,   1.6196,  -1.1759,   0.2178,   4.9611,   2.9816,\n",
      "         -2.8281,   0.0903,  -0.3835], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0248], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0576, -21.2233,  -6.4051,  -9.2007,  -7.8070,  -3.0637,  -5.0432,\n",
      "        -10.8529,  -7.9345,  -8.4083], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.058\n",
      "activated x value: tensor([ 3.5087, -7.3099,  3.4210, -1.4484, -1.0838,  0.2886,  6.9191, -2.1502,\n",
      "         0.1201, -2.0129], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9836], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.4749, -14.2934,  -3.5626,  -8.4319,  -8.0674,  -6.6949,  -0.0644,\n",
      "         -9.1338,  -6.8635,  -8.9964], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.064\n",
      "activated x value: tensor([  3.8367,   2.6204,  10.2108,   6.3733, -10.0039,   0.5328,   2.2314,\n",
      "         -8.4803,   1.1526,  -7.2469], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2348], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.3981,  -7.6144,  -0.0240,  -3.8614, -20.2387,  -9.7020,  -8.0033,\n",
      "        -18.7151,  -9.0822, -17.4816], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([ 1.8734, -3.2537, -1.5854,  0.0369,  0.4876,  5.7584,  3.9804, -5.0468,\n",
      "        -0.9916, -0.4575], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9423], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.0689,  -9.1960,  -7.5277,  -5.9054,  -5.4547,  -0.1839,  -1.9619,\n",
      "        -10.9891,  -6.9339,  -6.3998], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.184\n",
      "activated x value: tensor([  1.7710, -11.2833,   1.1945,   4.9889,  -4.0199,  -1.5596,  -8.9608,\n",
      "         13.6334,  -1.5554,   5.7771], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.6340], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1863e+01, -2.4917e+01, -1.2439e+01, -8.6451e+00, -1.7654e+01,\n",
      "        -1.5194e+01, -2.2595e+01, -5.7507e-04, -1.5189e+01, -7.8569e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-5.2183, -8.4478, -0.7156, -4.3779,  8.7087, -3.2083, -0.8765,  6.5040,\n",
      "         1.5066,  4.8813], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8335], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.0518, -17.2813,  -9.5492, -13.2114,  -0.1248, -12.0419,  -9.7101,\n",
      "         -2.3296,  -7.3270,  -3.9523], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.125\n",
      "activated x value: tensor([-6.7763,  7.7732,  1.7988,  0.8766, -2.0732, -1.2788,  0.1358, -0.0079,\n",
      "         0.9954, -0.8176], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7792], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4556e+01, -5.9309e-03, -5.9804e+00, -6.9025e+00, -9.8524e+00,\n",
      "        -9.0580e+00, -7.6433e+00, -7.7870e+00, -6.7838e+00, -8.5968e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-6.5007e+00,  8.5718e-01,  9.7755e+00,  3.5189e+00, -6.1557e+00,\n",
      "        -2.6561e+00, -3.3245e-01,  1.6060e+00, -1.9969e-03, -1.2322e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7780], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6279e+01, -8.9208e+00, -2.4500e-03, -6.2591e+00, -1.5934e+01,\n",
      "        -1.2434e+01, -1.0110e+01, -8.1720e+00, -9.7800e+00, -1.1010e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-3.5095, -6.6755, -1.3146,  0.3694,  3.9589, -1.9130, -0.5850,  0.5885,\n",
      "         3.1056,  6.3197], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4526], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.9621, -13.1281,  -7.7672,  -6.0832,  -2.4937,  -8.3656,  -7.0377,\n",
      "         -5.8642,  -3.3470,  -0.1330], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.133\n",
      "activated x value: tensor([-0.2437, -5.2434,  2.3467, -3.9002,  1.3324, -3.1730,  8.6666, -0.8901,\n",
      "         0.4189,  0.4623], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6698], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9135e+00, -1.3913e+01, -6.3230e+00, -1.2570e+01, -7.3374e+00,\n",
      "        -1.1843e+01, -3.2005e-03, -9.5598e+00, -8.2509e+00, -8.2075e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 2.2349, -3.4556,  3.8507,  9.3041, -7.2640,  1.1756, -3.3400, -5.9081,\n",
      "         5.2572, -1.7611], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.3268], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0919, -12.7824,  -5.4761,  -0.0227, -16.5908,  -8.1512, -12.6668,\n",
      "        -15.2349,  -4.0696, -11.0879], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-2.8126, -4.2250, -3.0956,  1.7470, -0.0780,  4.1824, -1.6061, -0.1130,\n",
      "         2.0765,  4.3329], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0597], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8722, -9.2847, -8.1553, -3.3126, -5.1376, -0.8773, -6.6657, -5.1726,\n",
      "        -2.9832, -0.7268], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.727\n",
      "activated x value: tensor([-1.4745, -7.8262,  0.8081, -3.5904, 12.2621, -9.8815,  5.5067, -0.3023,\n",
      "         2.2456,  3.6181], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.2635], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3738e+01, -2.0090e+01, -1.1455e+01, -1.5854e+01, -1.4000e-03,\n",
      "        -2.2145e+01, -6.7568e+00, -1.2566e+01, -1.0018e+01, -8.6454e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 6.7493, -6.2511,  1.7938, -0.3874, -2.0710,  2.0250, -0.7530, -1.7948,\n",
      "         2.1310, -0.9219], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7769], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0276, -13.0280,  -4.9831,  -7.1643,  -8.8478,  -4.7519,  -7.5298,\n",
      "         -8.5716,  -4.6459,  -7.6987], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([ 1.1147, -5.1490,  0.2206,  3.7053, -2.5506,  8.0758, -0.5168, -8.4241,\n",
      "         3.3156,  0.3557], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0987], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9840, -13.2477,  -7.8782,  -4.3934, -10.6493,  -0.0229,  -8.6155,\n",
      "        -16.5228,  -4.7831,  -7.7430], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-6.3599,  8.0108,  0.2103,  2.5339, -4.8977, -0.0614, -0.8469, -0.3941,\n",
      "         1.0787,  1.2823], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([8.0182], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4378e+01, -7.4177e-03, -7.8079e+00, -5.4843e+00, -1.2916e+01,\n",
      "        -8.0796e+00, -8.8651e+00, -8.4123e+00, -6.9395e+00, -6.7359e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-1.6075, -5.6050, -0.4928,  0.1289,  6.3597,  0.5681, -0.4385, -0.9196,\n",
      "        -0.2115,  1.7570], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3792], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9867, -11.9842,  -6.8720,  -6.2503,  -0.0195,  -5.8111,  -6.8177,\n",
      "         -7.2988,  -6.5907,  -4.6223], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-6.0679,  3.1956,  0.5603,  2.5406, -3.3662, -1.4751, -4.0343,  7.1866,\n",
      "        -0.8001,  2.2360], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2230], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.2909,  -4.0274,  -6.6627,  -4.6824, -10.5892,  -8.6981, -11.2573,\n",
      "         -0.0364,  -8.0231,  -4.9870], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.036\n",
      "activated x value: tensor([-1.5402,  1.1130,  3.6765,  7.6149, -6.4931,  3.8282, -1.7664, -7.3953,\n",
      "         3.6323, -2.0338], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6756], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2157,  -6.5626,  -3.9991,  -0.0607, -14.1687,  -3.8474,  -9.4419,\n",
      "        -15.0709,  -4.0433,  -9.7094], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.061\n",
      "activated x value: tensor([ 5.0053, -7.8460, -9.0327, -0.1533,  0.1544, 10.0410, -1.8674, -3.6352,\n",
      "         3.5348,  3.8774], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0511], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.0458e+00, -1.7897e+01, -1.9084e+01, -1.0204e+01, -9.8967e+00,\n",
      "        -1.0146e-02, -1.1919e+01, -1.3686e+01, -6.5163e+00, -6.1737e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-0.8087, -0.4614, -0.5286,  9.1895, -2.3068,  2.1101, -5.2735, -2.2662,\n",
      "         0.5781, -0.1122], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1908], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.9995e+00, -9.6522e+00, -9.7194e+00, -1.3056e-03, -1.1498e+01,\n",
      "        -7.0807e+00, -1.4464e+01, -1.1457e+01, -8.6127e+00, -9.3030e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 9.7724, -8.4596, -6.2789,  2.8890, -0.3843,  9.1140, -3.4259, -3.0865,\n",
      "         1.8965, -0.6988], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1906], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.4181, -18.6501, -16.4694,  -7.3016, -10.5748,  -1.0766, -13.6165,\n",
      "        -13.2771,  -8.2941, -10.8894], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.418\n",
      "activated x value: tensor([ 3.5392, -9.1869,  4.7534,  6.5776, -0.3477,  3.1653, -0.8126, -3.6602,\n",
      "        -1.5980, -2.7890], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7961], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.2569, -15.9830,  -2.0427,  -0.2185,  -7.1438,  -3.6308,  -7.6087,\n",
      "        -10.4563,  -8.3941,  -9.5851], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -2.043\n",
      "activated x value: tensor([  8.8556, -10.8467,   0.0901,   1.2507,  -2.5610,   3.2226,   1.0224,\n",
      "         -2.2509,   0.9818,   0.5560], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8609], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2691e-03, -1.9708e+01, -8.7708e+00, -7.6102e+00, -1.1422e+01,\n",
      "        -5.6383e+00, -7.8385e+00, -1.1112e+01, -7.8791e+00, -8.3049e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([ 0.7543, -4.6382, -1.5812,  0.4617,  2.3417,  7.9086,  0.2998, -3.8593,\n",
      "         1.1700, -3.0621], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9155], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.1612e+00, -1.2554e+01, -9.4968e+00, -7.4539e+00, -5.5738e+00,\n",
      "        -6.9475e-03, -7.6157e+00, -1.1775e+01, -6.7456e+00, -1.0978e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-3.7141, -5.4618, -2.1092,  2.0970,  2.0305,  0.5565, -3.6207,  2.3072,\n",
      "         1.8274,  5.7581], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8599], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.5740, -11.3217,  -7.9690,  -3.7629,  -3.8294,  -5.3033,  -9.4806,\n",
      "         -3.5527,  -4.0325,  -0.1018], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.102\n",
      "activated x value: tensor([  3.4348,  -7.2324,   3.8184,   2.4190,  -3.4545,   3.9227,   1.4797,\n",
      "        -11.3941,   6.8541,   0.1957], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9955], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.5607, -14.2279,  -3.1771,  -4.5765, -10.4500,  -3.0728,  -5.5158,\n",
      "        -18.3896,  -0.1414,  -6.7998], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.141\n",
      "activated x value: tensor([-7.5046,  6.7357, -1.4796,  3.9183, -3.8953,  0.8890, -1.5753, -0.9978,\n",
      "         1.6826,  1.7286], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8096], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.3142,  -0.0739,  -8.2892,  -2.8912, -10.7049,  -5.9206,  -8.3849,\n",
      "         -7.8074,  -5.1270,  -5.0810], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.074\n",
      "activated x value: tensor([-2.3400, -7.8243, -0.5600,  0.8479,  2.0950,  2.3319, -0.9969, -0.9244,\n",
      "         6.2000,  0.3239], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2467], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.5867, -14.0710,  -6.8067,  -5.3988,  -4.1517,  -3.9148,  -7.2436,\n",
      "         -7.1712,  -0.0467,  -5.9228], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.047\n",
      "activated x value: tensor([-0.7743, -4.6363, -6.1496,  0.4675,  4.8452,  1.2578, -3.3904,  2.7924,\n",
      "        -0.4399,  5.3788], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9039], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6783, -10.5403, -12.0535,  -5.4364,  -1.0587,  -4.6462,  -9.2944,\n",
      "         -3.1115,  -6.3438,  -0.5251], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.525\n",
      "activated x value: tensor([-0.8635, -3.0614, -0.3619, -0.1102,  0.9515, -1.7866, -0.4572, -0.1909,\n",
      "         1.0771,  5.0433], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1010], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9645, -8.1624, -5.4629, -5.2112, -4.1495, -6.8876, -5.5582, -5.2919,\n",
      "        -4.0239, -0.0577], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.058\n",
      "activated x value: tensor([  0.2121, -10.6098,  -0.1482,  -3.3977,   7.7852,  -4.2119,  -0.8412,\n",
      "          1.9563,   1.7501,   6.3954], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0128], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.8007, -18.6226,  -8.1610, -11.4105,  -0.2276, -12.2247,  -8.8540,\n",
      "         -6.0565,  -6.2627,  -1.6174], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.228\n",
      "activated x value: tensor([-3.0357, -0.1976, -0.3902,  0.9800, -0.4896,  2.3738, -0.0202, -3.0653,\n",
      "         3.2246,  0.3748], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7655], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8013, -3.9631, -4.1557, -2.7855, -4.2551, -1.3918, -3.7857, -6.8308,\n",
      "        -0.5409, -3.3907], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.541\n",
      "activated x value: tensor([ 0.3271, -6.5225,  9.0006,  1.0536,  2.0275, -3.8381,  1.3584, -2.5925,\n",
      "        -2.1734,  0.4812], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0028], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6757e+00, -1.5525e+01, -2.1648e-03, -7.9492e+00, -6.9753e+00,\n",
      "        -1.2841e+01, -7.6445e+00, -1.1595e+01, -1.1176e+01, -8.5217e+00],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 0.0505, -3.1077,  0.4914,  3.9646,  3.0695,  1.4895, -0.1131, -7.3925,\n",
      "         1.4194,  0.2152], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4735], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.4230,  -7.5812,  -3.9821,  -0.5089,  -1.4040,  -2.9840,  -4.5866,\n",
      "        -11.8660,  -3.0541,  -4.2583], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.509\n",
      "activated x value: tensor([-4.2710, -3.3171,  2.7023, -0.1174,  2.0406,  0.3092,  5.3533, -3.0046,\n",
      "        -0.1908,  0.4342], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4750], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.7459, -8.7921, -2.7726, -5.5924, -3.4344, -5.1657, -0.1216, -8.4796,\n",
      "        -5.6657, -5.0408], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.122\n",
      "activated x value: tensor([-3.4534, -3.5318, -2.3766,  7.5038,  0.5102,  3.7122, -5.9220, -1.7502,\n",
      "         3.4569,  2.6489], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5516], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.0049, -11.0834,  -9.9282,  -0.0478,  -7.0414,  -3.8394, -13.4735,\n",
      "         -9.3018,  -4.0947,  -4.9027], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.048\n",
      "activated x value: tensor([-4.6035, -1.2397,  9.7217,  5.6591, -3.2693, -3.4863,  3.2904, -3.5118,\n",
      "        -1.6543,  0.4463], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7405], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.3439, -10.9801,  -0.0188,  -4.0813, -13.0098, -13.2268,  -6.4500,\n",
      "        -13.2523, -11.3947,  -9.2942], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([ -6.4801,   3.9068,  13.6212,   3.6025,  -5.4408,  -3.8603,   4.9054,\n",
      "        -14.1140,   5.1169,  -1.2465], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.6216], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0102e+01, -9.7148e+00, -4.7207e-04, -1.0019e+01, -1.9062e+01,\n",
      "        -1.7482e+01, -8.7163e+00, -2.7736e+01, -8.5047e+00, -1.4868e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-1.6724, -4.6358, -1.5552,  0.8464,  1.7207,  4.2383, -0.0468, -3.5693,\n",
      "         1.6568,  2.1221], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5239], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.1963, -9.1597, -6.0791, -3.6775, -2.8031, -0.2856, -4.5707, -8.0932,\n",
      "        -2.8670, -2.4018], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.286\n",
      "activated x value: tensor([  3.6789, -10.6855,  -1.5838,   0.9587,   3.1827,   5.7327,  -2.7624,\n",
      "         -4.3400,   3.3086,   1.8986], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0148], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -2.3358, -16.7003,  -7.5986,  -5.0560,  -2.8320,  -0.2821,  -8.7772,\n",
      "        -10.3547,  -2.7061,  -4.1161], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.282\n",
      "activated x value: tensor([-1.7449, -1.4405, 12.1738,  1.5671, -2.3658, -3.0301,  1.2766, -7.4162,\n",
      "         2.4759, -2.1364], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.1739], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3919e+01, -1.3614e+01, -1.0777e-04, -1.0607e+01, -1.4540e+01,\n",
      "        -1.5204e+01, -1.0897e+01, -1.9590e+01, -9.6980e+00, -1.4310e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-7.8311,  0.3823,  1.3562,  2.0907,  2.7052,  3.1572, -2.7082, -3.2022,\n",
      "         5.2686, -1.9844], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5065], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.3375,  -5.1242,  -4.1503,  -3.4158,  -2.8013,  -2.3492,  -8.2147,\n",
      "         -8.7087,  -0.2379,  -7.4909], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.238\n",
      "activated x value: tensor([ 10.1218, -12.5932,   3.0644,   2.4311,  -3.4072,   4.0012,  -5.9022,\n",
      "         -1.2246,   2.4891,   1.5860], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1260], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.2000e-03, -2.2719e+01, -7.0616e+00, -7.6949e+00, -1.3533e+01,\n",
      "        -6.1248e+00, -1.6028e+01, -1.1351e+01, -7.6368e+00, -8.5399e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-8.0849, -0.3943,  1.6173,  3.3470, -1.7551, -2.9098, -5.2706,  5.5445,\n",
      "         1.4740,  7.1601], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3662], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.4511,  -7.7605,  -5.7489,  -4.0192,  -9.1213, -10.2760, -12.6368,\n",
      "         -1.8217,  -5.8922,  -0.2061], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.822\n",
      "activated x value: tensor([-2.5766,  7.2509,  0.7691,  5.6518, -6.7808,  5.6067, -7.5737, -0.9279,\n",
      "         2.1292, -3.6442], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5896], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1662,  -0.3387,  -6.8205,  -1.9378, -14.3704,  -1.9829, -15.1633,\n",
      "         -8.5174,  -5.4604, -11.2337], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.983\n",
      "activated x value: tensor([ 9.8388, -6.5755,  4.3680,  1.2354, -6.8172, -0.5190,  3.6125, -1.9587,\n",
      "         0.4246, -1.6772], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8453], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.4783e-03, -1.6421e+01, -5.4772e+00, -8.6099e+00, -1.6662e+01,\n",
      "        -1.0364e+01, -6.2328e+00, -1.1804e+01, -9.4207e+00, -1.1522e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-0.2060, -1.8701,  0.0498,  1.4663, -0.4853,  3.5541, -0.7459, -2.7024,\n",
      "         1.2497, -0.0436], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8483], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.0543, -5.7184, -3.7985, -2.3820, -4.3335, -0.2942, -4.5942, -6.5507,\n",
      "        -2.5985, -3.8918], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.294\n",
      "activated x value: tensor([ 1.2561, -6.2802, -5.7773,  2.0869, -1.5418,  8.8490, -3.3133, -2.3302,\n",
      "         5.1072,  1.7263], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8749], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6188, -15.1551, -14.6522,  -6.7880, -10.4167,  -0.0259, -12.1882,\n",
      "        -11.2051,  -3.7678,  -7.1486], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.026\n",
      "activated x value: tensor([-3.6246, -0.7201, -0.0815,  0.4331,  0.8645,  4.1876,  0.6435, -3.9546,\n",
      "         2.2767, -0.2571], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4267], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0513, -5.1468, -4.5082, -3.9936, -3.5622, -0.2391, -3.7832, -8.3813,\n",
      "        -2.1500, -4.6838], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -3.994\n",
      "activated x value: tensor([-5.0183,  0.3602, -2.3733,  0.5406, -2.9145,  2.8520, -5.2216,  5.0998,\n",
      "         5.6121,  0.0825], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1300], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.1483,  -5.7698,  -8.5033,  -5.5894,  -9.0445,  -3.2780, -11.3515,\n",
      "         -1.0302,  -0.5179,  -6.0475], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.518\n",
      "activated x value: tensor([-6.4189,  7.6360,  1.7641,  1.8598, -2.8200, -1.3356, -1.0993,  0.8203,\n",
      "         1.1925, -1.0849], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6451], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4064e+01, -9.0442e-03, -5.8810e+00, -5.7853e+00, -1.0465e+01,\n",
      "        -8.9806e+00, -8.7444e+00, -6.8248e+00, -6.4526e+00, -8.7300e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-0.8645,  2.0308,  1.4574,  3.0142, -4.3398,  1.1408,  0.1024, -3.7168,\n",
      "         2.5500, -0.4207], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.9209], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.7855, -1.8902, -2.4635, -0.9068, -8.2608, -2.7801, -3.8185, -7.6377,\n",
      "        -1.3709, -4.3416], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.907\n",
      "activated x value: tensor([-2.5558, -9.9886,  3.7973,  0.8357,  2.5627,  3.1835, -3.8430, -3.9839,\n",
      "         8.4164,  0.0906], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4351], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9909, -18.4237,  -4.6378,  -7.5994,  -5.8723,  -5.2516, -12.2781,\n",
      "        -12.4190,  -0.0187,  -8.3445], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-4.2178, -4.5857,  2.0756, -2.7683,  3.2540,  1.2785,  7.8187, -3.1039,\n",
      "        -0.3631, -0.3943], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8342], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.0520, -12.4199,  -5.7587, -10.6025,  -4.5803,  -6.5557,  -0.0155,\n",
      "        -10.9381,  -8.1973,  -8.2286], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([ 1.9246, -3.1044,  1.9608,  1.0018, -1.0206, -1.4937,  5.2323, -3.8605,\n",
      "         3.6199, -3.8132], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4886], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.5639, -8.5930, -3.5278, -4.4868, -6.5092, -6.9823, -0.2563, -9.3491,\n",
      "        -1.8687, -9.3018], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-4.8999, -0.6269,  4.9549, 11.0326, -2.8183, -0.2035, -6.3576, -2.3863,\n",
      "         3.1760, -1.5326], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.0353], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5935e+01, -1.1662e+01, -6.0804e+00, -2.7046e-03, -1.3854e+01,\n",
      "        -1.1239e+01, -1.7393e+01, -1.3422e+01, -7.8593e+00, -1.2568e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-4.9228,  5.4347,  1.6046,  4.4142, -5.2099,  0.1748, -2.4338, -0.2939,\n",
      "         4.1984, -2.2128], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9547], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8775,  -0.5199,  -4.3501,  -1.5404, -11.1646,  -5.7799,  -8.3885,\n",
      "         -6.2486,  -1.7563,  -8.1675], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.756\n",
      "activated x value: tensor([ 2.5886, -6.8797, 10.6297,  7.2246, -5.1853, -3.5967,  1.6318, -3.3349,\n",
      "         1.0749, -4.1979], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6629], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.0743, -17.5426,  -0.0332,  -3.4383, -15.8482, -14.2596,  -9.0311,\n",
      "        -13.9978,  -9.5879, -14.8607], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([-4.8396,  4.8754,  0.7917,  1.5528, -1.6139, -0.9959, -1.4885,  2.1490,\n",
      "        -0.2579,  0.3681], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0076], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8473, -0.1323, -4.2159, -3.4549, -6.6215, -6.0036, -6.4961, -2.8587,\n",
      "        -5.2655, -4.6395], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.132\n",
      "activated x value: tensor([-0.3508, -3.9437, -4.1215, 10.8992, -5.3589,  3.9003, -7.9145,  3.3499,\n",
      "        -0.1708,  3.3193], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9012], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1252e+01, -1.4845e+01, -1.5023e+01, -1.9770e-03, -1.6260e+01,\n",
      "        -7.0009e+00, -1.8816e+01, -7.5513e+00, -1.1072e+01, -7.5819e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 6.6192, -3.7526, -0.7366,  0.2738, -5.8111,  4.1250, -0.6783,  0.5549,\n",
      "         2.4475, -1.9326], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7178], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0986, -10.4704,  -7.4544,  -6.4440, -12.5289,  -2.5928,  -7.3961,\n",
      "         -6.1629,  -4.2703,  -8.6504], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.593\n",
      "activated x value: tensor([-7.5482,  0.6560, -3.2265,  0.0753,  2.4147,  3.1212, -1.9501, -2.5673,\n",
      "         3.7962,  5.6567], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9077], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.4560,  -5.2517,  -9.1343,  -5.8324,  -3.4931,  -2.7865,  -7.8578,\n",
      "         -8.4751,  -2.1115,  -0.2510], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.251\n",
      "activated x value: tensor([-4.0063, -1.7692, -4.2147, -1.5288,  8.8135, -1.4970, -1.8311, -1.7399,\n",
      "         2.6055,  5.1792], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8416], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.8479, -10.6108, -13.0563, -10.3704,  -0.0282, -10.3387, -10.6727,\n",
      "        -10.5815,  -6.2361,  -3.6624], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-0.1679, -7.2311, -3.2725, -6.4301,  5.2533,  0.3319, -0.0972,  1.4177,\n",
      "         2.9826,  8.0880], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1529], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3208, -15.3840, -11.4254, -14.5830,  -2.8996,  -7.8210,  -8.2501,\n",
      "         -6.7352,  -5.1703,  -0.0649], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.065\n",
      "activated x value: tensor([ 1.4487, -6.0126,  4.2598, -2.6023, -0.5589, -1.4179,  9.9709, -8.6824,\n",
      "         3.4789,  0.3622], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9760], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.5273e+00, -1.5989e+01, -5.7162e+00, -1.2578e+01, -1.0535e+01,\n",
      "        -1.1394e+01, -5.1193e-03, -1.8658e+01, -6.4971e+00, -9.6138e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-6.7791,  7.9784,  1.5388,  2.3464, -5.8701,  1.2515,  0.7529, -3.9284,\n",
      "         4.5906, -1.3933], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0186], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.7977,  -0.0402,  -6.4798,  -5.6722, -13.8887,  -6.7671,  -7.2656,\n",
      "        -11.9469,  -3.4279,  -9.4119], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.040\n",
      "activated x value: tensor([-2.8770, -6.8933,  2.2635, -1.5439,  4.2228,  2.5879,  2.0800, -1.1053,\n",
      "        -0.4759,  1.1950], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6413], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5183, -11.5345,  -2.3778,  -6.1851,  -0.4184,  -2.0533,  -2.5613,\n",
      "         -5.7466,  -5.1172,  -3.4463], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.418\n",
      "activated x value: tensor([-2.3579, -5.5394,  0.9827, -2.4201,  5.8144, -1.2696,  0.9974, -1.1760,\n",
      "         1.3994,  2.9678], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8992], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.2572, -11.4387,  -4.9165,  -8.3193,  -0.0848,  -7.1689,  -4.9018,\n",
      "         -7.0753,  -4.4999,  -2.9315], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.085\n",
      "activated x value: tensor([-10.6364,   5.2799,  -2.0926,   1.9902,   0.2688,   1.3192,  -0.1982,\n",
      "         -0.2480,   2.3800,   0.8010], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4093], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.0456,  -0.1294,  -7.5018,  -3.4191,  -5.1404,  -4.0901,  -5.6074,\n",
      "         -5.6573,  -3.0292,  -4.6083], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.129\n",
      "activated x value: tensor([ 0.1656, -9.0945,  0.8257, -4.3049,  5.1178, -0.3813,  0.6423,  0.6750,\n",
      "         2.3199,  3.3515], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3646], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.1990, -14.4592,  -4.5389,  -9.6696,  -0.2468,  -5.7459,  -4.7223,\n",
      "         -4.6896,  -3.0448,  -2.0131], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.247\n",
      "activated x value: tensor([ 0.1037, -2.5374,  0.0624,  0.2143, -2.8678,  3.6141,  8.5417, -9.2423,\n",
      "         3.5147, -1.6304], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5561], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.4525e+00, -1.1094e+01, -8.4938e+00, -8.3418e+00, -1.1424e+01,\n",
      "        -4.9420e+00, -1.4428e-02, -1.7798e+01, -5.0414e+00, -1.0187e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([ 0.6241, -3.6718,  1.2729, -3.0063,  1.5784, -1.7856,  7.9219, -3.8584,\n",
      "         0.3598,  1.2178], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9274], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.3033e+00, -1.1599e+01, -6.6545e+00, -1.0934e+01, -6.3490e+00,\n",
      "        -9.7130e+00, -5.5566e-03, -1.1786e+01, -7.5676e+00, -6.7096e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 6.9705, -7.6418,  2.5149, -1.3150, -4.1262,  3.4243,  2.6474, -2.9721,\n",
      "         4.7066, -3.5329], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1172], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1467, -14.7590,  -4.6023,  -8.4323, -11.2435,  -3.6929,  -4.4698,\n",
      "        -10.0893,  -2.4106, -10.6502], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -4.470\n",
      "activated x value: tensor([-6.8205, -9.5447, -5.0557, -1.2618,  8.7496,  0.6384, -1.6024,  1.9656,\n",
      "         3.4723,  8.2622], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2326], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.0531, -18.7773, -14.2883, -10.4944,  -0.4829,  -8.5941, -10.8350,\n",
      "         -7.2669,  -5.7603,  -0.9704], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.483\n",
      "activated x value: tensor([-5.6616,  2.8051,  7.2525,  2.3365, -7.3771,  0.5239,  1.1810, -4.2033,\n",
      "         6.5410, -3.8346], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6669], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.3285,  -4.8618,  -0.4144,  -5.3305, -15.0441,  -7.1430,  -6.4859,\n",
      "        -11.8702,  -1.1260, -11.5015], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.414\n",
      "activated x value: tensor([ -1.9723,  -3.2120,   2.6803,   3.2116,   0.2012,   3.7415,   1.4110,\n",
      "        -10.0000,   8.7301,  -4.1140], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7441], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0716e+01, -1.1956e+01, -6.0638e+00, -5.5326e+00, -8.5430e+00,\n",
      "        -5.0026e+00, -7.3331e+00, -1.8744e+01, -1.3979e-02, -1.2858e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([-5.7758,  5.4955,  2.0371,  2.2982, -3.7719, -3.5863, -4.7104,  5.9137,\n",
      "        -0.7621,  2.7666], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([6.4734], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.2493,  -0.9780,  -4.4363,  -4.1752, -10.2453, -10.0597, -11.1838,\n",
      "         -0.5598,  -7.2355,  -3.7068], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.560\n",
      "activated x value: tensor([-1.1236, -5.3280, -6.1637,  4.5018, -2.5450,  7.3268, -9.4808,  3.4446,\n",
      "         3.0155,  7.7169], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2710], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.3945, -13.5989, -14.4347,  -3.7692, -10.8159,  -0.9442, -17.7518,\n",
      "         -4.8263,  -5.2555,  -0.5541], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.944\n",
      "activated x value: tensor([ -0.6679,  -2.3388,  14.9901,   5.6797,  -8.5503,  -0.0940,   5.2619,\n",
      "        -11.3683,   4.3858,  -7.6655], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.9903], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5658e+01, -1.7329e+01, -1.7548e-04, -9.3106e+00, -2.3541e+01,\n",
      "        -1.5084e+01, -9.7284e+00, -2.6359e+01, -1.0604e+01, -2.2656e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-2.3849, -1.0341, -3.3660,  0.2932,  3.1969,  1.4638, -1.0266, -0.6638,\n",
      "        -0.5046,  5.5967], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7091], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0940, -6.7432, -9.0751, -5.4159, -2.5122, -4.2453, -6.7357, -6.3729,\n",
      "        -6.2137, -0.1125], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.112\n",
      "activated x value: tensor([-7.3210, -1.4497, -0.1831,  1.3554,  1.3628,  1.5796, -2.4277,  0.2295,\n",
      "         2.8203,  4.7440], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9886], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.3096,  -6.4383,  -5.1717,  -3.6332,  -3.6258,  -3.4090,  -7.4163,\n",
      "         -4.7591,  -2.1683,  -0.2446], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.168\n",
      "activated x value: tensor([ 2.5349, -4.1819, -0.0212, -1.8308, -0.1758,  5.8101, -0.6353, -3.9105,\n",
      "         2.3011,  0.4362], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8870], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.3521, -10.0690,  -5.9083,  -7.7178,  -6.0628,  -0.0770,  -6.5224,\n",
      "         -9.7975,  -3.5859,  -5.4508], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.077\n",
      "activated x value: tensor([-0.0352, -4.7137,  0.0375,  4.5229, -0.3408,  5.3395,  1.2454, -6.0138,\n",
      "         2.8351, -3.2917], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7801], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8153, -10.4938,  -5.7426,  -1.2572,  -6.1209,  -0.4405,  -4.5347,\n",
      "        -11.7938,  -2.9450,  -9.0718], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.441\n",
      "activated x value: tensor([-5.1724, -3.1491,  5.5864,  6.7242, -3.2684,  1.2274, -3.9657, -5.2492,\n",
      "         8.6244, -1.1746], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8052], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.9776, -11.9543,  -3.2188,  -2.0810, -12.0736,  -7.5777, -12.7709,\n",
      "        -14.0544,  -0.1808,  -9.9798], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.181\n",
      "activated x value: tensor([-6.3149,  2.4227,  4.1200,  1.9631, -5.3551, -0.8976,  2.2368,  1.9881,\n",
      "         0.7771, -0.2154], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6054], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9203,  -2.1826,  -0.4853,  -2.6422,  -9.9605,  -5.5029,  -2.3685,\n",
      "         -2.6172,  -3.8282,  -4.8208], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.485\n",
      "activated x value: tensor([-1.7009, -7.4184,  4.6241, -1.9795,  1.7530,  1.5667, 12.6636, -9.5506,\n",
      "         0.8708, -0.8078], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.6640], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4365e+01, -2.0082e+01, -8.0399e+00, -1.4643e+01, -1.0911e+01,\n",
      "        -1.1097e+01, -3.6621e-04, -2.2215e+01, -1.1793e+01, -1.3472e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-1.8508, -6.7788,  0.1859,  2.5325, -0.9870, -0.8154, -7.5276, 10.8327,\n",
      "         0.6931,  3.0829], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.8334], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2684e+01, -1.7612e+01, -1.0648e+01, -8.3009e+00, -1.1820e+01,\n",
      "        -1.1649e+01, -1.8361e+01, -7.6103e-04, -1.0140e+01, -7.7505e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-5.2625, -1.1058,  2.2841, 10.9060, -1.9146,  0.1729, -8.0809, -0.7758,\n",
      "         3.7003,  0.1567], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9070], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6170e+01, -1.2013e+01, -8.6228e+00, -9.8228e-04, -1.2822e+01,\n",
      "        -1.0734e+01, -1.8988e+01, -1.1683e+01, -7.2067e+00, -1.0750e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.2008, -3.3162, -1.2321,  8.6616, -2.9276,  3.8522, -6.7165,  0.1151,\n",
      "         2.8099,  0.2442], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6730], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0874e+01, -1.1989e+01, -9.9051e+00, -1.1462e-02, -1.1601e+01,\n",
      "        -4.8209e+00, -1.5390e+01, -8.5579e+00, -5.8632e+00, -8.4289e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-3.5502, -4.8811,  2.1084,  1.6865, -2.6634,  2.5200, -2.9573, -6.3206,\n",
      "        10.3216,  2.8717], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3231], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3873e+01, -1.5204e+01, -8.2147e+00, -8.6366e+00, -1.2986e+01,\n",
      "        -7.8031e+00, -1.3280e+01, -1.6644e+01, -1.4439e-03, -7.4513e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([  3.3329,  -6.8856,   7.2023,  -3.4971,  -1.0757,  -1.4180,  14.8980,\n",
      "        -12.3892,   3.5870,  -2.8437], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.8984], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1565e+01, -2.1784e+01, -7.6962e+00, -1.8396e+01, -1.5974e+01,\n",
      "        -1.6316e+01, -4.7684e-04, -2.7288e+01, -1.1311e+01, -1.7742e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-5.5468, -2.4373,  4.4948,  0.9711,  2.2697,  0.4381,  1.3453, -6.4059,\n",
      "         5.5771, -1.2667], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9188], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.4656,  -8.3561,  -1.4239,  -4.9477,  -3.6491,  -5.4807,  -4.5735,\n",
      "        -12.3247,  -0.3416,  -7.1855], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.342\n",
      "activated x value: tensor([ 13.4783, -10.7441,  -0.7519,   1.6530,  -3.1547,   7.5771,  -4.4266,\n",
      "         -1.9647,   1.4962,  -1.1984], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.4810], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.7475e-03, -2.4225e+01, -1.4233e+01, -1.1828e+01, -1.6636e+01,\n",
      "        -5.9039e+00, -1.7908e+01, -1.5446e+01, -1.1985e+01, -1.4679e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-2.0841, -7.3468,  1.2715, -0.5615,  2.7078, -1.5229, -2.3230,  3.0139,\n",
      "         0.3549,  5.8343], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9485], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.0326, -13.2953,  -4.6770,  -6.5100,  -3.2407,  -7.4714,  -8.2715,\n",
      "         -2.9346,  -5.5936,  -0.1142], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.114\n",
      "activated x value: tensor([ 3.3862, -6.0403, 12.4169, -0.0386, -3.3280, -1.3857, -1.1291, -4.6869,\n",
      "         4.7908, -4.6658], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4175], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.0313e+00, -1.8458e+01, -6.1321e-04, -1.2456e+01, -1.5746e+01,\n",
      "        -1.3803e+01, -1.3547e+01, -1.7104e+01, -7.6267e+00, -1.7083e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.1480, -2.1153, -0.2794,  1.8012,  0.7396,  4.2008, -0.4343, -3.7987,\n",
      "         1.3580,  0.6396], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4109], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.5589, -6.5261, -4.6903, -2.6096, -3.6713, -0.2101, -4.8452, -8.2096,\n",
      "        -3.0528, -3.7713], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.210\n",
      "activated x value: tensor([ 0.8655, -8.8738,  2.1636, -7.3105,  6.4460,  2.0698,  5.3049, -3.1473,\n",
      "         1.0317,  1.1153], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7527], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8873, -15.6266,  -4.5891, -14.0632,  -0.3068,  -4.6829,  -1.4478,\n",
      "         -9.9001,  -5.7210,  -5.6374], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.307\n",
      "activated x value: tensor([-5.1794, -1.6215,  6.3515,  9.9165, -0.3175, -0.4556, -0.9674, -7.8204,\n",
      "         2.9631, -2.2242], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9454], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.1248, -11.5669,  -3.5939,  -0.0289, -10.2629, -10.4010, -10.9128,\n",
      "        -17.7658,  -6.9823, -12.1696], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.029\n",
      "activated x value: tensor([ 1.6686, -8.0976, 13.4873,  3.4488, -7.1979, -0.5330,  0.1632, -3.9912,\n",
      "         3.2123, -4.4908], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.4874], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1819e+01, -2.1585e+01, -8.7738e-05, -1.0039e+01, -2.0685e+01,\n",
      "        -1.4020e+01, -1.3324e+01, -1.7479e+01, -1.0275e+01, -1.7978e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 8.4967, -9.1973,  2.1146, -0.7952, -2.7783,  2.1924,  3.2858, -4.1430,\n",
      "         3.0445, -1.3110], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5100], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3338e-02, -1.7707e+01, -6.3954e+00, -9.3052e+00, -1.1288e+01,\n",
      "        -6.3176e+00, -5.2242e+00, -1.2653e+01, -5.4655e+00, -9.8210e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-1.7671, -9.9250, -0.6598,  1.7451,  2.0756, -2.7098, -3.4019,  6.2243,\n",
      "         0.8320,  7.5856], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8206], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.5877, -17.7455,  -8.4804,  -6.0755,  -5.7449, -10.5304, -11.2225,\n",
      "         -1.5963,  -6.9885,  -0.2349], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.235\n",
      "activated x value: tensor([-3.2087,  2.4151,  0.6279,  4.0936, -3.8567,  1.5203,  1.6547, -5.9832,\n",
      "         2.8032,  0.0369], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6094], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.8181,  -2.1942,  -3.9814,  -0.5158,  -8.4661,  -3.0890,  -2.9546,\n",
      "        -10.5925,  -1.8062,  -4.5725], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -2.955\n",
      "activated x value: tensor([-2.7578, -1.9388, -1.0018,  3.7811, -1.9038,  2.1049, -0.0818, -0.4448,\n",
      "         0.9983,  0.4194], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0706], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8284, -6.0094, -5.0724, -0.2895, -5.9743, -1.9657, -4.1524, -4.5154,\n",
      "        -3.0723, -3.6512], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.966\n",
      "activated x value: tensor([-5.0688, -6.7876, -0.1838, -6.0350,  8.0426, -5.7856,  5.7390,  3.0038,\n",
      "         0.4355,  6.1322], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2699], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.3387, -15.0575,  -8.4537, -14.3049,  -0.2273, -14.0555,  -2.5309,\n",
      "         -5.2661,  -7.8344,  -2.1377], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -2.531\n",
      "activated x value: tensor([-7.7033,  9.0826,  0.5323,  2.7773, -4.8298, -0.2620, -1.2657, -0.8244,\n",
      "         2.2215,  1.1495], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0862], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6789e+01, -3.5906e-03, -8.5539e+00, -6.3089e+00, -1.3916e+01,\n",
      "        -9.3482e+00, -1.0352e+01, -9.9106e+00, -6.8647e+00, -7.9367e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 0.4964, -8.3516,  1.6853,  1.5520,  0.6662,  5.0264,  0.2813, -6.7368,\n",
      "         4.3645,  1.7284], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5281], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.0317, -13.8797,  -3.8427,  -3.9760,  -4.8619,  -0.5017,  -5.2468,\n",
      "        -12.2649,  -1.1635,  -3.7997], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.502\n",
      "activated x value: tensor([ 4.2292, -6.4821, -2.5573, 12.8990, -6.2975,  2.9377, -8.5197,  5.2859,\n",
      "        -1.9796,  1.0057], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.8997], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6705e+00, -1.9382e+01, -1.5457e+01, -7.2002e-04, -1.9197e+01,\n",
      "        -9.9620e+00, -2.1419e+01, -7.6138e+00, -1.4879e+01, -1.1894e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.3232, -1.4726, -3.3752,  1.1531,  4.2423, -1.2463, -3.0109,  0.2402,\n",
      "         1.1320,  6.6808], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7738], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.0970,  -8.2464, -10.1490,  -5.6207,  -2.5315,  -8.0201,  -9.7847,\n",
      "         -6.5337,  -5.6419,  -0.0931], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.093\n",
      "activated x value: tensor([-3.0429,  1.1880,  5.1819, -0.6373, -2.6309, -5.4282, -1.8310,  1.5489,\n",
      "         3.6362,  1.9455], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4457], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.4886,  -4.2577,  -0.2638,  -6.0830,  -8.0766, -10.8740,  -7.2768,\n",
      "         -3.8968,  -1.8095,  -3.5002], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 1.3806, -6.5967, -0.9127,  8.7654, -6.9613,  6.4531, -6.4354, -2.2503,\n",
      "         4.9617,  1.2081], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8810], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5004, -15.4778,  -9.7937,  -0.1156, -15.8424,  -2.4279, -15.3165,\n",
      "        -11.1313,  -3.9193,  -7.6730], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.116\n",
      "activated x value: tensor([-0.1836, -2.6521,  2.3424, -2.2182, -0.1359,  1.3111,  7.2194, -6.7034,\n",
      "         1.0844, -0.2053], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2338], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4174,  -9.8858,  -4.8914,  -9.4520,  -7.3697,  -5.9226,  -0.0144,\n",
      "        -13.9371,  -6.1493,  -7.4391], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([-4.5500, -1.9863,  1.6956, -1.3640,  2.2981, -3.5789,  6.5373, -0.4928,\n",
      "         2.6883, -1.1388], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5819], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.1319,  -8.5682,  -4.8863,  -7.9459,  -4.2838, -10.1607,  -0.0446,\n",
      "         -7.0747,  -3.8936,  -7.7207], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-3.3005,  5.1839,  2.6691,  0.5373, -4.3547,  0.0426,  1.1454, -6.5222,\n",
      "         6.6045, -0.7975], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8433], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1438,  -1.6594,  -4.1742,  -6.3060, -11.1980,  -6.8007,  -5.6979,\n",
      "        -13.3655,  -0.2388,  -7.6408], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -1.659\n",
      "activated x value: tensor([-5.2667, -4.5560, -3.4673,  0.5800,  6.1358,  1.6759, -3.4807,  0.5171,\n",
      "         2.2543,  4.8383], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4081], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.6748, -10.9641,  -9.8754,  -5.8281,  -0.2724,  -4.7323,  -9.8888,\n",
      "         -5.8910,  -4.1538,  -1.5699], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.272\n",
      "activated x value: tensor([  0.0211,   2.2948,  11.3844,   9.3183,  -9.2436,   0.6008,   3.1515,\n",
      "        -15.4286,   6.8664,  -8.5349], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5136], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.4925,  -9.2188,  -0.1293,  -2.1953, -20.7572, -10.9128,  -8.3621,\n",
      "        -26.9422,  -4.6472, -20.0485], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.129\n",
      "activated x value: tensor([-3.3136,  3.8773, -0.0146,  1.3578, -1.4421,  0.0226, -0.7332,  0.8756,\n",
      "        -0.5490,  0.5196], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0877], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.4013, -0.2104, -4.1023, -2.7299, -5.5298, -4.0651, -4.8209, -3.2121,\n",
      "        -4.6367, -3.5681], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.210\n",
      "activated x value: tensor([  1.4908, -12.3466,   4.3477,  -8.8350,   8.6774,   3.3212,  10.6461,\n",
      "         -8.6959,   0.3954,   0.4410], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7791], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2883, -23.1258,  -6.4315, -19.6141,  -2.1017,  -7.4579,  -0.1331,\n",
      "        -19.4750, -10.3837, -10.3381], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.133\n",
      "activated x value: tensor([  4.2427, -10.1469,   3.3116,   0.6206,  -0.9824,   2.3237,  -3.9392,\n",
      "          1.4885,   0.6266,   2.4353], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8459], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.6031, -14.9928,  -1.5343,  -4.2253,  -5.8283,  -2.5222,  -8.7851,\n",
      "         -3.3574,  -4.2193,  -2.4105], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -2.411\n",
      "activated x value: tensor([-7.0835,  7.5971,  0.0670,  1.6583, -1.8856, -1.2260, -0.5228,  0.9213,\n",
      "         0.2643,  0.9440], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6040], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4687e+01, -6.8746e-03, -7.5369e+00, -5.9456e+00, -9.4895e+00,\n",
      "        -8.8299e+00, -8.1267e+00, -6.6827e+00, -7.3396e+00, -6.6599e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([ 1.5331, -4.6808,  0.1727, -1.0751, -0.2373,  8.6461, -2.4522, -4.5252,\n",
      "         3.9750, -0.4837], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6568], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.1237e+00, -1.3338e+01, -8.4841e+00, -9.7318e+00, -8.8941e+00,\n",
      "        -1.0653e-02, -1.1109e+01, -1.3182e+01, -4.6818e+00, -9.1405e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-7.8558,  8.6548,  1.1649,  3.1206, -4.2921, -0.9743, -0.0185, -0.8834,\n",
      "         1.4119,  0.0698], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6605], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6516e+01, -5.7049e-03, -7.4956e+00, -5.5399e+00, -1.2953e+01,\n",
      "        -9.6348e+00, -8.6790e+00, -9.5439e+00, -7.2486e+00, -8.5907e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-1.3463, -4.8858, -4.3520,  2.9084,  1.2671, -0.0245, -3.7393,  8.4819,\n",
      "        -0.3575,  1.0666], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4875], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8337e+00, -1.3373e+01, -1.2839e+01, -5.5791e+00, -7.2204e+00,\n",
      "        -8.5120e+00, -1.2227e+01, -5.5294e-03, -8.8450e+00, -7.4209e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 12.6639, -14.7341,   0.9967,  -1.5616,  -1.5654,   5.6579,  -1.6095,\n",
      "         -0.6116,   1.7468,   0.1155], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.6649], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4032e-04, -2.7399e+01, -1.1668e+01, -1.4227e+01, -1.4230e+01,\n",
      "        -7.0070e+00, -1.4274e+01, -1.3277e+01, -1.0918e+01, -1.2549e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-8.0215,  8.1142,  0.6271,  3.0922, -3.8097, -1.8316, -2.4852,  1.7003,\n",
      "         1.5771,  2.3463], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1275], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6149e+01, -1.3355e-02, -7.5004e+00, -5.0354e+00, -1.1937e+01,\n",
      "        -9.9591e+00, -1.0613e+01, -6.4272e+00, -6.5504e+00, -5.7813e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([ 0.5168, -3.4896,  1.0862,  3.4694,  1.1885,  2.3486, -0.9396, -6.1163,\n",
      "         1.5516,  0.8672], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0610], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.5442,  -7.5506,  -2.9748,  -0.5916,  -2.8725,  -1.7124,  -5.0006,\n",
      "        -10.1773,  -2.5094,  -3.1938], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.592\n",
      "activated x value: tensor([-4.6858,  6.0655,  1.3149,  1.1570, -2.9896, -0.2811, -0.6105, -0.1128,\n",
      "         0.4931,  0.0812], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0927], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7785,  -0.0272,  -4.7778,  -4.9357,  -9.0823,  -6.3738,  -6.7032,\n",
      "         -6.2054,  -5.5996,  -6.0114], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.027\n",
      "activated x value: tensor([ 0.4278, -5.7904,  2.0042,  0.7859, -0.3928,  2.3111, -2.2697, -4.6308,\n",
      "         5.3181,  1.6478], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4433], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.0155, -11.2337,  -3.4391,  -4.6574,  -5.8361,  -3.1322,  -7.7130,\n",
      "        -10.0741,  -0.1253,  -3.7955], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.125\n",
      "activated x value: tensor([-1.0119, -4.3851,  2.5860, -2.2896,  1.2564, -1.9032, 12.7706, -9.0957,\n",
      "         2.7101, -0.9173], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.7707], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3783e+01, -1.7156e+01, -1.0185e+01, -1.5060e+01, -1.1514e+01,\n",
      "        -1.4674e+01, -9.3460e-05, -2.1866e+01, -1.0061e+01, -1.3688e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-6.7257, -5.7889, -3.7956, -1.6820, 12.4057, -0.5753, -0.0689,  0.3649,\n",
      "        -1.2821,  8.0184], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4181], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9144e+01, -1.8207e+01, -1.6214e+01, -1.4100e+01, -1.2370e-02,\n",
      "        -1.2993e+01, -1.2487e+01, -1.2053e+01, -1.3700e+01, -4.3997e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-7.2096, -1.6871, -0.5876,  0.6104,  8.0587, -0.7642,  0.7850, -1.3816,\n",
      "        -0.5854,  3.4742], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0707], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5280e+01, -9.7578e+00, -8.6583e+00, -7.4604e+00, -1.2050e-02,\n",
      "        -8.8349e+00, -7.2857e+00, -9.4523e+00, -8.6561e+00, -4.5965e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-7.0588, -0.2017, -1.4212, -1.3673,  3.7792, -3.5603, -2.4950,  3.3648,\n",
      "         1.8291,  6.9010], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9788], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.0376,  -7.1805,  -8.3999,  -8.3461,  -3.1996, -10.5391,  -9.4738,\n",
      "         -3.6140,  -5.1497,  -0.0778], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.078\n",
      "activated x value: tensor([-3.8890, -2.8158, -7.4966, -1.8361,  7.2367,  2.6803, -2.0744, -1.0104,\n",
      "        -0.0198,  9.0355], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1903], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.0793, -12.0061, -16.6869, -11.0264,  -1.9536,  -6.5100, -11.2647,\n",
      "        -10.2007,  -9.2101,  -0.1548], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.155\n",
      "activated x value: tensor([ 0.4584, -2.8878, -2.2987,  8.1700, -5.0443,  4.2455, -0.4101, -4.1243,\n",
      "         0.6710,  0.8123], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1914], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.7330, -11.0792, -10.4900,  -0.0214, -13.2357,  -3.9459,  -8.6015,\n",
      "        -12.3157,  -7.5204,  -7.3791], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.021\n",
      "activated x value: tensor([-10.4117,   4.2828,   1.5640,   2.9182,  -1.9157,  -2.1652,  -0.4897,\n",
      "          1.3277,   2.0549,   3.0661], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8648], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.2765,  -0.5820,  -3.3007,  -1.9465,  -6.7804,  -7.0300,  -5.3544,\n",
      "         -3.5371,  -2.8099,  -1.7986], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -3.537\n",
      "activated x value: tensor([-5.4603,  6.4041,  1.3171,  1.3514, -1.9751, -0.8294, -1.3280,  1.0468,\n",
      "         0.3672, -0.2768], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4261], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8865,  -0.0221,  -5.1090,  -5.0747,  -8.4012,  -7.2556,  -7.7542,\n",
      "         -5.3794,  -6.0589,  -6.7030], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.022\n",
      "activated x value: tensor([-2.5287, -6.9465, -0.1829, -0.6098,  1.8074, -0.2258, -2.4534,  4.2379,\n",
      "        -0.1621,  6.0468], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2172], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.7459, -13.1637,  -6.4001,  -6.8271,  -4.4099,  -6.4430,  -8.6706,\n",
      "         -1.9793,  -6.3793,  -0.1704], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.170\n",
      "activated x value: tensor([  7.6273, -11.3097,   2.2558,   0.1392,  -1.7180,   2.8467,  -0.9186,\n",
      "         -0.9269,   1.2006,   0.4975], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6436], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6357e-02, -1.8953e+01, -5.3878e+00, -7.5044e+00, -9.3616e+00,\n",
      "        -4.7970e+00, -8.5622e+00, -8.5705e+00, -6.4430e+00, -7.1461e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([  9.0553, -12.3968,   2.6646,  -1.3971,  -3.0592,  -0.4581,  -2.3721,\n",
      "          3.0271,   1.5382,   4.3651], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0691], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3838e-02, -2.1466e+01, -6.4046e+00, -1.0466e+01, -1.2128e+01,\n",
      "        -9.5272e+00, -1.1441e+01, -6.0420e+00, -7.5309e+00, -4.7041e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([-6.3838,  7.6099,  3.6502, -0.3761, -0.6048, -3.1784, -1.4296, -0.1908,\n",
      "         3.3366, -2.7130], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6436], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.0273,  -0.0336,  -3.9934,  -8.0196,  -8.2484, -10.8220,  -9.0732,\n",
      "         -7.8343,  -4.3069, -10.3566], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.034\n",
      "activated x value: tensor([ 2.7586, -4.8831,  0.3066, 11.7176, -7.8816,  6.2110, -7.6319,  0.4769,\n",
      "         0.5910, -2.3110], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7219], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9632e+00, -1.6605e+01, -1.1415e+01, -4.2191e-03, -1.9603e+01,\n",
      "        -5.5108e+00, -1.9354e+01, -1.1245e+01, -1.1131e+01, -1.4033e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-0.2167, -0.2340,  1.6651,  6.5803, -2.3020,  1.2592,  1.9098, -6.3904,\n",
      "        -0.1558, -2.1640], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6053], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.8220,  -6.8393,  -4.9401,  -0.0250,  -8.9072,  -5.3460,  -4.6954,\n",
      "        -12.9957,  -6.7611,  -8.7692], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([ 0.0173, -3.5734, -1.7027, -3.3877, -0.0494,  1.3421, -0.9569,  3.2594,\n",
      "         0.0719,  4.9498], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1629], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.1456, -8.7363, -6.8656, -8.5506, -5.2123, -3.8208, -6.1199, -1.9035,\n",
      "        -5.0910, -0.2132], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -3.821\n",
      "activated x value: tensor([-0.1282, -5.3137,  2.1331,  3.1378, -1.7611,  5.6851, -2.0080, -8.8748,\n",
      "         9.3371, -2.8024], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.3655], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4937, -14.6793,  -7.2324,  -6.2277, -11.1266,  -3.6804, -11.3735,\n",
      "        -18.2403,  -0.0284, -12.1679], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([ 0.2383, -6.2014,  0.3114,  2.4810, -0.7958, 11.1332, -4.2574, -7.2898,\n",
      "         6.4379, -2.6781], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1425], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0904e+01, -1.7344e+01, -1.0831e+01, -8.6615e+00, -1.1938e+01,\n",
      "        -9.3155e-03, -1.5400e+01, -1.8432e+01, -4.7046e+00, -1.3821e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-1.5228, -5.1248,  0.1423, -4.5822,  7.3910, -2.7732,  1.7149,  1.7106,\n",
      "         0.8495,  1.6699], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4034], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9262e+00, -1.2528e+01, -7.2611e+00, -1.1986e+01, -1.2375e-02,\n",
      "        -1.0177e+01, -5.6885e+00, -5.6928e+00, -6.5539e+00, -5.7335e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([  9.3030, -12.7486,   3.8724,   0.7089,  -6.7522,   4.5159,  -1.9841,\n",
      "         -3.0889,   4.2867,   2.0377], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.3230], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0045e-02, -2.2072e+01, -5.4506e+00, -8.6142e+00, -1.6075e+01,\n",
      "        -4.8071e+00, -1.1307e+01, -1.2412e+01, -5.0363e+00, -7.2854e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-9.9379,  2.4308,  1.5794,  3.5106, -3.6541, -1.9724, -4.0868,  7.3864,\n",
      "         1.1706,  3.2643], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4344], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.3723,  -5.0036,  -5.8550,  -3.9237, -11.0884,  -9.4068, -11.5212,\n",
      "         -0.0479,  -6.2637,  -4.1701], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.048\n",
      "activated x value: tensor([  0.3984,  -4.0556,   1.9265,   2.1743,  -3.3553,   4.8840,   8.8755,\n",
      "        -10.8762,   1.1824,  -1.1675], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8966], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.4982, -12.9522,  -6.9702,  -6.7223, -12.2519,  -4.0126,  -0.0212,\n",
      "        -19.7728,  -7.7142, -10.0641], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.021\n",
      "activated x value: tensor([-9.2177,  9.1122,  0.6374,  2.1932, -3.9070,  0.2215,  0.8726, -2.0425,\n",
      "         2.7913, -0.5081], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1156], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8333e+01, -3.4742e-03, -8.4783e+00, -6.9224e+00, -1.3023e+01,\n",
      "        -8.8942e+00, -8.2430e+00, -1.1158e+01, -6.3243e+00, -9.6238e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-5.3276, -0.2738, -0.2921,  0.1149,  5.3735, -3.3103,  1.4544, -1.8545,\n",
      "         1.1417,  2.9621], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5020], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8296,  -5.7758,  -5.7941,  -5.3871,  -0.1286,  -8.8124,  -4.0476,\n",
      "         -7.3565,  -4.3603,  -2.5399], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.129\n",
      "activated x value: tensor([-3.5250, -6.4172,  2.9264,  6.3205, -3.5676,  1.2835, -3.0509,  5.7560,\n",
      "        -2.2510,  3.9287], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8514], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3764, -13.2687,  -3.9250,  -0.5309, -10.4191,  -5.5679,  -9.9023,\n",
      "         -1.0955,  -9.1025,  -2.9228], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.095\n",
      "activated x value: tensor([-5.4755,  5.7871,  0.8957, -0.2720, -0.6438, -0.7990, -1.2529,  2.3497,\n",
      "         0.5893, -0.7815], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8386], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3141,  -0.0515,  -4.9429,  -6.1105,  -6.4824,  -6.6376,  -7.0914,\n",
      "         -3.4889,  -5.2493,  -6.6201], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.051\n",
      "activated x value: tensor([-0.7011, -7.8170, -2.1957, -1.4392,  0.8285,  2.8775, -4.9299,  5.0964,\n",
      "         1.4174,  6.4020], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6740], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.3750, -14.4909,  -8.8696,  -8.1131,  -5.8455,  -3.7965, -11.6039,\n",
      "         -1.5776,  -5.2565,  -0.2720], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.578\n",
      "activated x value: tensor([-3.0752, -4.0316,  3.1920, 13.4645, -3.1469,  2.2088, -6.1999, -3.3847,\n",
      "         3.0873, -2.4211], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.4646], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6540e+01, -1.7496e+01, -1.0273e+01, -7.9155e-05, -1.6611e+01,\n",
      "        -1.1256e+01, -1.9664e+01, -1.6849e+01, -1.0377e+01, -1.5886e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([  1.2257,  -2.6030,  15.9466,   9.5870, -11.2175,   1.0244,   0.1931,\n",
      "        -15.7183,   9.2883,  -8.1380], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.9496], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4724e+01, -1.8553e+01, -3.0098e-03, -6.3626e+00, -2.7167e+01,\n",
      "        -1.4925e+01, -1.5756e+01, -3.1668e+01, -6.6614e+00, -2.4088e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 1.7670, -3.6517,  8.4106,  8.3596, -6.5076, -1.5607, -1.0863,  0.5983,\n",
      "        -2.5263, -2.9728], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0795], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.3126, -12.7312,  -0.6690,  -0.7199, -15.5871, -10.6403, -10.1658,\n",
      "         -8.4812, -11.6058, -12.0523], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.669\n",
      "activated x value: tensor([-1.8108,  0.2883, -0.2128,  1.6394, -1.2765,  1.6683,  2.3802, -3.9358,\n",
      "         0.9360,  0.0499], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.3130], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.1238, -3.0246, -3.5258, -1.6736, -4.5895, -1.6447, -0.9328, -7.2488,\n",
      "        -2.3770, -3.2631], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.933\n",
      "activated x value: tensor([-8.0869,  1.2359, -1.7120,  2.3068, -0.7576,  4.2437, -3.7917, -1.8049,\n",
      "         7.1869,  1.9187], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2534], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.3403,  -6.0174,  -8.9653,  -4.9466,  -8.0110,  -3.0097, -11.0450,\n",
      "         -9.0582,  -0.0664,  -5.3347], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.066\n",
      "activated x value: tensor([-1.8681, -4.6867,  6.0556, -3.7439,  0.8218,  3.0952,  9.4271, -7.6144,\n",
      "         1.5078, -3.5858], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4632], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3313, -14.1499,  -3.4075, -13.2071,  -8.6414,  -6.3679,  -0.0360,\n",
      "        -17.0776,  -7.9554, -13.0489], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.036\n",
      "activated x value: tensor([ -0.5633,  -6.8565,   5.5871,  -4.8800,   3.4816,  -0.8109,  12.9218,\n",
      "        -11.4264,   2.2037,   1.3333], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.9225], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3486e+01, -1.9779e+01, -7.3355e+00, -1.7803e+01, -9.4409e+00,\n",
      "        -1.3733e+01, -7.6580e-04, -2.4349e+01, -1.0719e+01, -1.1589e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 0.5735, -6.0154,  3.9311, 11.1240, -3.5101,  2.0440, -4.1734, -7.8881,\n",
      "         3.1984,  1.0287], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1253], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0552e+01, -1.7141e+01, -7.1942e+00, -1.2941e-03, -1.4635e+01,\n",
      "        -9.0813e+00, -1.5299e+01, -1.9013e+01, -7.9269e+00, -1.0097e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 10.5936, -13.2161,   1.0525,  -4.0600,  -3.5662,   5.0535,  -2.4972,\n",
      "         -2.1383,   6.1789,   2.8616], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6100], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6405e-02, -2.3826e+01, -9.5575e+00, -1.4670e+01, -1.4176e+01,\n",
      "        -5.5565e+00, -1.3107e+01, -1.2748e+01, -4.4312e+00, -7.7484e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-2.7969,  1.5674, 11.5068,  2.5757, -6.1451, -0.8775,  4.7455, -7.8258,\n",
      "         1.8860, -4.4781], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5082], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4305e+01, -9.9409e+00, -1.4086e-03, -8.9325e+00, -1.7653e+01,\n",
      "        -1.2386e+01, -6.7627e+00, -1.9334e+01, -9.6222e+00, -1.5986e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -9.941\n",
      "activated x value: tensor([ -2.1114,  -3.1847,   2.2221,  -2.9887,   1.2144,   3.4503,  11.6017,\n",
      "        -10.4319,   3.2331,  -2.2476], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.6023], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3714e+01, -1.4787e+01, -9.3803e+00, -1.4591e+01, -1.0388e+01,\n",
      "        -8.1520e+00, -6.3801e-04, -2.2034e+01, -8.3692e+00, -1.3850e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-1.6332, -1.7609, -1.0209,  6.0459, -1.0509,  0.3198, -3.7079, -3.0916,\n",
      "         1.2079,  4.1538], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1983], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8315, -7.9592, -7.2192, -0.1524, -7.2492, -5.8785, -9.9063, -9.2900,\n",
      "        -4.9904, -2.0445], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.152\n",
      "activated x value: tensor([-4.5333, -7.6503, -1.8505, -0.3812,  4.5484,  1.0363, -1.5524,  1.5015,\n",
      "         1.7450,  7.4569], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5177], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.0510, -15.1680,  -9.3682,  -7.8989,  -2.9694,  -6.4814,  -9.0701,\n",
      "         -6.0162,  -5.7728,  -0.0608], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.061\n",
      "activated x value: tensor([ 16.5640, -12.4667,   5.4568,  -4.0614, -11.6115,   2.7517,   2.3079,\n",
      "         -1.8813,   4.0096,   0.5526], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([16.5640], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0981e-05, -2.9031e+01, -1.1107e+01, -2.0625e+01, -2.8175e+01,\n",
      "        -1.3812e+01, -1.4256e+01, -1.8445e+01, -1.2554e+01, -1.6011e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-8.3227, -3.5882,  7.1400,  4.1565, -3.1214, -1.9645, -1.7792,  5.7180,\n",
      "        -0.2826,  1.1831], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3988], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.7215, -10.9869,  -0.2588,  -3.2423, -10.5201,  -9.3633,  -9.1780,\n",
      "         -1.6808,  -7.6814,  -6.2156], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-2.0425, -1.2469,  1.2491,  7.7728, -3.0541,  2.6525,  1.4244, -6.9758,\n",
      "         1.2716, -1.9328], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7837], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8263e+00, -9.0307e+00, -6.5346e+00, -1.0891e-02, -1.0838e+01,\n",
      "        -5.1312e+00, -6.3593e+00, -1.4760e+01, -6.5121e+00, -9.7165e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-3.9185, -4.9721,  3.3921,  4.6218, -4.3829,  0.6150, -4.1365, -3.4072,\n",
      "         8.7200,  3.0423], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7449], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.6634, -13.7171,  -5.3528,  -4.1231, -13.1278,  -8.1300, -12.8814,\n",
      "        -12.1521,  -0.0249,  -5.7027], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([ 2.3809, -3.5087,  2.2369, -0.6598, -1.1345,  5.3967, -1.6598, -4.2585,\n",
      "         1.9323,  0.8083], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5258], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.1449, -9.0345, -3.2889, -6.1856, -6.6603, -0.1291, -7.1856, -9.7843,\n",
      "        -3.5935, -4.7175], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.129\n",
      "activated x value: tensor([-5.7795,  7.6204,  0.2948,  2.0000, -4.3135,  0.7435, -0.7123, -1.0689,\n",
      "         1.7238,  0.0699], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6294], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3409e+01, -8.9645e-03, -7.3345e+00, -5.6294e+00, -1.1943e+01,\n",
      "        -6.8859e+00, -8.3416e+00, -8.6982e+00, -5.9055e+00, -7.5595e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-1.8549, -4.5184,  2.9159, -2.4699,  0.4167,  1.7491, -0.5484, -4.8107,\n",
      "         7.3970,  2.3797], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4197], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2746, -11.9381,  -4.5038,  -9.8896,  -7.0030,  -5.6706,  -7.9681,\n",
      "        -12.2304,  -0.0227,  -5.0400], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-7.5065,  8.4453,  1.1025,  2.6301, -4.2856,  0.9110,  0.9581, -4.4060,\n",
      "         3.8625, -1.9144], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4602], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5967e+01, -1.4875e-02, -7.3577e+00, -5.8301e+00, -1.2746e+01,\n",
      "        -7.5492e+00, -7.5021e+00, -1.2866e+01, -4.5977e+00, -1.0375e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([ 0.3816, -7.3414, -3.7239,  4.2330,  2.4904,  5.3794, -2.8833, -2.1091,\n",
      "         2.3730,  0.4931], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7428], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.3612, -13.0842,  -9.4667,  -1.5097,  -3.2523,  -0.3633,  -8.6260,\n",
      "         -7.8519,  -3.3697,  -5.2497], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.363\n",
      "activated x value: tensor([-5.0083,  7.9895, 11.1372,  4.4128, -9.2961, -3.4041,  3.4885, -8.1350,\n",
      "         4.7358, -5.7457], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1825], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.1908,  -3.1930,  -0.0452,  -6.7697, -20.4786, -14.5866,  -7.6940,\n",
      "        -19.3175,  -6.4467, -16.9282], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-5.6669,  7.3888,  1.4497,  1.3840, -4.8497,  0.5483, -0.1699, -1.3804,\n",
      "         1.5405,  0.1579], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3992], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3066e+01, -1.0409e-02, -5.9495e+00, -6.0152e+00, -1.2249e+01,\n",
      "        -6.8510e+00, -7.5692e+00, -8.7796e+00, -5.8587e+00, -7.2413e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([ 3.1078, -0.6486,  0.1577,  0.9281, -2.4839,  7.7127, -5.8873, -1.8343,\n",
      "         2.9293, -3.6903], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7328], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.6250,  -8.3815,  -7.5751,  -6.8047, -10.2168,  -0.0202, -13.6201,\n",
      "         -9.5671,  -4.8035, -11.4232], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-2.1562, -1.5576,  3.4186, -2.6605,  0.2185,  0.0394,  8.8549, -4.3211,\n",
      "        -0.6712, -0.9164], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8598], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1016e+01, -1.0417e+01, -5.4411e+00, -1.1520e+01, -8.6413e+00,\n",
      "        -8.8204e+00, -4.8580e-03, -1.3181e+01, -9.5310e+00, -9.7762e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([  1.0896, -12.7645,  12.5628,   6.5041,  -0.1001,   1.6525,  -1.3813,\n",
      "         -7.1181,   1.8065,  -3.5845], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.5652], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1476e+01, -2.5330e+01, -2.3890e-03, -6.0611e+00, -1.2665e+01,\n",
      "        -1.0913e+01, -1.3947e+01, -1.9683e+01, -1.0759e+01, -1.6150e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-7.4043, -4.6454,  0.7703,  0.7523,  2.6295, -4.8174, -5.5540, 11.7795,\n",
      "         2.3914,  3.8807], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7801], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9184e+01, -1.6425e+01, -1.1010e+01, -1.1028e+01, -9.1506e+00,\n",
      "        -1.6597e+01, -1.7334e+01, -5.9414e-04, -9.3887e+00, -7.8994e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-6.9290, -6.8721, -1.6480, -1.0599,  7.2971, -0.2406,  2.0111, -1.1909,\n",
      "         2.3403,  6.1397], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5804], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.5094, -14.4526,  -9.2285,  -8.6403,  -0.2833,  -7.8210,  -5.5693,\n",
      "         -8.7713,  -5.2402,  -1.4407], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.283\n",
      "activated x value: tensor([  1.9232,   2.7565,   7.7317,   5.5165,  -8.7086,   1.5395,   4.7481,\n",
      "        -12.7494,   4.9073,  -6.5990], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9395], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.0163,  -5.1830,  -0.2079,  -2.4230, -16.6481,  -6.4000,  -3.1915,\n",
      "        -20.6889,  -3.0322, -14.5385], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.208\n",
      "activated x value: tensor([-0.9036, -8.7334,  1.8234,  6.0079, -3.7026, -1.2026, -8.2810, 12.3408,\n",
      "        -0.6523,  3.0468], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.3427], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3246e+01, -2.1076e+01, -1.0519e+01, -6.3348e+00, -1.6045e+01,\n",
      "        -1.3545e+01, -2.0624e+01, -1.8997e-03, -1.2995e+01, -9.2958e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-2.2156, -6.5940, -0.0878, -3.5322,  3.4135, -2.9278, -1.9446,  5.4891,\n",
      "         1.4309,  6.9680], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2004], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4160, -13.7944,  -7.2882, -10.7326,  -3.7869, -10.1281,  -9.1450,\n",
      "         -1.7113,  -5.7695,  -0.2324], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.232\n",
      "activated x value: tensor([ 12.3199, -11.1628,   3.8568,  -1.4507,  -6.8793,   7.9308,   6.7750,\n",
      "        -15.6667,   9.6961,  -4.5164], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4052], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0853, -23.5680,  -8.5484, -13.8560, -19.2845,  -4.4744,  -5.6302,\n",
      "        -28.0719,  -2.7091, -16.9216], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.085\n",
      "activated x value: tensor([14.7981, -8.7115,  0.8496, -3.1928, -8.0902, 11.8624,  7.3242, -5.6578,\n",
      "         0.1072, -7.2943], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.8504], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0523, -23.5620, -14.0008, -18.0432, -22.9406,  -2.9880,  -7.5262,\n",
      "        -20.5082, -14.7432, -22.1447], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.052\n",
      "activated x value: tensor([-2.9243, -5.2873,  3.6360,  0.2290,  1.9881,  2.5494,  0.9520, -5.1112,\n",
      "         1.1846,  2.6023], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3659], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.2901, -9.6532, -0.7299, -4.1368, -2.3778, -1.8165, -3.4138, -9.4771,\n",
      "        -3.1813, -1.7635], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.816\n",
      "activated x value: tensor([ 0.6698, -6.1846, -3.1743, -1.6592,  1.5129,  1.8341, -2.6909,  6.0488,\n",
      "         0.3584,  3.6529], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1669], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.4971, -12.3514,  -9.3412,  -7.8261,  -4.6540,  -4.3327,  -8.8577,\n",
      "         -0.1180,  -5.8085,  -2.5140], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-5.8047, -1.9976, -0.4765, -1.7105,  3.8417,  1.6320, -1.0030,  0.0128,\n",
      "         2.1277,  2.9273], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3958], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2006,  -6.3934,  -4.8723,  -6.1063,  -0.5541,  -2.7638,  -5.3989,\n",
      "         -4.3830,  -2.2681,  -1.4685], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.554\n",
      "activated x value: tensor([-4.3734,  4.9851,  2.3902,  0.3366, -0.5783, -1.0902, -1.8936,  1.2184,\n",
      "         0.8232, -1.4280], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1089], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4823, -0.1238, -2.7188, -4.7723, -5.6872, -6.1991, -7.0026, -3.8906,\n",
      "        -4.2857, -6.5369], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.124\n",
      "activated x value: tensor([-1.7060, -4.6948, -2.1714,  0.3495,  1.3338,  0.8268, -3.5217,  5.2621,\n",
      "        -0.6044,  5.3006], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9958], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.7018, -10.6906,  -8.1672,  -5.6463,  -4.6620,  -5.1689,  -9.5175,\n",
      "         -0.7337,  -6.6001,  -0.6951], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.734\n",
      "activated x value: tensor([-0.5928, -2.2202,  1.8618, -2.1529,  1.0190,  0.0286,  8.7648, -5.4851,\n",
      "         0.1300, -0.7635], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7668], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.3596e+00, -1.0987e+01, -6.9050e+00, -1.0920e+01, -7.7478e+00,\n",
      "        -8.7382e+00, -1.9684e-03, -1.4252e+01, -8.6368e+00, -9.5303e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-5.5499,  8.3436,  2.7526,  1.7065, -4.4322, -1.5885,  0.1181, -1.8890,\n",
      "         1.9985, -0.4786], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3509], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3901e+01, -7.2746e-03, -5.5983e+00, -6.6443e+00, -1.2783e+01,\n",
      "        -9.9394e+00, -8.2327e+00, -1.0240e+01, -6.3524e+00, -8.8294e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-0.1986, -5.1307, -0.4031,  4.1815, -4.4458,  6.4770,  4.9890, -4.5760,\n",
      "         2.5457, -4.0483], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7760], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9746, -11.9066,  -7.1791,  -2.5945, -11.2218,  -0.2990,  -1.7870,\n",
      "        -11.3520,  -4.2303, -10.8243], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.299\n",
      "activated x value: tensor([-3.5283, -2.2193, -4.1943, -1.5973,  0.0391,  7.4903, -4.4121, -0.6148,\n",
      "         6.7119,  2.1050], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8720], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.4003, -10.0913, -12.0663,  -9.4693,  -7.8329,  -0.3817, -12.2841,\n",
      "         -8.4868,  -1.1601,  -5.7669], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.160\n",
      "activated x value: tensor([-6.5850,  7.2651,  1.1321,  1.1909, -2.5263, -1.0743, -0.3930,  0.4196,\n",
      "         0.9884,  0.2355], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2741], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3859e+01, -9.0275e-03, -6.1420e+00, -6.0833e+00, -9.8004e+00,\n",
      "        -8.3484e+00, -7.6671e+00, -6.8545e+00, -6.2857e+00, -7.0386e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([ 11.1923,  -5.6620,   3.6152,   2.5303, -12.1045,   5.0745,  -2.2411,\n",
      "         -0.5815,   0.1432,  -2.1299], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1952], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.9106e-03, -1.6857e+01, -7.5800e+00, -8.6650e+00, -2.3300e+01,\n",
      "        -6.1208e+00, -1.3436e+01, -1.1777e+01, -1.1052e+01, -1.3325e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-1.0418, -2.4237,  0.1242, -2.4565,  1.5769,  1.9774,  0.8093, -2.0048,\n",
      "         3.2412,  0.7161], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7777], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.8194, -6.2013, -3.6534, -6.2342, -2.2008, -1.8003, -2.9684, -5.7825,\n",
      "        -0.5365, -3.0616], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.536\n",
      "activated x value: tensor([  2.3641,  -4.4556,  13.7851,   6.9152,  -9.2897,  -1.8119,  -1.2242,\n",
      "        -13.1875,   8.7975,  -2.7802], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.7930], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1429e+01, -1.8249e+01, -7.8411e-03, -6.8778e+00, -2.3083e+01,\n",
      "        -1.5605e+01, -1.5017e+01, -2.6980e+01, -4.9954e+00, -1.6573e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([ 0.1904, -3.6569, -5.8175, -3.7633,  3.6365, -1.4136,  7.4345, -2.5656,\n",
      "         2.5786,  4.8710], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5372], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.3469, -11.1941, -13.3547, -11.3005,  -3.9007,  -8.9508,  -0.1027,\n",
      "        -10.1029,  -4.9587,  -2.6662], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -7.347\n",
      "activated x value: tensor([ 2.8328, -3.2925,  3.2888, -2.9421, -1.3883, -1.0867,  7.9518, -6.0403,\n",
      "         1.6013, -1.4591], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9692], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.1364, -11.2617,  -4.6804, -10.9113,  -9.3574,  -9.0558,  -0.0173,\n",
      "        -14.0095,  -6.3678,  -9.4283], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([-4.0415, -5.1287,  3.3158,  2.2048, -0.2000,  2.1477, -1.8386, -6.7288,\n",
      "        10.0630, -1.0725], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0650], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4107e+01, -1.5194e+01, -6.7492e+00, -7.8602e+00, -1.0265e+01,\n",
      "        -7.9173e+00, -1.1904e+01, -1.6794e+01, -1.9808e-03, -1.1137e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 0.8167, -5.9919, -0.5176,  5.2802, -8.1466,  4.3610, -5.8110, -2.6452,\n",
      "         9.1740,  2.7422], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2040], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3873, -15.1959,  -9.7216,  -3.9237, -17.3506,  -4.8430, -15.0149,\n",
      "        -11.8492,  -0.0300,  -6.4618], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.030\n",
      "activated x value: tensor([-2.9727, -5.6791,  1.9251,  1.4368, -2.6956, -0.2700, -7.3934,  9.8718,\n",
      "         0.4298,  5.4760], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8847], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2857e+01, -1.5564e+01, -7.9596e+00, -8.4480e+00, -1.2580e+01,\n",
      "        -1.0155e+01, -1.7278e+01, -1.2941e-02, -9.4550e+00, -4.4087e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-0.8370,  0.9237, -0.6469,  1.6620, -1.7912,  9.1647, -2.8567, -7.8591,\n",
      "         6.0158, -3.6868], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2076], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0446,  -8.2839,  -9.8545,  -7.5456, -10.9988,  -0.0429, -12.0644,\n",
      "        -17.0668,  -3.1918, -12.8945], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([-1.1206e+00,  2.3849e+00, -1.1417e-02,  1.1563e+01, -3.3173e+00,\n",
      "         2.5341e+00, -6.2239e+00, -2.8593e+00,  1.5985e+00, -3.9345e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5633], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2684e+01, -9.1784e+00, -1.1575e+01, -2.8419e-04, -1.4881e+01,\n",
      "        -9.0292e+00, -1.7787e+01, -1.4423e+01, -9.9647e+00, -1.5498e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-5.3898, -2.3600, -4.7234, -0.7585,  3.3833, -0.5709, -4.9074,  1.6189,\n",
      "         4.5459,  9.9103], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9168], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5307e+01, -1.2277e+01, -1.4640e+01, -1.0675e+01, -6.5334e+00,\n",
      "        -1.0488e+01, -1.4824e+01, -8.2979e+00, -5.3708e+00, -6.4306e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([ 11.4966, -11.6442,   1.5391,  -0.4485,  -5.0708,   6.6225,   0.7666,\n",
      "         -2.5496,   1.5673,  -1.5880], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5044], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7391e-03, -2.3149e+01, -9.9653e+00, -1.1953e+01, -1.6575e+01,\n",
      "        -4.8819e+00, -1.0738e+01, -1.4054e+01, -9.9371e+00, -1.3092e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-7.4499,  6.3228, -2.3724,  3.1006, -3.9720,  0.8919, -6.5421,  2.4936,\n",
      "         5.2126,  1.9332], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6651], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.1150,  -0.3422,  -9.0374,  -3.5644, -10.6371,  -5.7732, -13.2071,\n",
      "         -4.1714,  -1.4524,  -4.7319], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.452\n",
      "activated x value: tensor([-7.7482, -3.8400, -4.3466,  2.4266,  3.6293,  1.0026, -6.2036,  2.7748,\n",
      "         3.4568,  7.7545], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7963], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.5445, -11.6363, -12.1430,  -5.3698,  -4.1670,  -6.7938, -13.9999,\n",
      "         -5.0215,  -4.3395,  -0.0418], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([ 0.3092,  0.7856,  1.2965, -1.9928, -2.5978,  8.8249,  1.7942, -7.5815,\n",
      "         3.1067, -4.2687], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8301], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.5209e+00, -8.0446e+00, -7.5336e+00, -1.0823e+01, -1.1428e+01,\n",
      "        -5.2500e-03, -7.0360e+00, -1.6412e+01, -5.7234e+00, -1.3099e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-7.2825,  5.7127, -0.9256,  2.3377, -1.7044,  2.3793, -1.4778, -2.2858,\n",
      "         2.3412, -0.4125], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8166], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.0991,  -0.1038,  -6.7422,  -3.4789,  -7.5210,  -3.4373,  -7.2944,\n",
      "         -8.1024,  -3.4754,  -6.2290], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.104\n",
      "activated x value: tensor([ 0.3370, -6.3923, -0.0860, -6.1508,  7.0418,  0.2328,  1.5313,  1.2734,\n",
      "        -0.9464,  2.1516], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0598], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.7228, -13.4521,  -7.1458, -13.2106,  -0.0180,  -6.8270,  -5.5286,\n",
      "         -5.7864,  -8.0062,  -4.9082], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([-4.3027,  1.3573,  3.1262,  3.3848, -6.2852,  2.7480, -1.6488, -5.2874,\n",
      "         8.4531, -2.2172], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4684], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7711,  -7.1110,  -5.3422,  -5.0836, -14.7536,  -5.7204, -10.1172,\n",
      "        -13.7557,  -0.0153, -10.6855], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-3.8708, -3.5429,  0.9784,  2.9245, -2.2735, -0.7781, -4.0671,  6.4320,\n",
      "        -0.9638,  5.0654], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6873], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5582, -10.2302,  -5.7090,  -3.7629,  -8.9608,  -7.4654, -10.7544,\n",
      "         -0.2553,  -7.6511,  -1.6219], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.255\n",
      "activated x value: tensor([ 0.1572, -2.8192, -3.0653,  2.8696, -0.4847,  5.4000, -3.4966,  2.0546,\n",
      "         0.1366, -0.7357], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5231], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.3658, -8.3423, -8.5883, -2.6535, -6.0078, -0.1230, -9.0196, -3.4685,\n",
      "        -5.3865, -6.2588], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.123\n",
      "activated x value: tensor([-8.0198, -4.7411, -1.6913,  1.2854,  6.5399, -0.3276, -1.3488,  0.5925,\n",
      "         2.2592,  5.0995], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7711], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.7909, -11.5122,  -8.4624,  -5.4858,  -0.2313,  -7.0988,  -8.1200,\n",
      "         -6.1786,  -4.5120,  -1.6716], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.231\n",
      "activated x value: tensor([-2.8357,  1.8019,  2.4423,  4.8094, -5.1996,  4.2272, -2.4210, -4.9728,\n",
      "         4.7997, -2.5600], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8005], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.6362,  -3.9986,  -3.3582,  -0.9911, -11.0000,  -1.5732,  -8.2215,\n",
      "        -10.7733,  -1.0008,  -8.3605], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.001\n",
      "activated x value: tensor([ 1.0486e+01, -1.0943e+01,  1.0910e+00,  8.6397e-01, -3.5527e+00,\n",
      "         2.7632e+00, -2.4173e+00,  9.9077e-03,  1.0670e+00,  1.6384e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.4866], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.4877e-04, -2.1429e+01, -9.3956e+00, -9.6226e+00, -1.4039e+01,\n",
      "        -7.7233e+00, -1.2904e+01, -1.0477e+01, -9.4196e+00, -8.8481e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.4593, -1.5417,  1.3240,  1.7718, -1.9575, -0.9336, -6.4115,  8.0690,\n",
      "        -0.1706,  4.6240], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1038], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.5631,  -9.6455,  -6.7798,  -6.3320, -10.0612,  -9.0374, -14.5153,\n",
      "         -0.0348,  -8.2743,  -3.4798], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.035\n",
      "activated x value: tensor([ 2.7725, -4.0812,  0.5032,  5.5083, -2.8007,  7.3053, -3.4174, -7.3559,\n",
      "         4.5463, -2.9694], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5213], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.7488, -11.6025,  -7.0180,  -2.0130, -10.3220,  -0.2160, -10.9387,\n",
      "        -14.8772,  -2.9750, -10.4907], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -2.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-8.2962, -0.9364,  0.1770,  1.6420,  2.3686,  0.5433, -3.4946,  0.5039,\n",
      "         3.4405,  3.8377], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5897], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.8859,  -5.5261,  -4.4127,  -2.9476,  -2.2211,  -4.0464,  -8.0843,\n",
      "         -4.0857,  -1.1492,  -0.7520], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -2.948\n",
      "activated x value: tensor([-5.0106, -1.6943,  6.2245, -4.4037,  1.7326, -3.1818, 11.6840, -7.5013,\n",
      "         3.3568, -1.4229], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.6886], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6699e+01, -1.3383e+01, -5.4641e+00, -1.6092e+01, -9.9560e+00,\n",
      "        -1.4870e+01, -4.5385e-03, -1.9190e+01, -8.3318e+00, -1.3112e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([11.7080, -9.4803,  1.6861,  0.5647, -4.4402,  6.2712, -0.5564, -5.2431,\n",
      "         3.2410, -2.7356], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7126], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.6177e-03, -2.1193e+01, -1.0026e+01, -1.1148e+01, -1.6153e+01,\n",
      "        -5.4414e+00, -1.2269e+01, -1.6956e+01, -8.4716e+00, -1.4448e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-1.1899, -7.3250,  1.3255, -5.7526,  5.3092, -1.2144,  0.7938,  0.5251,\n",
      "         2.1931,  4.9091], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8719], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0619, -13.1969,  -4.5464, -11.6245,  -0.5628,  -7.0863,  -5.0781,\n",
      "         -5.3468,  -3.6788,  -0.9628], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.963\n",
      "activated x value: tensor([-7.3199, -1.8145,  1.3695,  2.3296,  2.9674,  3.1345, -0.0539, -5.9153,\n",
      "         6.7918, -1.6552], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8548], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.1748,  -8.6693,  -5.4853,  -4.5252,  -3.8875,  -3.7203,  -6.9088,\n",
      "        -12.7701,  -0.0630,  -8.5100], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.063\n",
      "activated x value: tensor([-2.4368, -2.9419, -0.6960, -0.0553,  0.3617,  2.6031,  6.9559, -6.7963,\n",
      "         1.8081,  1.0384], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9798], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4166,  -9.9217,  -7.6758,  -7.0351,  -6.6181,  -4.3768,  -0.0240,\n",
      "        -13.7761,  -5.1717,  -5.9414], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([ 11.1116, -13.3445,   3.5957,  -2.9096,  -3.5414,   8.2771,  -1.3021,\n",
      "         -9.6088,   7.8954,  -0.2496], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2064], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0948, -24.5509,  -7.6106, -14.1159, -14.7478,  -2.9293, -12.5085,\n",
      "        -20.8152,  -3.3110, -11.4560], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.095\n",
      "activated x value: tensor([  2.6384,  -9.0147, -10.7463,   4.1722,  -1.2758,  10.1932,  -3.7739,\n",
      "         -0.8983,   4.0207,   5.2764], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2056], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5672e+00, -1.9220e+01, -2.0952e+01, -6.0333e+00, -1.1481e+01,\n",
      "        -1.2310e-02, -1.3979e+01, -1.1104e+01, -6.1849e+00, -4.9291e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([ 13.8861, -13.0488,   4.9942,   2.3044,  -9.9691,   8.1370,  -4.5149,\n",
      "         -4.0980,   7.3143,  -5.0417], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.8909], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.7207e-03, -2.6940e+01, -8.8967e+00, -1.1586e+01, -2.3860e+01,\n",
      "        -5.7539e+00, -1.8406e+01, -1.7989e+01, -6.5765e+00, -1.8933e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-6.0910, -3.1119,  9.8811,  2.9995, -0.7333, -7.6242,  5.7055, -2.2832,\n",
      "         0.7920,  1.0138], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8976], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5989e+01, -1.3010e+01, -1.6541e-02, -6.8981e+00, -1.0631e+01,\n",
      "        -1.7522e+01, -4.1921e+00, -1.2181e+01, -9.1056e+00, -8.8838e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([  9.4830, -10.7187,   2.2122,  -1.3658,  -3.0769,   3.8506,   1.6225,\n",
      "         -4.2722,   3.4141,  -0.6765], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4900], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.0133e-03, -2.0209e+01, -7.2778e+00, -1.0856e+01, -1.2567e+01,\n",
      "        -5.6394e+00, -7.8675e+00, -1.3762e+01, -6.0759e+00, -1.0166e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-2.8812, -6.1201, -1.3187, -2.0891,  5.1683, -0.8201, -0.4591,  0.7144,\n",
      "         2.7214,  6.0507], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4278], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.3090, -12.5479,  -7.7465,  -8.5168,  -1.2595,  -7.2479,  -6.8869,\n",
      "         -5.7134,  -3.7064,  -0.3771], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.377\n",
      "activated x value: tensor([-3.3927, -3.4895, -3.5005,  1.1999,  3.6071, -0.0991, -5.0186,  1.5039,\n",
      "         1.2173,  8.8200], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8273], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2220e+01, -1.2317e+01, -1.2328e+01, -7.6274e+00, -5.2202e+00,\n",
      "        -8.9264e+00, -1.3846e+01, -7.3234e+00, -7.6100e+00, -7.2222e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([ 5.9958, -8.0282,  0.6910, -0.7096, -1.3388,  3.5222, -0.3705, -1.9842,\n",
      "         0.4058,  1.7987], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1020], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1061, -14.1302,  -5.4110,  -6.8116,  -7.4408,  -2.5798,  -6.4724,\n",
      "         -8.0862,  -5.6962,  -4.3033], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.106\n",
      "activated x value: tensor([ 12.6220, -10.6622,   6.9457,   2.1493, -10.0400,   3.1682,  -1.8500,\n",
      "         -2.4496,   2.9515,  -3.3031], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.6255], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.5906e-03, -2.3288e+01, -5.6798e+00, -1.0476e+01, -2.2666e+01,\n",
      "        -9.4574e+00, -1.4476e+01, -1.5075e+01, -9.6741e+00, -1.5929e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ -3.4619, -10.4914,   0.2331,  -0.6345,   3.8155,  -0.6889,  -3.9906,\n",
      "          5.2351,   0.7518,   8.6153], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6575], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.1194, -19.1489,  -8.4244,  -9.2920,  -4.8420,  -9.3464, -12.6481,\n",
      "         -3.4224,  -7.9057,  -0.0422], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.042\n",
      "activated x value: tensor([ 0.6843, -0.7096,  2.8831, 13.2765, -9.6845,  6.0387, -5.0581, -7.0443,\n",
      "         3.3098, -3.2045], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.2773], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2593e+01, -1.3987e+01, -1.0394e+01, -8.0013e-04, -2.2962e+01,\n",
      "        -7.2386e+00, -1.8335e+01, -2.0322e+01, -9.9675e+00, -1.6482e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-8.3868,  7.9125,  0.1103,  2.2525, -4.4553,  1.2440, -1.0073, -0.9205,\n",
      "         2.8117,  0.4800], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9246], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6311e+01, -1.2056e-02, -7.8142e+00, -5.6721e+00, -1.2380e+01,\n",
      "        -6.6805e+00, -8.9319e+00, -8.8451e+00, -5.1129e+00, -7.4445e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-1.6266, -8.4465, -1.8560, -4.8293,  4.2034, -4.0718, -5.7155,  6.5364,\n",
      "         5.6618,  9.5700], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6403], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2669, -18.0868, -11.4963, -14.4697,  -5.4369, -13.7121, -15.3558,\n",
      "         -3.1039,  -3.9785,  -0.0704], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.070\n",
      "activated x value: tensor([-6.8319, -1.9198, 10.0229, 14.8041, -6.2148, -0.8326, -5.1351, -3.4548,\n",
      "         3.7632, -3.4891], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.8124], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.1644e+01, -1.6732e+01, -4.7895e+00, -8.3675e-03, -2.1027e+01,\n",
      "        -1.5645e+01, -1.9947e+01, -1.8267e+01, -1.1049e+01, -1.8301e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ -4.3773,  -5.6260,  -6.2166,   3.1953,   0.3415,   0.2612, -10.3617,\n",
      "         13.1170,   1.5489,   8.0530], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.1234], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7501e+01, -1.8749e+01, -1.9340e+01, -9.9281e+00, -1.2782e+01,\n",
      "        -1.2862e+01, -2.3485e+01, -6.3639e-03, -1.1575e+01, -5.0704e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-8.2523, -9.4196, -7.3702,  1.1747, 16.2461, -3.1475,  0.4901, -1.9120,\n",
      "         5.0775,  6.4114], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([16.2462], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.4498e+01, -2.5666e+01, -2.3616e+01, -1.5071e+01, -6.8665e-05,\n",
      "        -1.9394e+01, -1.5756e+01, -1.8158e+01, -1.1169e+01, -9.8348e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-5.9088, -1.4350,  7.2804,  5.7548, -3.0463, -1.5384, -7.0554,  1.6325,\n",
      "         5.3685, -0.6110], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5948], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.5037,  -9.0299,  -0.3145,  -1.8400, -10.6412,  -9.1333, -14.6502,\n",
      "         -5.9624,  -2.2263,  -8.2058], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.314\n",
      "activated x value: tensor([-2.2180, -4.4404, -0.3091,  0.5596,  2.7263,  3.6941, -0.3272, -3.6428,\n",
      "         4.8773, -1.0277], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2495], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.4675, -9.6899, -5.5585, -4.6898, -2.5231, -1.5553, -5.5767, -8.8923,\n",
      "        -0.3722, -6.2772], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.372\n",
      "activated x value: tensor([-4.4158, -0.1622, -1.5738,  3.5473, -1.8162,  2.4869, -5.3060,  0.8020,\n",
      "         4.3089,  2.0291], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8841], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.2999,  -5.0463,  -6.4579,  -1.3368,  -6.7004,  -2.3972, -10.1901,\n",
      "         -4.0822,  -0.5753,  -2.8550], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.337\n",
      "activated x value: tensor([ 2.5980, -5.1082,  4.4141,  0.7847, -4.1871, 10.2491,  2.8823, -8.4923,\n",
      "         1.2462, -3.0620], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2533], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.6553e+00, -1.5362e+01, -5.8392e+00, -9.4686e+00, -1.4440e+01,\n",
      "        -4.2248e-03, -7.3710e+00, -1.8746e+01, -9.0071e+00, -1.3315e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 12.8118,  -7.0373,   6.6643,  -1.2243, -11.6254,   0.0142,   2.0690,\n",
      "         -1.3011,   1.8478,  -1.2745], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.8140], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.1801e-03, -1.9851e+01, -6.1497e+00, -1.4038e+01, -2.4439e+01,\n",
      "        -1.2800e+01, -1.0745e+01, -1.4115e+01, -1.0966e+01, -1.4088e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 0.2831, -1.5231, -6.7029, -1.4798,  4.7251,  5.3554, -2.5256, -0.2466,\n",
      "         3.3061, -0.8457], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8717], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.5886,  -7.3948, -12.5746,  -7.3515,  -1.1466,  -0.5162,  -8.3973,\n",
      "         -6.1183,  -2.5655,  -6.7174], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.516\n",
      "activated x value: tensor([ 1.4391, -7.9803,  0.6328,  2.7124, -3.5937, -0.8687, -7.0929, 13.8329,\n",
      "        -0.2483,  2.0142], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.8329], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2394e+01, -2.1813e+01, -1.3200e+01, -1.1120e+01, -1.7427e+01,\n",
      "        -1.4702e+01, -2.0926e+01, -2.9564e-05, -1.4081e+01, -1.1819e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 1.0046, -6.2242,  0.1797,  4.4431, -0.5465,  6.7097,  1.1260, -5.6698,\n",
      "         1.8703, -3.0439], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8238], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8192, -13.0480,  -6.6441,  -2.3807,  -7.3703,  -0.1141,  -5.6978,\n",
      "        -12.4936,  -4.9535,  -9.8677], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.114\n",
      "activated x value: tensor([-1.0879, -3.6405, -1.6645,  6.7965, -1.4540,  6.4225, -2.0078, -8.9610,\n",
      "         5.2569, -0.2116], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4407], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.5286, -11.0812,  -9.1052,  -0.6441,  -8.8947,  -1.0182,  -9.4485,\n",
      "        -16.4017,  -2.1837,  -7.6523], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.018\n",
      "activated x value: tensor([-0.9020, -8.6820,  1.7793, -7.2603, -1.6967,  0.1466,  5.8474, -3.5981,\n",
      "        10.3125,  3.6490], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3254], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1227e+01, -1.9007e+01, -8.5462e+00, -1.7586e+01, -1.2022e+01,\n",
      "        -1.0179e+01, -4.4781e+00, -1.3924e+01, -1.2951e-02, -6.6765e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-6.2322,  6.1387, -2.3740, -0.0734, -5.2533,  2.8737, -2.6771,  1.5604,\n",
      "         3.7088,  2.6032], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2940], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.5262,  -0.1553,  -8.6680,  -6.3674, -11.5473,  -3.4203,  -8.9711,\n",
      "         -4.7336,  -2.5852,  -3.6908], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -4.734\n",
      "activated x value: tensor([-5.0958,  0.7007, 12.1307,  5.4060, -4.3086, -3.8209,  3.7415, -8.0032,\n",
      "         2.6315, -2.4818], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.1322], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7228e+01, -1.1432e+01, -1.5135e-03, -6.7262e+00, -1.6441e+01,\n",
      "        -1.5953e+01, -8.3907e+00, -2.0135e+01, -9.5008e+00, -1.4614e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-1.6603, -6.2563, 10.4975,  3.1408, -2.3792, -2.7893, -0.9777,  2.1329,\n",
      "        -1.5034, -0.4155], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.4984], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2159e+01, -1.6755e+01, -9.1553e-04, -7.3576e+00, -1.2878e+01,\n",
      "        -1.3288e+01, -1.1476e+01, -8.3655e+00, -1.2002e+01, -1.0914e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 1.5301, -9.1424, -2.1362, -3.5516, -1.1005, 10.3035, -2.7552,  2.6938,\n",
      "         4.1800,  0.7254], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3065], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.7763e+00, -1.9449e+01, -1.2443e+01, -1.3858e+01, -1.1407e+01,\n",
      "        -2.9240e-03, -1.3062e+01, -7.6127e+00, -6.1265e+00, -9.5810e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ -1.4599, -10.9649,  -0.5329,  -4.0506,   5.6865,   0.5719,  -0.6797,\n",
      "          3.0974,   3.0375,   3.9835], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9780], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4379, -16.9429,  -6.5110, -10.0286,  -0.2916,  -5.4061,  -6.6577,\n",
      "         -2.8807,  -2.9405,  -1.9946], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.292\n",
      "activated x value: tensor([-2.3103, -5.8460, 10.6697, 18.0224, -5.6766,  0.8534, -7.2489, -8.4164,\n",
      "         3.2269, -4.3433], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([18.0230], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0333e+01, -2.3869e+01, -7.3534e+00, -6.4087e-04, -2.3700e+01,\n",
      "        -1.7170e+01, -2.5272e+01, -2.6439e+01, -1.4796e+01, -2.2366e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-9.1863,  9.2029,  0.1372,  2.7725, -4.6031, -0.7582, -1.4596,  0.6511,\n",
      "         1.8183,  2.2335], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2064], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8393e+01, -3.5467e-03, -9.0692e+00, -6.4339e+00, -1.3810e+01,\n",
      "        -9.9647e+00, -1.0666e+01, -8.5553e+00, -7.3881e+00, -6.9729e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-4.3914,  1.6750,  3.9147,  0.6036, -4.5230,  1.8863,  2.8123, -6.2462,\n",
      "         5.8830, -0.9653], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0864], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.4778,  -4.4113,  -2.1717,  -5.4827, -10.6094,  -4.2001,  -3.2741,\n",
      "        -12.3326,  -0.2034,  -7.0517], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.203\n",
      "activated x value: tensor([-2.6357, -1.5122,  3.5482, -3.9323,  0.0825,  3.1140,  2.5845, -4.5533,\n",
      "         4.7892, -1.6370], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2592], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8949, -6.7714, -1.7110, -9.1915, -5.1767, -2.1452, -2.6747, -9.8125,\n",
      "        -0.4700, -6.8962], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.470\n",
      "activated x value: tensor([-10.0561,   9.0962,   1.5515,   1.5624,  -4.3900,  -1.6967,   0.4152,\n",
      "          0.9492,   1.6839,   1.5595], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0989], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9155e+01, -2.6779e-03, -7.5474e+00, -7.5365e+00, -1.3489e+01,\n",
      "        -1.0796e+01, -8.6837e+00, -8.1497e+00, -7.4150e+00, -7.5395e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([  7.9464, -10.4671,   0.1333,   0.2699,  -6.1663,   0.8006,   0.6822,\n",
      "          2.9614,   2.5389,   3.3907], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9703], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0239, -18.4374,  -7.8370,  -7.7004, -14.1366,  -7.1698,  -7.2881,\n",
      "         -5.0089,  -5.4314,  -4.5796], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.024\n",
      "activated x value: tensor([-7.0484, -0.2371,  6.7954,  1.8260, -1.4098, -1.9157,  1.6907,  0.0674,\n",
      "         0.6046, -0.8101], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8133], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.8618,  -7.0505,  -0.0179,  -4.9873,  -8.2232,  -8.7290,  -5.1226,\n",
      "         -6.7459,  -6.2088,  -7.6234], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.018\n",
      "activated x value: tensor([ 10.5914, -10.7280,   6.0993,   8.5853, -12.0912,   4.3611, -11.1448,\n",
      "          1.5710,   5.7341,  -3.3321], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7360], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1446, -21.4640,  -4.6367,  -2.1507, -22.8273,  -6.3749, -21.8808,\n",
      "         -9.1650,  -5.0019, -14.0681], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.145\n",
      "activated x value: tensor([-4.7070, -1.4289,  2.4034,  0.7780,  0.2223, -1.3274, -0.9091,  5.4908,\n",
      "        -0.8486,  0.4473], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5601], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2670,  -6.9889,  -3.1567,  -4.7820,  -5.3378,  -6.8875,  -6.4692,\n",
      "         -0.0693,  -6.4086,  -5.1128], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.069\n",
      "activated x value: tensor([-1.8159, -5.0242,  5.9336,  0.4925, -6.8300, -1.4173, -1.4184,  5.2483,\n",
      "         2.7310,  1.0343], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3771], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.1930, -11.4013,  -0.4435,  -5.8846, -13.2071,  -7.7944,  -7.7955,\n",
      "         -1.1288,  -3.6461,  -5.3427], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.443\n",
      "activated x value: tensor([ 0.3827, -6.8866, 14.1187,  5.5865, -0.9702,  2.0700,  3.2296, -8.7753,\n",
      "        -0.0463, -8.3484], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.1189], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3736e+01, -2.1005e+01, -2.2316e-04, -8.5324e+00, -1.5089e+01,\n",
      "        -1.2049e+01, -1.0889e+01, -2.2894e+01, -1.4165e+01, -2.2467e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-1.0108, -7.1340, -2.1080, -5.9648, 10.1001,  1.9655,  3.9176, -3.1464,\n",
      "         0.1460,  3.4953], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1038], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1115e+01, -1.7238e+01, -1.2212e+01, -1.6069e+01, -3.7746e-03,\n",
      "        -8.1383e+00, -6.1863e+00, -1.3250e+01, -9.9578e+00, -6.6085e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-0.8494, -5.8666, -1.1557,  3.5713, -0.0102,  6.7413, -3.2960, -3.4412,\n",
      "         2.7169,  1.6920], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8075], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6569, -12.6740,  -7.9631,  -3.2362,  -6.8176,  -0.0662, -10.1035,\n",
      "        -10.2486,  -4.0906,  -5.1154], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.066\n",
      "activated x value: tensor([12.5308, -9.5790,  3.7580, -0.7038, -6.5023,  3.7119,  0.2773, -5.2167,\n",
      "         4.1412, -2.4650], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.5314], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.3692e-04, -2.2110e+01, -8.7734e+00, -1.3235e+01, -1.9034e+01,\n",
      "        -8.8194e+00, -1.2254e+01, -1.7748e+01, -8.3901e+00, -1.4996e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-0.9895, -4.8895, -0.3912, -0.0329,  6.4738,  0.2853,  0.3682, -1.7777,\n",
      "        -0.7946,  2.8459], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5081], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4977, -11.3976,  -6.8993,  -6.5410,  -0.0343,  -6.2228,  -6.1400,\n",
      "         -8.2859,  -7.3027,  -3.6622], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-3.0935, -3.3049,  0.9021,  6.7102, -3.5136,  1.9418, -4.9338, -0.8997,\n",
      "         4.7872,  3.2463], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8838], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.9774, -10.1888,  -5.9818,  -0.1736, -10.3975,  -4.9420, -11.8177,\n",
      "         -7.7835,  -2.0966,  -3.6375], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.174\n",
      "activated x value: tensor([-1.3018, -6.4729,  1.7013, -5.3276,  3.0199, -2.6672, -0.3658,  2.5502,\n",
      "         1.0729,  6.6258], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6809], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9828, -13.1539,  -4.9796, -12.0085,  -3.6611,  -9.3482,  -7.0468,\n",
      "         -4.1307,  -5.6080,  -0.0551], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.055\n",
      "activated x value: tensor([-7.4969,  3.6762, -1.7648,  0.7322,  1.4168, -0.6863, -1.2726,  2.6426,\n",
      "         0.0838,  3.0802], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4255], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.9224,  -0.7493,  -6.1903,  -3.6933,  -3.0087,  -5.1118,  -5.6981,\n",
      "         -1.7829,  -4.3417,  -1.3453], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.345\n",
      "activated x value: tensor([-3.5796,  5.2275,  4.2556,  7.6565, -7.7220,  0.6482, -4.1282, -3.8237,\n",
      "         3.0839, -1.7389], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7812], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3607,  -2.5536,  -3.5255,  -0.1247, -15.5032,  -7.1330, -11.9094,\n",
      "        -11.6049,  -4.6972,  -9.5200], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.125\n",
      "activated x value: tensor([-3.0853e+00, -2.7882e+00, -2.6003e+00,  2.4690e+00,  5.4769e+00,\n",
      "        -2.8526e-03, -1.6388e+00, -2.1979e+00, -1.7783e-01,  5.4724e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1970], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2823, -8.9852, -8.7973, -3.7280, -0.7201, -6.1999, -7.8358, -8.3949,\n",
      "        -6.3748, -0.7246], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.720\n",
      "activated x value: tensor([ 11.2064,  -7.4580,   3.9232,   2.1610, -10.3173,   5.7914,  -1.2308,\n",
      "          0.5952,   0.2892,  -2.9624], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2117], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2872e-03, -1.8670e+01, -7.2885e+00, -9.0508e+00, -2.1529e+01,\n",
      "        -5.4203e+00, -1.2443e+01, -1.0617e+01, -1.0923e+01, -1.4174e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-0.3668, -3.6781, -2.9759,  8.6747, -2.2935,  4.1219, -5.0013, -3.8188,\n",
      "         2.0501,  2.3782], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6884], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.0552, -12.3666, -11.6643,  -0.0138, -10.9819,  -4.5666, -13.6897,\n",
      "        -12.5073,  -6.6384,  -6.3103], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([ -2.3055, -13.1894,  -1.7699,   0.4682,   2.3683,   4.1037,  -4.7389,\n",
      "          0.4340,   3.4589,  10.7001], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7025], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3008e+01, -2.3892e+01, -1.2472e+01, -1.0234e+01, -8.3341e+00,\n",
      "        -6.5988e+00, -1.5441e+01, -1.0268e+01, -7.2436e+00, -2.3966e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 2.7991, -7.1389,  1.1105,  1.0476, -0.5262,  4.8894, -2.9270, -6.5498,\n",
      "         5.6709,  0.9634], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1065], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.3073, -13.2453,  -4.9960,  -5.0589,  -6.6327,  -1.2171,  -9.0334,\n",
      "        -12.6562,  -0.4356,  -5.1431], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.436\n",
      "activated x value: tensor([ -1.5025, -10.4495,   1.5696,   2.5191,   3.2215,  -3.4927,  -4.1491,\n",
      "          4.6920,  -0.9531,   8.0326], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0808], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.5833, -18.5303,  -6.5112,  -5.5617,  -4.8593, -11.5735, -12.2299,\n",
      "         -3.3888,  -9.0339,  -0.0482], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.048\n",
      "activated x value: tensor([-8.9612, -0.3252, -0.3320,  5.5755, -4.2931,  3.7665, -1.9310, -2.0400,\n",
      "         7.0268,  1.7758], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2732], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.2344,  -7.5984,  -7.6052,  -1.6977, -11.5663,  -3.5067,  -9.2042,\n",
      "         -9.3132,  -0.2464,  -5.4974], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.246\n",
      "activated x value: tensor([-0.9179, -3.6553, 10.7308,  3.4394, -8.8873, -2.7611,  0.5665,  1.6266,\n",
      "         0.3053, -1.2461], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7317], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1650e+01, -1.4387e+01, -8.7738e-04, -7.2923e+00, -1.9619e+01,\n",
      "        -1.3493e+01, -1.0165e+01, -9.1051e+00, -1.0426e+01, -1.1978e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 1.7818, -2.2925,  0.3053, -1.7849, -4.1842,  2.9431, -1.1272,  2.4919,\n",
      "        -1.2526,  3.0399], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0969], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.3151, -6.3895, -3.7916, -5.8818, -8.2811, -1.1538, -5.2241, -1.6050,\n",
      "        -5.3496, -1.0570], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.154\n",
      "activated x value: tensor([ 1.2938, -6.6554,  8.2630, -0.4041,  0.2980, -2.2579,  1.3815, -1.8148,\n",
      "         1.1956, -1.8529], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2665], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9726e+00, -1.4922e+01, -3.4428e-03, -8.6706e+00, -7.9685e+00,\n",
      "        -1.0524e+01, -6.8849e+00, -1.0081e+01, -7.0709e+00, -1.0119e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-10.6456,   9.4521,  -0.1786,   3.4889,  -3.7899,  -1.3188,  -0.6113,\n",
      "          0.1128,   2.5977,   1.7427], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4564], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0102e+01, -4.2849e-03, -9.6350e+00, -5.9675e+00, -1.3246e+01,\n",
      "        -1.0775e+01, -1.0068e+01, -9.3436e+00, -6.8586e+00, -7.7136e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-6.6544, -5.4811, -2.6590, -0.4503, 10.0330,  1.8710, -1.1450, -3.5166,\n",
      "         2.2044,  6.0566], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0523], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.7068, -15.5334, -12.7113, -10.5026,  -0.0193,  -8.1814, -11.1973,\n",
      "        -13.5690,  -7.8479,  -3.9958], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-3.3517, -2.6815,  0.1391,  1.2409, -1.3403,  0.6833, -4.6908,  6.8513,\n",
      "        -0.5489,  3.8860], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9091], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.2608,  -9.5907,  -6.7701,  -5.6682,  -8.2495,  -6.2259, -11.6000,\n",
      "         -0.0578,  -7.4580,  -3.0232], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.058\n",
      "activated x value: tensor([  0.0400, -12.4143,  -0.5933,  -5.4514,   4.8769,  -5.7394,  -1.8525,\n",
      "          9.7426,   1.7772,   8.7991], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.0772], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0372, -22.4915, -10.6705, -15.5286,  -5.2003, -15.8165, -11.9297,\n",
      "         -0.3346,  -8.3000,  -1.2781], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.278\n",
      "activated x value: tensor([11.2590, -6.9801,  9.2432,  6.6900, -9.6516,  3.2505,  0.1317, -5.1752,\n",
      "        -0.9191, -7.1105], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.3934], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.1345, -18.3736,  -2.1503,  -4.7035, -21.0451,  -8.1430, -11.2617,\n",
      "        -16.5686, -12.3126, -18.5039], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.134\n",
      "activated x value: tensor([ 8.0468, -8.6244,  3.0182, -2.8846, -3.7484,  4.0123, -1.7725, -1.7647,\n",
      "         4.2944, -0.8550], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0936], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0469, -16.7180,  -5.0755, -10.9783, -11.8421,  -4.0813,  -9.8662,\n",
      "         -9.8583,  -3.7992,  -8.9486], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.047\n",
      "activated x value: tensor([ 2.2363, -5.8682,  3.9693, -1.8211,  1.2203,  5.6611, -3.4935, -3.8938,\n",
      "         2.2461,  0.3372], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8978], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([ -3.6615, -11.7660,  -1.9284,  -7.7189,  -4.6774,  -0.2367,  -9.3913,\n",
      "         -9.7916,  -3.6517,  -5.5606], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.237\n",
      "activated x value: tensor([ -0.4247, -12.3543,   1.4827,   6.4458,  -4.9643,  -2.3523,  -8.7020,\n",
      "         14.5203,   0.1837,   5.4287], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.5207], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4945e+01, -2.6875e+01, -1.3038e+01, -8.0749e+00, -1.9485e+01,\n",
      "        -1.6873e+01, -2.3223e+01, -4.2725e-04, -1.4337e+01, -9.0920e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 3.1191, -1.9511, -5.5924, -0.3362, -0.4608,  8.3843, -5.6910,  2.2231,\n",
      "         2.5098, -2.7938], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3947], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.2756e+00, -1.0346e+01, -1.3987e+01, -8.7309e+00, -8.8555e+00,\n",
      "        -1.0389e-02, -1.4086e+01, -6.1716e+00, -5.8849e+00, -1.1188e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([ 1.5323, -6.4935, 13.8680,  3.1972, -6.8408,  1.9677, -4.0463, -3.5659,\n",
      "         6.7152, -7.8522], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.8688], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2336e+01, -2.0362e+01, -8.1635e-04, -1.0672e+01, -2.0710e+01,\n",
      "        -1.1901e+01, -1.7915e+01, -1.7435e+01, -7.1536e+00, -2.1721e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-9.8296e+00,  3.7835e+00, -2.4701e+00,  4.7007e-03,  1.3155e+00,\n",
      "        -4.1529e-01, -4.2633e+00,  6.8155e+00,  1.6746e+00,  2.9049e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8925], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.7221,  -3.1090,  -9.3626,  -6.8878,  -5.5770,  -7.3078, -11.1559,\n",
      "         -0.0771,  -5.2180,  -3.9876], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.077\n",
      "activated x value: tensor([-2.3573,  0.1844, -1.4291, -0.6943, -2.8832, -0.0419, -5.5843,  4.6213,\n",
      "         4.0827,  4.1738], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4335], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.7908,  -5.2491,  -6.8626,  -6.1277,  -8.3166,  -5.4753, -11.0178,\n",
      "         -0.8122,  -1.3508,  -1.2597], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.812\n",
      "activated x value: tensor([-0.5181, -2.5585, -1.6668, 10.2944, -3.4911,  5.4516, -6.5494, -3.0558,\n",
      "         2.9547, -1.4824], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.3029], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0821e+01, -1.2861e+01, -1.1970e+01, -8.5373e-03, -1.3794e+01,\n",
      "        -4.8513e+00, -1.6852e+01, -1.3359e+01, -7.3482e+00, -1.1785e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-1.6535, -3.1739,  2.0568, -4.5070,  1.3143,  2.3774,  8.2307, -2.6877,\n",
      "        -1.3934, -1.3821], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2368], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8903e+00, -1.1411e+01, -6.1800e+00, -1.2744e+01, -6.9225e+00,\n",
      "        -5.8594e+00, -6.1426e-03, -1.0925e+01, -9.6302e+00, -9.6189e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-7.4112,  1.4474,  2.6450,  0.0098, -0.4914, -4.1066,  0.6200,  7.0033,\n",
      "         0.3888,  0.7029], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0260], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.4372,  -5.5786,  -4.3810,  -7.0162,  -7.5174, -11.1326,  -6.4061,\n",
      "         -0.0228,  -6.6372,  -6.3231], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([ 2.2381, -3.9075,  0.1525,  0.7309, -0.8213,  7.6515, -1.3840, -6.3834,\n",
      "         2.8283, -1.0866], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6659], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.4278, -11.5734,  -7.5133,  -6.9350,  -8.4872,  -0.0144,  -9.0499,\n",
      "        -14.0493,  -4.8376,  -8.7525], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([ 1.5367,  1.4191,  0.7849,  2.1267, -4.2155,  4.0968, -4.6941, -0.4502,\n",
      "         0.7388, -0.4937], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4173], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.8806, -2.9983, -3.6324, -2.2906, -8.6328, -0.3205, -9.1114, -4.8675,\n",
      "        -3.6785, -4.9110], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.321\n",
      "activated x value: tensor([-8.0051, -0.4324, -3.0410,  1.9922,  1.4754,  1.6536, -2.2004,  1.0771,\n",
      "         1.6014,  6.1774], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2292], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.2343,  -6.6617,  -9.2703,  -4.2370,  -4.7539,  -4.5756,  -8.4297,\n",
      "         -5.1522,  -4.6278,  -0.0518], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.052\n",
      "activated x value: tensor([ 1.5745, -4.4780, -2.2516, -2.1987,  3.3173,  0.9823, -2.9554,  4.4102,\n",
      "        -0.7698,  2.7979], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9017], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.3273, -9.3798, -7.1534, -7.1004, -1.5844, -3.9195, -7.8571, -0.4915,\n",
      "        -5.6715, -2.1039], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.492\n",
      "activated x value: tensor([-3.9774,  6.1036,  3.8640, -0.7033,  0.1501, -3.8879,  1.7559, -6.0378,\n",
      "         6.5732, -4.3657], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1052], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.0826,  -1.0016,  -3.2412,  -7.8085,  -6.9551, -10.9931,  -5.3493,\n",
      "        -13.1430,  -0.5320, -11.4709], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -1.002\n",
      "activated x value: tensor([ 1.4290, -7.1601, -4.1853, -2.6323,  4.3049,  2.4384,  0.2514,  0.4394,\n",
      "         0.3459,  4.9223], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4439], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.0149, -12.6040,  -9.6292,  -8.0761,  -1.1390,  -3.0055,  -5.1924,\n",
      "         -5.0045,  -5.0980,  -0.5216], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.139\n",
      "activated x value: tensor([10.7699, -5.5113, -0.9983,  0.7014, -6.2718,  2.7433,  3.2694, -2.7703,\n",
      "         0.5693, -2.3134], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7709], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.6989e-04, -1.6282e+01, -1.1769e+01, -1.0069e+01, -1.7043e+01,\n",
      "        -8.0276e+00, -7.5015e+00, -1.3541e+01, -1.0202e+01, -1.3084e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 12.7902, -14.8257,  -5.6556,  -0.6316,  -1.2306,   7.1311,   1.0759,\n",
      "         -3.2440,   2.6888,   3.2076], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.7938], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.6001e-03, -2.7620e+01, -1.8449e+01, -1.3425e+01, -1.4024e+01,\n",
      "        -5.6627e+00, -1.1718e+01, -1.6038e+01, -1.0105e+01, -9.5862e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -9.586\n",
      "activated x value: tensor([-4.6748, -7.5388, -4.3665, -1.3683,  4.2465,  1.6855, -1.9499,  0.8308,\n",
      "         4.5066,  9.5498], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5618], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4237e+01, -1.7101e+01, -1.3928e+01, -1.0930e+01, -5.3152e+00,\n",
      "        -7.8763e+00, -1.1512e+01, -8.7309e+00, -5.0552e+00, -1.1934e-02],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-6.3056, -4.0898, -2.3792, -0.0366,  8.3345,  0.8757,  0.9531, -3.6285,\n",
      "         1.3189,  3.4757], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3446], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4650e+01, -1.2434e+01, -1.0724e+01, -8.3811e+00, -1.0071e-02,\n",
      "        -7.4689e+00, -7.3914e+00, -1.1973e+01, -7.0257e+00, -4.8688e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 2.5678, -6.6732,  8.3814,  6.6759, -1.9094, -3.1294,  3.3045, -3.5650,\n",
      "        -1.5780, -3.2090], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5562], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.9884, -15.2295,  -0.1748,  -1.8803, -10.4656, -11.6856,  -5.2517,\n",
      "        -12.1212, -10.1342, -11.7652], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.175\n",
      "activated x value: tensor([-5.3390, -2.1868,  0.8293,  7.8840, -0.9495,  3.5449, -4.4591, -2.2520,\n",
      "         3.5661,  0.6162], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9118], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.2508, -10.0986,  -7.0826,  -0.0278,  -8.8614,  -4.3669, -12.3709,\n",
      "        -10.1638,  -4.3458,  -7.2956], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-7.5403,  1.6490, -3.7819,  0.5762,  3.5564,  1.7723, -3.3404,  0.6431,\n",
      "         3.9102,  2.1630], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6865], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.2268,  -3.0375,  -8.4684,  -4.1103,  -1.1301,  -2.9141,  -8.0268,\n",
      "         -4.0434,  -0.7763,  -2.5234], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -1.130\n",
      "activated x value: tensor([ 3.5003, -4.7961, -4.2132, -1.4022,  0.4920,  6.3474,  2.9715, -5.7404,\n",
      "         1.5580,  1.6114], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4542], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -2.9538, -11.2502, -10.6674,  -7.8564,  -5.9621,  -0.1067,  -3.4826,\n",
      "        -12.1945,  -4.8962,  -4.8427], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.107\n",
      "activated x value: tensor([-9.2450,  8.5545,  1.3106,  3.1711, -4.3369, -2.4906, -0.6528,  1.2922,\n",
      "         1.5206,  1.8768], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5628], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7808e+01, -8.2331e-03, -7.2521e+00, -5.3916e+00, -1.2900e+01,\n",
      "        -1.1053e+01, -9.2156e+00, -7.2705e+00, -7.0422e+00, -6.6859e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-1.7540, -2.2998,  2.4707, -0.3306, -0.8178,  1.1155, -0.8830, -3.6462,\n",
      "         5.9436,  0.5835], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9911], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.7451, -8.2908, -3.5204, -6.3217, -6.8089, -4.8755, -6.8741, -9.6373,\n",
      "        -0.0475, -5.4075], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.047\n",
      "activated x value: tensor([-3.9771,  0.6397,  9.2245,  3.6822, -3.6600, -1.3847,  0.6188, -7.4391,\n",
      "         4.4961, -2.6904], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2376], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3215e+01, -8.5979e+00, -1.3078e-02, -5.5554e+00, -1.2898e+01,\n",
      "        -1.0622e+01, -8.6188e+00, -1.6677e+01, -4.7415e+00, -1.1928e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -5.555\n",
      "activated x value: tensor([ -6.0203,  -0.9757,   3.8348,   0.1551,  -1.0644,   2.2003,  10.7235,\n",
      "        -12.8419,   5.3009,  -1.0843], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7291], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6749e+01, -1.1705e+01, -6.8944e+00, -1.0574e+01, -1.1794e+01,\n",
      "        -8.5289e+00, -5.6667e-03, -2.3571e+01, -5.4283e+00, -1.1813e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-7.8891,  7.6004,  1.3985,  2.0776, -3.6325, -2.5579, -0.4578,  1.6029,\n",
      "         2.0721,  0.3675], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6139], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5503e+01, -1.3477e-02, -6.2154e+00, -5.5363e+00, -1.1246e+01,\n",
      "        -1.0172e+01, -8.0718e+00, -6.0110e+00, -5.5418e+00, -7.2464e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([ -0.6855, -10.8247,   2.7409,   4.7768,  -2.8229,  -2.1074,  -6.7140,\n",
      "         10.8968,  -0.9966,   4.2726], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9006], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1586e+01, -2.1725e+01, -8.1597e+00, -6.1238e+00, -1.3723e+01,\n",
      "        -1.3008e+01, -1.7615e+01, -3.8252e-03, -1.1897e+01, -6.6280e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([ 2.5466, -7.7622, 10.5268,  5.8788, -2.0743, -1.1311,  3.2435, -5.8322,\n",
      "        -0.3582, -5.6493], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.5374], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.9908e+00, -1.8300e+01, -1.0585e-02, -4.6586e+00, -1.2612e+01,\n",
      "        -1.1668e+01, -7.2938e+00, -1.6370e+01, -1.0896e+01, -1.6187e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-4.2409, -0.6572,  1.7901,  1.1355, -1.0874,  3.0561,  5.9152, -8.6338,\n",
      "         3.3152, -0.8022], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0634], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.3043,  -6.7205,  -4.2733,  -4.9279,  -7.1507,  -3.0073,  -0.1482,\n",
      "        -14.6971,  -2.7482,  -6.8655], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.148\n",
      "activated x value: tensor([ 0.5815, -3.1263,  1.2932, -3.5249,  0.1608,  2.4025,  7.6115, -3.7657,\n",
      "         0.3867, -0.8738], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6212], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.0397e+00, -1.0747e+01, -6.3280e+00, -1.1146e+01, -7.4604e+00,\n",
      "        -5.2186e+00, -9.6717e-03, -1.1387e+01, -7.2345e+00, -8.4949e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-0.2606, -3.3308,  1.6891,  4.1846, -4.3058,  2.2481, -0.7122, -7.4413,\n",
      "         6.8142,  1.6204], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9054], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1660, -10.2362,  -5.2163,  -2.7208, -11.2112,  -4.6573,  -7.6176,\n",
      "        -14.3467,  -0.0912,  -5.2850], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.091\n",
      "activated x value: tensor([-4.2554,  0.7199,  2.6491,  0.2968, -0.5053,  1.3848,  5.6813, -5.9692,\n",
      "         1.8001, -1.2327], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7740], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0294,  -5.0541,  -3.1249,  -5.4772,  -6.2793,  -4.3892,  -0.0927,\n",
      "        -11.7432,  -3.9739,  -7.0067], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.093\n",
      "activated x value: tensor([-3.0956,  5.5102,  2.5101,  1.0585, -3.2713, -0.1481, -0.6854, -1.8282,\n",
      "         1.9819, -1.6844], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6037], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6993, -0.0935, -3.0936, -4.5453, -8.8750, -5.7518, -6.2891, -7.4319,\n",
      "        -3.6219, -7.2881], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.094\n",
      "activated x value: tensor([-7.2856,  2.3447,  9.0015,  4.2726, -8.3218,  1.7919,  2.5212, -4.4560,\n",
      "         2.6222, -3.7123], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0155], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6301e+01, -6.6708e+00, -1.3997e-02, -4.7429e+00, -1.7337e+01,\n",
      "        -7.2236e+00, -6.4943e+00, -1.3471e+01, -6.3933e+00, -1.2728e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([ 2.8622, -6.0593,  0.4346,  0.0362, -1.8273, 11.5308, -1.4359, -4.5534,\n",
      "         2.3876, -3.2413], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.5311], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6689e+00, -1.7590e+01, -1.1097e+01, -1.1495e+01, -1.3358e+01,\n",
      "        -3.0804e-04, -1.2967e+01, -1.6084e+01, -9.1435e+00, -1.4772e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-7.8357,  0.7145,  2.8708,  8.2935, -2.2712, -0.3387, -4.6170, -0.5598,\n",
      "         1.7542,  0.9265], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3008], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6136e+01, -7.5862e+00, -5.4300e+00, -7.3261e-03, -1.0572e+01,\n",
      "        -8.6394e+00, -1.2918e+01, -8.8606e+00, -6.5466e+00, -7.3743e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-3.3439e+00, -1.2654e+00, -2.7990e+00, -3.0436e-02,  5.9003e+00,\n",
      "         5.3584e-01,  4.0035e-01, -5.4382e-01, -3.1739e-03,  1.6782e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9313], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2751, -7.1966, -8.7302, -5.9617, -0.0310, -5.3954, -5.5309, -6.4751,\n",
      "        -5.9344, -4.2531], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-5.0833, -2.8614, 10.7137,  7.4850, -0.6339, -1.4070,  1.3479, -9.2511,\n",
      "         0.5747, -1.5525], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7527], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.8360, -13.6141,  -0.0390,  -3.2677, -11.3866, -12.1597,  -9.4048,\n",
      "        -20.0038, -10.1780, -12.3052], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.039\n",
      "activated x value: tensor([ 2.1017,  0.9325,  1.2254,  7.6466, -5.8916,  2.6476, -3.8170, -3.2770,\n",
      "         2.1402, -4.2227], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6640], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.5623,  -6.7315,  -6.4386,  -0.0174, -13.5556,  -5.0164, -11.4810,\n",
      "        -10.9410,  -5.5238, -11.8867], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([ -3.0536, -10.9895,   3.9668,   0.5430,   4.0287,  -9.2957,  -3.9044,\n",
      "          8.5688,  -0.1776,   9.0724], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5531], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.6067, -20.5425,  -5.5863,  -9.0100,  -5.5244, -18.8488, -13.4575,\n",
      "         -0.9843,  -9.7307,  -0.4807], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.481\n",
      "activated x value: tensor([ 11.3974, -10.6089,   2.4443,   0.8772,  -6.7644,   3.7184,  -7.2776,\n",
      "          0.5167,   4.9203,   1.2393], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.3996], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.2125e-03, -2.2008e+01, -8.9553e+00, -1.0522e+01, -1.8164e+01,\n",
      "        -7.6812e+00, -1.8677e+01, -1.0883e+01, -6.4793e+00, -1.0160e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-5.4734, -5.1513, -3.4331, -6.6019, 11.2100, -2.4326,  3.2487,  2.5374,\n",
      "         2.0243,  3.9876], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2113], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6685e+01, -1.6363e+01, -1.4644e+01, -1.7813e+01, -1.3533e-03,\n",
      "        -1.3644e+01, -7.9626e+00, -8.6739e+00, -9.1870e+00, -7.2237e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-1.6296,  0.8716,  2.2591,  4.7459, -5.6265,  0.8388,  2.7673, -5.5738,\n",
      "         2.1879,  0.2597], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0481], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6777,  -4.1765,  -2.7889,  -0.3022, -10.6745,  -4.2092,  -2.2808,\n",
      "        -10.6219,  -2.8601,  -4.7883], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.302\n",
      "activated x value: tensor([-2.3298, -0.7306,  2.4476,  1.3671, -0.7380,  0.3535,  2.5319, -9.2770,\n",
      "         7.4976, -1.8801], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5145], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.8443,  -8.2451,  -5.0669,  -6.1474,  -8.2525,  -7.1610,  -4.9826,\n",
      "        -16.7915,  -0.0169,  -9.3946], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([-6.5773, -4.6290, -5.2529,  1.0199,  4.4879,  0.3184, -2.8422,  2.3374,\n",
      "         2.0824,  9.2047], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2159], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5793e+01, -1.3845e+01, -1.4469e+01, -8.1960e+00, -4.7280e+00,\n",
      "        -8.8975e+00, -1.2058e+01, -6.8784e+00, -7.1335e+00, -1.1154e-02],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-5.0294, -6.1553, -1.4396, -1.9119,  4.6959, -3.5199, -1.9313,  5.2064,\n",
      "         1.9057,  8.0791], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1678], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.1972, -14.3230,  -9.6073, -10.0797,  -3.4719, -11.6877, -10.0990,\n",
      "         -2.9614,  -6.2620,  -0.0887], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.089\n",
      "activated x value: tensor([-5.6764, -3.1224,  1.4651,  9.1189, -4.7823,  3.9666, -6.6912,  3.6801,\n",
      "         0.7864,  1.5764], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1302], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4807e+01, -1.2253e+01, -7.6651e+00, -1.1317e-02, -1.3912e+01,\n",
      "        -5.1636e+00, -1.5821e+01, -5.4501e+00, -8.3438e+00, -7.5539e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-5.6593,  0.7074, -3.7547,  1.2529, -0.1869,  0.7237, -2.2145,  4.5802,\n",
      "         0.3444,  4.0827], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1168], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7761,  -4.4094,  -8.8716,  -3.8639,  -5.3038,  -4.3932,  -7.3313,\n",
      "         -0.5366,  -4.7725,  -1.0342], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.034\n",
      "activated x value: tensor([-1.4254, -3.3537,  3.8007, -5.8252,  1.5767,  2.0021,  8.7605, -4.2028,\n",
      "         1.9855, -3.0511], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7706], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0196e+01, -1.2124e+01, -4.9698e+00, -1.4596e+01, -7.1939e+00,\n",
      "        -6.7685e+00, -1.0079e-02, -1.2973e+01, -6.7850e+00, -1.1822e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.010\n",
      "activated x value: tensor([-2.6747e+00, -7.7405e+00,  9.6530e-03, -9.0060e-01,  1.0612e+01,\n",
      "        -1.4122e+00,  1.2726e+00, -2.2009e+00, -1.0889e+00,  3.4704e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6128], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3287e+01, -1.8353e+01, -1.0603e+01, -1.1513e+01, -9.3269e-04,\n",
      "        -1.2025e+01, -9.3401e+00, -1.2814e+01, -1.1702e+01, -7.1424e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-9.9537, -3.5939, -4.6996,  0.0457, 11.9348,  0.9226,  0.7074,  1.2989,\n",
      "        -0.5794,  4.5061], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.9355], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.1889e+01, -1.5529e+01, -1.6635e+01, -1.1890e+01, -6.5804e-04,\n",
      "        -1.1013e+01, -1.1228e+01, -1.0637e+01, -1.2515e+01, -7.4294e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ -1.2528, -11.3123,  -1.7369,   0.9222,  10.5904,   3.9345,  -0.7242,\n",
      "         -5.4731,  -0.1021,   4.6186], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.5944], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1847e+01, -2.1907e+01, -1.2331e+01, -9.6721e+00, -3.9377e-03,\n",
      "        -6.6598e+00, -1.1319e+01, -1.6067e+01, -1.0696e+01, -5.9758e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-3.8631,  0.6357,  1.9404,  0.2738, -1.3491,  2.4873,  8.5831, -8.1689,\n",
      "         3.0192, -2.2096], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5911], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2454e+01, -7.9555e+00, -6.6508e+00, -8.3174e+00, -9.9402e+00,\n",
      "        -6.1038e+00, -8.0299e-03, -1.6760e+01, -5.5720e+00, -1.0801e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([  4.7312,  -2.3111,   7.4334,   0.9328,  -6.5799,   5.3908,   5.7659,\n",
      "        -11.2492,   1.9477,  -6.4286], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7635], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.0323, -10.0747,  -0.3301,  -6.8307, -14.3435,  -2.3728,  -1.9976,\n",
      "        -19.0127,  -5.8159, -14.1922], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.330\n",
      "activated x value: tensor([-4.2819,  7.4257,  2.9937,  2.0707, -6.1144,  0.7090, -0.6300, -2.0070,\n",
      "         2.0752, -1.2167], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4486], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.7305,  -0.0229,  -4.4549,  -5.3779, -13.5630,  -6.7396,  -8.0786,\n",
      "         -9.4555,  -5.3734,  -8.6653], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.023\n",
      "activated x value: tensor([-6.5807,  4.5798,  8.3526,  2.7960, -4.8773, -4.0529,  2.3077, -1.7740,\n",
      "        -0.3243, -1.0018], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3817], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.9624,  -3.8018,  -0.0291,  -5.5856, -13.2590, -12.4346,  -6.0739,\n",
      "        -10.1556,  -8.7059,  -9.3835], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.029\n",
      "activated x value: tensor([-3.7044, -5.5150,  0.2001, -2.9752,  8.1215, -1.7897, -0.1713, -0.4906,\n",
      "         3.3107,  3.1009], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1370], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8414, -13.6520,  -7.9369, -11.1122,  -0.0155,  -9.9267,  -8.3083,\n",
      "         -8.6275,  -4.8263,  -5.0361], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([-6.8089, -4.2892, -3.3260, -2.6400,  4.7716, -3.5231, -3.9450, 11.0566,\n",
      "         5.2614,  4.8606], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.0636], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7872e+01, -1.5353e+01, -1.4390e+01, -1.3704e+01, -6.2919e+00,\n",
      "        -1.4587e+01, -1.5009e+01, -6.9218e-03, -5.8022e+00, -6.2030e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-1.7750, -3.2876, -1.3883,  4.8965, -0.3813,  4.5564, -3.0987,  0.8005,\n",
      "         0.1545, -0.9405], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4554], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.2304, -8.7431, -6.8438, -0.5590, -5.8367, -0.8990, -8.5541, -4.6549,\n",
      "        -5.3009, -6.3959], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.559\n",
      "activated x value: tensor([-7.7381,  7.4499,  1.1417,  0.7183, -1.7367, -1.6815,  1.2284, -2.4730,\n",
      "         4.0366,  0.5105], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4883], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.2265,  -0.0384,  -6.3467,  -6.7700,  -9.2250,  -9.1698,  -6.2600,\n",
      "         -9.9614,  -3.4517,  -6.9778], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.038\n",
      "activated x value: tensor([ 1.8845, -6.3883,  8.5186,  3.6657, -5.2540, -4.2416,  1.3253,  2.3588,\n",
      "         0.0759, -2.1315], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5308], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6463e+00, -1.4919e+01, -1.2155e-02, -4.8650e+00, -1.3785e+01,\n",
      "        -1.2772e+01, -7.2055e+00, -6.1720e+00, -8.4548e+00, -1.0662e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([-5.8766, -2.8990,  2.0945, -0.1194,  3.2282,  1.0313,  2.0633, -4.9279,\n",
      "         6.7922, -1.4947], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8417], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.7183,  -9.7407,  -4.7472,  -6.9611,  -3.6135,  -5.8104,  -4.7784,\n",
      "        -11.7696,  -0.0495,  -8.3365], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.050\n",
      "activated x value: tensor([ 0.4148, -5.7660, -0.0252,  2.2632,  1.0234,  3.7458, -3.2929, -2.2119,\n",
      "         1.7536,  1.5707], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2190], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.8042, -9.9849, -4.2441, -1.9558, -3.1955, -0.4732, -7.5119, -6.4309,\n",
      "        -2.4654, -2.6483], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.473\n",
      "activated x value: tensor([  2.1449, -10.6870,  -0.7054,   0.2818,  -2.5457,  -0.5441,  -5.7880,\n",
      "         12.4733,   1.6190,   3.9049], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4736], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0329e+01, -2.3161e+01, -1.3179e+01, -1.2192e+01, -1.5019e+01,\n",
      "        -1.3018e+01, -1.8262e+01, -2.5177e-04, -1.0855e+01, -8.5686e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-0.2115, -1.2714,  1.7915,  5.2144, -7.7276,  3.3107,  2.6622, -0.9376,\n",
      "        -1.3751, -1.8963], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4532], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6647,  -6.7246,  -3.6617,  -0.2389, -13.1808,  -2.1426,  -2.7910,\n",
      "         -6.3908,  -6.8283,  -7.3495], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.239\n",
      "activated x value: tensor([  0.7917, -15.4692,  -3.8138,  -1.6000,   2.0922,   2.4482,  -5.9902,\n",
      "          8.9209,   3.0814,   9.1763], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7525], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.9607, -25.2217, -13.5663, -11.3525,  -7.6602,  -7.3043, -15.7427,\n",
      "         -0.8316,  -6.6711,  -0.5761], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.832\n",
      "activated x value: tensor([ -3.0194, -10.6199,   3.0865,  -2.2659,   4.4325,  -3.9292,  -1.3384,\n",
      "         -1.2206,   3.9254,  10.7557], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7591], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3778e+01, -2.1379e+01, -7.6725e+00, -1.3025e+01, -6.3265e+00,\n",
      "        -1.4688e+01, -1.2097e+01, -1.1980e+01, -6.8337e+00, -3.3512e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 10.2723, -11.7866,  -1.0491,   4.8264,  -5.0272,   3.8063,  -6.9134,\n",
      "          3.3698,   0.4009,   2.4452], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2796], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.3109e-03, -2.2066e+01, -1.1329e+01, -5.4533e+00, -1.5307e+01,\n",
      "        -6.4733e+00, -1.7193e+01, -6.9098e+00, -9.8787e+00, -7.8344e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-7.4391,  8.3008,  2.0303,  0.8749, -4.1877, -1.3455,  2.8021, -4.3784,\n",
      "         4.5266, -0.1273], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3302], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.7693,  -0.0294,  -6.2999,  -7.4553, -12.5179,  -9.6757,  -5.5280,\n",
      "        -12.7085,  -3.8036,  -8.4575], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.029\n",
      "activated x value: tensor([-4.0116, -2.9591,  6.0561,  2.7761, -8.0323, -1.1002, -4.1596,  1.7712,\n",
      "         8.3343, -0.0749], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4369], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.4486, -11.3960,  -2.3808,  -5.6608, -16.4693,  -9.5371, -12.5965,\n",
      "         -6.6657,  -0.1026,  -8.5118], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.103\n",
      "activated x value: tensor([-0.5585,  0.5530,  2.4165, -0.7474, -2.8602,  2.5154,  8.5867, -9.3168,\n",
      "         3.4921, -3.6149], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5977], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1562e+00, -8.0447e+00, -6.1812e+00, -9.3451e+00, -1.1458e+01,\n",
      "        -6.0823e+00, -1.1003e-02, -1.7915e+01, -5.1056e+00, -1.2213e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-3.8445, -3.8952, -2.2745,  3.2982,  8.0090, -2.2298,  0.2889, -0.6595,\n",
      "        -4.3437,  6.3146], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1858], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.0303, -12.0810, -10.4603,  -4.8876,  -0.1768, -10.4156,  -7.8969,\n",
      "         -8.8453, -12.5295,  -1.8712], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.177\n",
      "activated x value: tensor([-5.6376,  4.1877,  2.4681,  4.7656, -3.3500, -0.8517, -2.5048,  0.5878,\n",
      "        -0.1468,  0.5953], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2988], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9364,  -1.1111,  -2.8307,  -0.5332,  -8.6488,  -6.1505,  -7.8036,\n",
      "         -4.7110,  -5.4457,  -4.7036], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -1.111\n",
      "activated x value: tensor([ -3.6223, -10.3208,   1.1303,   5.3353,  -3.4436,  -3.1126, -11.5448,\n",
      "         17.5952,   1.1484,   6.1022], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([17.5952], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.1218e+01, -2.7916e+01, -1.6465e+01, -1.2260e+01, -2.1039e+01,\n",
      "        -2.0708e+01, -2.9140e+01, -1.5259e-05, -1.6447e+01, -1.1493e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-3.0779, -3.0310,  0.7456, -4.3637,  2.0768,  0.4088,  9.0836, -1.9660,\n",
      "        -0.4873,  0.1217], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0852], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2163e+01, -1.2116e+01, -8.3396e+00, -1.3449e+01, -7.0084e+00,\n",
      "        -8.6763e+00, -1.5402e-03, -1.1051e+01, -9.5724e+00, -8.9635e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-3.0498,  1.3936,  3.4012,  0.5856, -1.3664, -1.0761,  0.9898, -1.0401,\n",
      "         1.4011, -1.4386], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.7798], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8296, -2.3863, -0.3787, -3.1943, -5.1463, -4.8560, -2.7900, -4.8200,\n",
      "        -2.3787, -5.2184], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -3.194\n",
      "activated x value: tensor([ 1.5138, -5.9893,  0.0133,  4.1941, -4.3916,  7.9531, -3.0476, -3.5554,\n",
      "         4.7891, -1.4304], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0186], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.5048, -14.0079,  -8.0053,  -3.8245, -12.4102,  -0.0654, -11.0662,\n",
      "        -11.5740,  -3.2295,  -9.4490], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.065\n",
      "activated x value: tensor([-3.5554, -8.5005,  2.6335, -3.0674,  6.0076, -0.3856,  0.9199,  0.3780,\n",
      "         0.9852,  5.7802], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6223], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1777, -15.1228,  -3.9888,  -9.6897,  -0.6147,  -7.0079,  -5.7024,\n",
      "         -6.2443,  -5.6372,  -0.8421], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.842\n",
      "activated x value: tensor([-5.8372,  0.4197, -0.4019, -1.6042,  6.1416, -3.2286,  0.2958, -1.5024,\n",
      "         0.2861,  6.0463], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7942], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.6314,  -6.3745,  -7.1961,  -8.3984,  -0.6526, -10.0228,  -6.4984,\n",
      "         -8.2965,  -6.5080,  -0.7479], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.653\n",
      "activated x value: tensor([-5.5288, -1.9452, -0.8408,  1.5898, -1.5421,  1.6426,  2.1002, -0.4288,\n",
      "         5.1847, -1.0972], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2910], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8198,  -7.2362,  -6.1318,  -3.7012,  -6.8331,  -3.6484,  -3.1908,\n",
      "         -5.7198,  -0.1063,  -6.3882], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.106\n",
      "activated x value: tensor([-7.4500, -0.0738, -0.5880,  5.6330, -0.4710, -0.7602, -5.8862, -0.5395,\n",
      "         3.7548,  6.2481], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7363], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.1863,  -6.8101,  -7.3243,  -1.1033,  -7.2073,  -7.4965, -12.6225,\n",
      "         -7.2758,  -2.9815,  -0.4882], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.103\n",
      "activated x value: tensor([-3.4522, -2.1179,  0.0236, -0.1752, -0.4828,  0.8813, -1.5873,  5.1266,\n",
      "        -1.4848,  3.7587], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3790], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8312, -7.4969, -5.3555, -5.5542, -5.8618, -4.4977, -6.9664, -0.2524,\n",
      "        -6.8638, -1.6204], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -5.355\n",
      "activated x value: tensor([-2.7219, -6.7002,  1.4245,  0.5856,  2.0988,  2.0935, -2.6199,  2.2471,\n",
      "         0.4567,  4.6400], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9196], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6415, -11.6198,  -3.4951,  -4.3340,  -2.8207,  -2.8260,  -7.5395,\n",
      "         -2.6724,  -4.4629,  -0.2796], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.280\n",
      "activated x value: tensor([ 2.4931, -5.0641,  2.2955,  1.0677, -2.0215,  1.1387, -9.8954, 11.1106,\n",
      "        -0.7943, -0.7030], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1111], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.6179e+00, -1.6175e+01, -8.8155e+00, -1.0043e+01, -1.3133e+01,\n",
      "        -9.9723e+00, -2.1006e+01, -4.3583e-04, -1.1905e+01, -1.1814e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 0.8738, -2.3922,  2.7919, -2.7471, -0.8963,  3.8333,  6.3940, -5.6310,\n",
      "         0.7662, -3.1482], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5012], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6274,  -8.8934,  -3.7093,  -9.2483,  -7.3975,  -2.6679,  -0.1072,\n",
      "        -12.1322,  -5.7350,  -9.6494], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.107\n",
      "activated x value: tensor([-1.1585, -5.5959,  3.0025, -2.4020,  1.7550, -1.5473,  0.2459,  3.6456,\n",
      "        -1.3146,  3.0234], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.4654], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6238, -10.0612,  -1.4629,  -6.8674,  -2.7104,  -6.0127,  -4.2194,\n",
      "         -0.8198,  -5.7800,  -1.4420], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.442\n",
      "activated x value: tensor([-2.2324, -8.4540, -5.9510, -3.5498, 11.7452, -0.8049,  1.3907,  1.0597,\n",
      "         1.3917,  5.5674], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.7473], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3980e+01, -2.0201e+01, -1.7698e+01, -1.5297e+01, -2.1639e-03,\n",
      "        -1.2552e+01, -1.0357e+01, -1.0688e+01, -1.0356e+01, -6.1799e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-2.3407, -2.8580,  2.0258, -3.3902,  1.4253, -2.5445,  8.1833, -0.1109,\n",
      "        -0.5214,  0.3033], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1874], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0528e+01, -1.1045e+01, -6.1616e+00, -1.1578e+01, -6.7621e+00,\n",
      "        -1.0732e+01, -4.1389e-03, -8.2983e+00, -8.7088e+00, -7.8841e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-0.1210, -8.7040, -4.4597,  1.9766, -0.3253,  0.3990, -8.9121, 12.9687,\n",
      "         0.6830,  5.6074], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.9693], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3090e+01, -2.1673e+01, -1.7429e+01, -1.0993e+01, -1.3295e+01,\n",
      "        -1.2570e+01, -2.1881e+01, -6.6376e-04, -1.2286e+01, -7.3619e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ -8.3429,   6.8698,  12.0124,   7.8355, -10.5617,   0.0830,   4.7748,\n",
      "         -8.3880,   1.4339,  -4.6170], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.0341], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0377e+01, -5.1643e+00, -2.1703e-02, -4.1986e+00, -2.2596e+01,\n",
      "        -1.1951e+01, -7.2593e+00, -2.0422e+01, -1.0600e+01, -1.6651e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.022\n",
      "activated x value: tensor([-8.6891,  7.5843, -0.6295,  1.8399, -2.6072,  2.4757, -0.7325, -2.3508,\n",
      "         2.4411, -0.1346], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6003], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6289e+01, -1.6002e-02, -8.2297e+00, -5.7603e+00, -1.0207e+01,\n",
      "        -5.1246e+00, -8.3327e+00, -9.9511e+00, -5.1592e+00, -7.7349e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-0.8382, -2.0903, -1.5883,  3.6791, -2.8384,  6.0487, -4.2807, -5.5368,\n",
      "         7.3847,  0.5354], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6386], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.4769,  -9.7290,  -9.2270,  -3.9595, -10.4770,  -1.5900, -11.9193,\n",
      "        -13.1754,  -0.2539,  -7.1032], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.254\n",
      "activated x value: tensor([-8.1677, -3.5200, -7.2867,  2.0478,  5.0514,  0.4385, -4.5142,  2.1139,\n",
      "         3.1888, 10.6907], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6952], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8863e+01, -1.4215e+01, -1.7982e+01, -8.6475e+00, -5.6438e+00,\n",
      "        -1.0257e+01, -1.5209e+01, -8.5813e+00, -7.5064e+00, -4.4985e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -5.644\n",
      "activated x value: tensor([-1.3795, -2.7554,  4.1141, -3.9169,  0.8017, -0.4919,  9.0295, -6.1021,\n",
      "         1.8480, -1.4022], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0380], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0418e+01, -1.1793e+01, -4.9239e+00, -1.2955e+01, -8.2363e+00,\n",
      "        -9.5299e+00, -8.4677e-03, -1.5140e+01, -7.1900e+00, -1.0440e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-2.7231, -2.7376,  1.9085, -1.7220,  1.2875,  3.1705,  5.4885, -9.9937,\n",
      "         9.5488, -4.1206], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5684], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2291e+01, -1.2306e+01, -7.6599e+00, -1.1290e+01, -8.2808e+00,\n",
      "        -6.3979e+00, -4.0798e+00, -1.9562e+01, -1.9512e-02, -1.3689e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([-9.3554e+00,  9.5072e+00, -2.2217e-01,  3.4633e+00, -3.5190e+00,\n",
      "         7.3004e-03, -9.0807e-01, -6.3359e-01,  4.7848e-01,  9.4472e-01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5101], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8866e+01, -2.8849e-03, -9.7323e+00, -6.0468e+00, -1.3029e+01,\n",
      "        -9.5028e+00, -1.0418e+01, -1.0144e+01, -9.0316e+00, -8.5654e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-1.3812, -4.8372, -2.1524, -2.0708,  8.1129,  0.6687,  0.8380, -0.9618,\n",
      "        -0.2474,  2.0181], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1169], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.4981e+00, -1.2954e+01, -1.0269e+01, -1.0188e+01, -4.0226e-03,\n",
      "        -7.4483e+00, -7.2789e+00, -9.0787e+00, -8.3643e+00, -6.0988e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-0.2711,  0.7229,  6.7612,  2.6749, -2.7926, -0.6636, -1.8552, -2.3439,\n",
      "         1.8800, -4.0922], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7894], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0605,  -6.0665,  -0.0282,  -4.1145,  -9.5820,  -7.4530,  -8.6446,\n",
      "         -9.1333,  -4.9094, -10.8816], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-5.3725, -6.0450,  3.8070, 11.4783,  1.2651, -0.6832, -6.8483, -2.2162,\n",
      "         3.8626,  0.1360], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.4793], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6852e+01, -1.7524e+01, -7.6723e+00, -1.0128e-03, -1.0214e+01,\n",
      "        -1.2163e+01, -1.8328e+01, -1.3696e+01, -7.6168e+00, -1.1343e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-5.3843, -2.9827, -2.1499,  0.9849,  5.1419, -0.6438, -2.3518,  2.0717,\n",
      "         1.5691,  3.6450], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4185], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8027,  -8.4011,  -7.5684,  -4.4336,  -0.2766,  -6.0623,  -7.7703,\n",
      "         -3.3468,  -3.8493,  -1.7734], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.277\n",
      "activated x value: tensor([-3.4142, -4.5664, -2.4022,  0.4550, -0.7699, -0.5555, -7.5868, 11.3242,\n",
      "         2.5231,  4.5786], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.3255], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4740e+01, -1.5892e+01, -1.3728e+01, -1.0871e+01, -1.2095e+01,\n",
      "        -1.1881e+01, -1.8912e+01, -1.3590e-03, -8.8024e+00, -6.7469e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 14.6218, -12.2663,   6.5389,   0.5324, -11.2309,   5.9861,  -8.3357,\n",
      "         -1.3393,   6.1508,  -0.9516], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.6225], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9714e-04, -2.6889e+01, -8.0836e+00, -1.4090e+01, -2.5853e+01,\n",
      "        -8.6364e+00, -2.2958e+01, -1.5962e+01, -8.4717e+00, -1.5574e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.0452, -5.7538,  0.1103, -0.7023,  2.3970,  1.7515,  2.8729, -9.7957,\n",
      "        10.0990,  1.4180], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1007], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2146e+01, -1.5854e+01, -9.9903e+00, -1.0803e+01, -7.7037e+00,\n",
      "        -8.3492e+00, -7.2278e+00, -1.9896e+01, -1.6565e-03, -8.6827e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-2.0245, -7.8244, -3.7336, -5.7804,  9.3501, -0.5480,  0.8113,  2.6735,\n",
      "         1.7763,  4.8641], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.3633], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1388e+01, -1.7188e+01, -1.3097e+01, -1.5144e+01, -1.3211e-02,\n",
      "        -9.9113e+00, -8.5520e+00, -6.6898e+00, -7.5870e+00, -4.4992e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-2.4290, -2.9857,  2.2737, -5.3110,  4.1671, -2.1092,  3.4380,  2.0182,\n",
      "        -0.4196,  0.8735], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7554], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1844,  -7.7411,  -2.4817, -10.0664,  -0.5883,  -6.8646,  -1.3174,\n",
      "         -2.7371,  -5.1750,  -3.8819], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.588\n",
      "activated x value: tensor([ 1.1449, -6.3600,  4.1974, -3.3387,  0.7966,  2.1414, 11.0635, -3.2923,\n",
      "        -1.5247, -4.5169], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.0647], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.9199e+00, -1.7425e+01, -6.8673e+00, -1.4403e+01, -1.0268e+01,\n",
      "        -8.9233e+00, -1.2636e-03, -1.4357e+01, -1.2589e+01, -1.5582e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-3.7500,  0.1194,  3.6669,  2.9252, -0.9580,  1.8499,  0.7978, -2.3294,\n",
      "        -1.0148, -0.9052], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.2304], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.9805, -4.1111, -0.5635, -1.3053, -5.1884, -2.3805, -3.4327, -6.5598,\n",
      "        -5.2452, -5.1357], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.305\n",
      "activated x value: tensor([ 1.2387, -4.8135,  0.5162, -0.8498, -0.1950,  5.3305, -1.2562, -8.0550,\n",
      "         8.6997, -1.2774], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7346], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.4960, -13.5481,  -8.2184,  -9.5844,  -8.9296,  -3.4042,  -9.9908,\n",
      "        -16.7897,  -0.0350, -10.0120], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.035\n",
      "activated x value: tensor([-2.5958, -3.9254, -0.2808, -2.0681,  7.4245, -4.4930, -0.0805, -0.1525,\n",
      "        -0.5534,  7.5961], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.2080], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8038, -12.1334,  -8.4888, -10.2761,  -0.7835, -12.7011,  -8.2885,\n",
      "         -8.3605,  -8.7614,  -0.6119], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.784\n",
      "activated x value: tensor([-4.8391,  3.4407,  0.5219,  0.9050, -1.1811,  3.6428, -1.0313, -3.3216,\n",
      "         3.7027, -2.5494], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.7441], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.5832, -1.3034, -4.2223, -3.8391, -5.9253, -1.1013, -5.7754, -8.0658,\n",
      "        -1.0414, -7.2935], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.041\n",
      "activated x value: tensor([-8.2234,  8.7783, -0.6757,  2.4408, -3.7460,  1.7878,  0.1797, -2.5696,\n",
      "         1.5671,  0.1631], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7822], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7006e+01, -3.8795e-03, -9.4578e+00, -6.3414e+00, -1.2528e+01,\n",
      "        -6.9944e+00, -8.6025e+00, -1.1352e+01, -7.2151e+00, -8.6191e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-5.8390, -2.0699,  2.0454,  0.5279,  0.1316, -2.8938, -0.0170,  6.2089,\n",
      "        -0.4442,  2.7756], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2645], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.1035,  -8.3343,  -4.2191,  -5.7366,  -6.1328,  -9.1582,  -6.2815,\n",
      "         -0.0556,  -6.7086,  -3.4888], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.056\n",
      "activated x value: tensor([ 2.0876, -2.2462,  2.4895, -2.5861, -2.2223,  4.7067,  9.0108, -9.5078,\n",
      "         1.5734, -3.0131], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0272], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.9397e+00, -1.1273e+01, -6.5377e+00, -1.1613e+01, -1.1250e+01,\n",
      "        -4.3206e+00, -1.6463e-02, -1.8535e+01, -7.4538e+00, -1.2040e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([ 1.6426, -4.0770,  1.6650,  2.0040, -2.4114,  6.6454, -1.4339, -7.2316,\n",
      "         3.7262, -1.3312], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7205], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.0779, -10.7975,  -5.0555,  -4.7165,  -9.1319,  -0.0751,  -8.1544,\n",
      "        -13.9521,  -2.9943,  -8.0517], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.075\n",
      "activated x value: tensor([-3.1226, -2.5444, -2.4503,  2.7464,  1.1270,  4.5685,  1.1284, -3.9175,\n",
      "         2.8382, -1.2388], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9110], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0336, -7.4554, -7.3613, -2.1646, -3.7840, -0.3424, -3.7826, -8.8285,\n",
      "        -2.0728, -6.1497], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.342\n",
      "activated x value: tensor([-10.6485,   6.8986,  -0.3936,   4.0186,  -1.2974,   3.1498,  -0.3965,\n",
      "         -4.5547,   2.0867,  -0.0524], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9852], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.6337,  -0.0866,  -7.3788,  -2.9666,  -8.2825,  -3.8354,  -7.3816,\n",
      "        -11.5399,  -4.8985,  -7.0376], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.087\n",
      "activated x value: tensor([-2.6778, -7.2472,  1.9107,  4.8984,  0.2960,  2.8610, -2.9564, -6.3111,\n",
      "         9.3901, -1.0277], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4034], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2081e+01, -1.6651e+01, -7.4926e+00, -4.5050e+00, -9.1074e+00,\n",
      "        -6.5424e+00, -1.2360e+01, -1.5714e+01, -1.3290e-02, -1.0431e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-1.1613, -3.1225, -0.0895,  2.5823, -2.3297,  6.1867,  5.9961, -5.4521,\n",
      "         0.8637, -4.1702], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8080], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9694,  -9.9305,  -6.8975,  -4.2257,  -9.1377,  -0.6213,  -0.8120,\n",
      "        -12.2601,  -5.9443, -10.9782], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.621\n",
      "activated x value: tensor([-1.1718, -7.2810, -5.5077,  5.1640, -3.0873,  8.9518, -6.2074,  2.4232,\n",
      "         5.4701,  0.7381], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0055], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.1773, -16.2865, -14.5132,  -3.8416, -12.0928,  -0.0537, -15.2129,\n",
      "         -6.5823,  -3.5354,  -8.2674], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.054\n",
      "activated x value: tensor([-7.7023,  8.7887,  0.7934,  1.4314, -5.2375,  1.0990,  1.1902, -2.6457,\n",
      "         2.8893, -0.2744], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7935], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6496e+01, -4.7913e-03, -8.0001e+00, -7.3621e+00, -1.4031e+01,\n",
      "        -7.6945e+00, -7.6033e+00, -1.1439e+01, -5.9042e+00, -9.0679e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-6.6872,  9.7138,  2.3196,  0.6860, -5.6756, -0.7718,  0.5449, -1.1556,\n",
      "         2.8095, -0.7516], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7157], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6403e+01, -1.9169e-03, -7.3961e+00, -9.0297e+00, -1.5391e+01,\n",
      "        -1.0487e+01, -9.1708e+00, -1.0871e+01, -6.9062e+00, -1.0467e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-9.9857, 10.6220, -0.7682,  2.5018, -4.5294, -0.3885, -2.1354,  1.4659,\n",
      "         1.3226,  2.2097], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6228], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0608e+01, -7.4768e-04, -1.1391e+01, -8.1210e+00, -1.5152e+01,\n",
      "        -1.1011e+01, -1.2758e+01, -9.1569e+00, -9.3001e+00, -8.4131e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 1.8234, -1.7784, -3.0846, -3.9555,  1.2387,  6.7666,  1.0226, -2.1199,\n",
      "         1.2728, -0.8570], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7857], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.9623,  -8.5641,  -9.8703, -10.7412,  -5.5470,  -0.0191,  -5.7631,\n",
      "         -8.9056,  -5.5129,  -7.6427], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([ -0.8026,   6.1683,   9.7366,   4.8508, -12.5608,   0.5060,   2.9076,\n",
      "         -8.0913,   3.0807,  -4.6352], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7742], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5768,  -3.6059,  -0.0375,  -4.9234, -22.3350,  -9.2682,  -6.8666,\n",
      "        -17.8654,  -6.6934, -14.4094], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.038\n",
      "activated x value: tensor([-3.3134, -2.6431, -1.3705,  5.9774, -1.9629,  3.9002, -4.0835, -4.9812,\n",
      "         8.9140, -0.5748], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9721], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.2855, -11.6152, -10.3426,  -2.9947, -10.9350,  -5.0718, -13.0556,\n",
      "        -13.9533,  -0.0581,  -9.5468], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.058\n",
      "activated x value: tensor([ 0.1263, -8.3397, -0.2933, -1.0545,  6.6439, -2.9105,  0.1642, -1.7608,\n",
      "         1.1670,  4.8871], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8107], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6843, -15.1504,  -7.1040,  -7.8652,  -0.1668,  -9.7212,  -6.6465,\n",
      "         -8.5714,  -5.6437,  -1.9236], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.167\n",
      "activated x value: tensor([-2.6841, -7.7640,  2.1889,  4.8403, -0.5422,  3.4797, -1.6454, -9.0844,\n",
      "        10.1811,  0.3856], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1875], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2872e+01, -1.7952e+01, -7.9986e+00, -5.3472e+00, -1.0730e+01,\n",
      "        -6.7079e+00, -1.1833e+01, -1.9272e+01, -6.4259e-03, -9.8019e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-8.8396, -1.4764, -3.4820,  2.9789,  2.0117,  1.3482, -4.3559, -1.4773,\n",
      "         3.2965, 10.6105], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6119], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9451e+01, -1.2088e+01, -1.4094e+01, -7.6330e+00, -8.6002e+00,\n",
      "        -9.2637e+00, -1.4968e+01, -1.2089e+01, -7.3154e+00, -1.4420e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([ 4.1228, -8.3498,  8.0090,  9.6223, -8.9407,  2.2160, -4.0936,  1.4357,\n",
      "         2.5130, -7.0874], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8088], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.6860, -18.1586,  -1.7997,  -0.1865, -18.7495,  -7.5927, -13.9024,\n",
      "         -8.3731,  -7.2958, -16.8962], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.800\n",
      "activated x value: tensor([-6.4143,  6.5565,  9.5486,  5.4195, -8.0834, -0.8695,  0.2336, -8.1849,\n",
      "         4.7328, -2.9731], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6205], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.0348,  -3.0640,  -0.0719,  -4.2010, -17.7038, -10.4900,  -9.3869,\n",
      "        -17.8054,  -4.8877, -12.5936], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.072\n",
      "activated x value: tensor([-4.9142,  4.3619,  5.7142,  1.0237, -1.7736,  0.8161,  2.8807, -6.6470,\n",
      "         1.8109, -3.2516], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0180], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.9322,  -1.6561,  -0.3038,  -4.9943,  -7.7916,  -5.2019,  -3.1373,\n",
      "        -12.6651,  -4.2071,  -9.2696], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.304\n",
      "activated x value: tensor([-1.9810, -6.1968,  4.2161, -1.2814, -2.7104,  5.3560, -2.0398, -1.0282,\n",
      "         3.9793,  1.5496], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8254], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.8064, -12.0222,  -1.6093,  -7.1068,  -8.5358,  -0.4694,  -7.8652,\n",
      "         -6.8536,  -1.8461,  -4.2758], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.609\n",
      "activated x value: tensor([ 3.5250,  0.8456,  3.4829,  4.3759, -4.0877,  6.4919,  0.8207, -9.6437,\n",
      "         1.8820, -8.2967], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7056], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.1807,  -5.8600,  -3.2227,  -2.3297, -10.7934,  -0.2137,  -5.8850,\n",
      "        -16.3494,  -4.8236, -15.0024], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -3.223\n",
      "activated x value: tensor([  5.6247, -15.7612,  15.7595,   5.4890,  -4.2219,   2.9431,   1.7705,\n",
      "        -10.4471,   6.2863,  -8.6676], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.7596], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0135e+01, -3.1521e+01, -1.5450e-04, -1.0271e+01, -1.9982e+01,\n",
      "        -1.2817e+01, -1.3989e+01, -2.6207e+01, -9.4733e+00, -2.4427e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ 0.5428, -6.4935, -2.0084,  1.3422, -0.7664,  0.3039, -5.2212,  4.3817,\n",
      "         0.8128,  6.6273], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7396], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.1968, -13.2330,  -8.7480,  -5.3974,  -7.5060,  -6.4357, -11.9608,\n",
      "         -2.3579,  -5.9267,  -0.1122], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.112\n",
      "activated x value: tensor([-0.4706, -5.2642,  1.6708, -3.3815,  2.3948,  1.9057,  9.8656, -7.8713,\n",
      "         3.1586, -1.1151], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8681], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0339e+01, -1.5132e+01, -8.1973e+00, -1.3250e+01, -7.4732e+00,\n",
      "        -7.9624e+00, -2.4652e-03, -1.7739e+01, -6.7095e+00, -1.0983e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-1.9360, -1.1624, -0.5320,  0.8268,  0.7701,  3.4377, -1.8727, -2.6874,\n",
      "         2.8604, -0.8703], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.0021], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9381, -5.1645, -4.5341, -3.1753, -3.2320, -0.5644, -5.8748, -6.6895,\n",
      "        -1.1417, -4.8724], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.142\n",
      "activated x value: tensor([-8.1199,  6.6159,  0.8361,  2.1499, -2.3383, -1.9640, -2.3702,  3.2857,\n",
      "         1.5897,  1.1600], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6757], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.7956,  -0.0598,  -5.8396,  -4.5258,  -9.0140,  -8.6397,  -9.0459,\n",
      "         -3.3900,  -5.0860,  -5.5157], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.060\n",
      "activated x value: tensor([ 3.5167, -5.0234,  3.1608,  2.1027, -0.7996,  1.7428,  0.1438, -1.6831,\n",
      "        -3.0864,  0.8641], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3225], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-0.8058, -9.3459, -1.1618, -2.2198, -5.1221, -2.5797, -4.1788, -6.0056,\n",
      "        -7.4089, -3.4584], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.162\n",
      "activated x value: tensor([ -4.3257,  -0.5770, -10.4196,   0.6913,   2.4191,   1.7547,  -5.1112,\n",
      "          7.6628,   1.7062,   6.0131], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8484], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.1740,  -8.4254, -18.2679,  -7.1571,  -5.4293,  -6.0937, -12.9596,\n",
      "         -0.1856,  -6.1422,  -1.8352], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.186\n",
      "activated x value: tensor([ 3.5435, -6.3170, 12.8255, -1.3093, -1.0099,  3.2609,  3.2514, -8.7190,\n",
      "         2.5823, -9.0825], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.8258], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.2823e+00, -1.9143e+01, -2.6989e-04, -1.4135e+01, -1.3836e+01,\n",
      "        -9.5648e+00, -9.5744e+00, -2.1545e+01, -1.0243e+01, -2.1908e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-9.9589,  8.6264,  0.9070,  1.6074, -4.0441, -0.6602, -0.0898, -1.0900,\n",
      "         4.2849,  1.0533], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6414], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8600e+01, -1.5076e-02, -7.7344e+00, -7.0341e+00, -1.2686e+01,\n",
      "        -9.3016e+00, -8.7313e+00, -9.7314e+00, -4.3566e+00, -7.5881e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([  1.8552, -11.9314,   4.1962,  -4.8630,   9.2481,  -5.8140,   4.2439,\n",
      "         -0.2358,  -0.3287,   2.8930], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2636], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-7.4084e+00, -2.1195e+01, -5.0674e+00, -1.4127e+01, -1.5487e-02,\n",
      "        -1.5078e+01, -5.0197e+00, -9.4994e+00, -9.5923e+00, -6.3706e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([ 0.5837, -8.7004,  3.7275, -2.6461,  3.0014,  2.5348,  9.4258, -4.8739,\n",
      "        -1.3331, -1.8756], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4320], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.8483e+00, -1.8132e+01, -5.7044e+00, -1.2078e+01, -6.4306e+00,\n",
      "        -6.8972e+00, -6.1550e-03, -1.4306e+01, -1.0765e+01, -1.1308e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-6.1235,  6.8383,  1.7325,  1.8034, -5.2864,  0.3610, -1.3850,  0.3887,\n",
      "         2.9854, -0.4254], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8755], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.9990,  -0.0372,  -5.1429,  -5.0720, -12.1619,  -6.5145,  -8.2605,\n",
      "         -6.4868,  -3.8901,  -7.3008], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.037\n",
      "activated x value: tensor([-8.8218,  8.3766, -0.6249,  2.3130, -3.0325,  1.4828, -0.6487, -1.6847,\n",
      "         1.8848,  0.7696], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3822], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7204e+01, -5.6343e-03, -9.0072e+00, -6.0692e+00, -1.1415e+01,\n",
      "        -6.8994e+00, -9.0310e+00, -1.0067e+01, -6.4974e+00, -7.6127e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.006\n",
      "activated x value: tensor([-1.6664, -1.2725, -0.0069, -0.1675,  0.6096,  5.0951,  1.4403, -3.8699,\n",
      "         2.2401, -2.0258], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1992], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8656, -6.4717, -5.2061, -5.3667, -4.5896, -0.1042, -3.7589, -9.0691,\n",
      "        -2.9591, -7.2250], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.104\n",
      "activated x value: tensor([ 1.6307, -4.7221,  2.4716, -1.8921, -0.6552,  2.2927, -1.2689, -1.3518,\n",
      "         2.8606,  0.5668], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.8566], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.2259, -8.5787, -1.3850, -5.7486, -4.5118, -1.5639, -5.1254, -5.2084,\n",
      "        -0.9960, -3.2898], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.564\n",
      "activated x value: tensor([ -1.4947, -11.3478,   9.5608,   3.3800,   0.1647,  -1.8573,   0.4166,\n",
      "         -4.0010,   1.8097,   2.4700], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5643], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1059e+01, -2.0912e+01, -3.5439e-03, -6.1843e+00, -9.3997e+00,\n",
      "        -1.1422e+01, -9.1478e+00, -1.3565e+01, -7.7546e+00, -7.0943e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-5.6529, -2.2800,  7.0341,  1.7016, -0.3094, -2.3463,  0.7462, -2.1532,\n",
      "         1.1475,  0.2900], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0456], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2699e+01, -9.3256e+00, -1.1505e-02, -5.3441e+00, -7.3550e+00,\n",
      "        -9.3919e+00, -6.2994e+00, -9.1988e+00, -5.8981e+00, -6.7556e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.012\n",
      "activated x value: tensor([ 2.6200, -3.2236, -0.9692,  4.3199, -2.5469,  5.2851, -0.0364, -8.5760,\n",
      "         5.3272, -2.8146], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2019], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.5818,  -9.4255,  -7.1711,  -1.8820,  -8.7488,  -0.9168,  -6.2383,\n",
      "        -14.7779,  -0.8746,  -9.0165], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.917\n",
      "activated x value: tensor([-5.3876, -0.1935,  2.2795,  0.0972,  0.3730,  0.4656, -0.6659, -3.6714,\n",
      "         5.7756,  0.3886], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8263], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.2139,  -6.0198,  -3.5467,  -5.7291,  -5.4533,  -5.3607,  -6.4922,\n",
      "         -9.4977,  -0.0507,  -5.4377], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.051\n",
      "activated x value: tensor([-4.0448,  6.0097,  1.6659,  0.7768, -3.7965,  0.5533, -0.6733,  0.2560,\n",
      "         0.9074, -1.0939], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0432], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.0880,  -0.0335,  -4.3773,  -5.2664,  -9.8397,  -5.4899,  -6.7165,\n",
      "         -5.7872,  -5.1357,  -7.1371], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([-0.8927,  3.1552,  2.1826,  7.9019, -7.9104,  1.9948, -2.0877, -2.5538,\n",
      "         1.7468, -2.6995], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9188], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.8115,  -4.7636,  -5.7362,  -0.0169, -15.8292,  -5.9240, -10.0065,\n",
      "        -10.4726,  -6.1720, -10.6183], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.017\n",
      "activated x value: tensor([ 0.0816, -2.2295,  1.6207,  1.0679, -3.7134,  1.9607, -2.3777, -2.9757,\n",
      "         7.3523, -0.1425], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3633], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.2817e+00, -9.5928e+00, -5.7426e+00, -6.2955e+00, -1.1077e+01,\n",
      "        -5.4027e+00, -9.7410e+00, -1.0339e+01, -1.1029e-02, -7.5058e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([  2.1506, -10.7273,  10.8752,   7.8002,  -2.5403,   0.1174,  -1.2881,\n",
      "         -6.0142,   2.9550,  -3.7689], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9208], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.7702, -21.6482,  -0.0457,  -3.1206, -13.4611, -10.8035, -12.2089,\n",
      "        -16.9351,  -7.9659, -14.6898], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.046\n",
      "activated x value: tensor([-6.7355,  8.1348,  1.8261,  1.7875, -4.9938, -0.5706, -0.0929, -0.2688,\n",
      "         2.6388, -0.6786], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1433], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4879e+01, -8.4467e-03, -6.3172e+00, -6.3558e+00, -1.3137e+01,\n",
      "        -8.7139e+00, -8.2361e+00, -8.4121e+00, -5.5045e+00, -8.8219e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([  0.9251,   0.4334,  16.3270,   9.9474, -11.3099,   1.5403,  -2.1385,\n",
      "        -14.3814,   8.5736,  -8.8486], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([16.3291], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5404e+01, -1.5896e+01, -2.1229e-03, -6.3817e+00, -2.7639e+01,\n",
      "        -1.4789e+01, -1.8468e+01, -3.0710e+01, -7.7555e+00, -2.5178e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([  8.1332, -11.1102,   1.9281,   0.5245,  -1.9638,   4.6986,   1.2104,\n",
      "         -2.6893,   0.8448,  -0.7304], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1691], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0360, -19.2793,  -6.2411,  -7.6446, -10.1329,  -3.4706,  -6.9587,\n",
      "        -10.8585,  -7.3244,  -8.8995], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.036\n",
      "activated x value: tensor([-3.6728, -1.8441, -2.8648,  0.7261, -1.9659,  4.5894, -1.0840, -1.4073,\n",
      "         3.7251,  4.5226], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4596], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.1324, -7.3037, -8.3244, -4.7336, -7.4256, -0.8702, -6.5436, -6.8669,\n",
      "        -1.7346, -0.9371], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.870\n",
      "activated x value: tensor([ 0.3535, -4.3757, 12.7397,  2.4080, -0.7880, -3.1546,  3.1000, -7.6261,\n",
      "         0.4778, -3.3185], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.7398], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2386e+01, -1.7116e+01, -1.0777e-04, -1.0332e+01, -1.3528e+01,\n",
      "        -1.5894e+01, -9.6399e+00, -2.0366e+01, -1.2262e+01, -1.6058e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-4.5109,  7.7560,  2.6917,  2.2445, -7.1718,  1.6243,  1.2998, -5.9923,\n",
      "         4.8972, -1.5902], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8251], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.3361,  -0.0691,  -5.1334,  -5.5806, -14.9969,  -6.2009,  -6.5253,\n",
      "        -13.8175,  -2.9279,  -9.4153], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.069\n",
      "activated x value: tensor([-1.6365, -6.6977,  0.6501, -0.3075, -0.0616, -0.4469, -3.6687,  6.1926,\n",
      "         0.4870,  5.1487], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5034], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.1398, -13.2010,  -5.8532,  -6.8109,  -6.5650,  -6.9502, -10.1720,\n",
      "         -0.3108,  -6.0164,  -1.3547], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-6.1398, -1.6779,  1.9989,  2.1946,  6.2674, -2.6648, -0.2883, -2.8067,\n",
      "         0.8903,  3.2515], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3505], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.4903,  -8.0284,  -4.3517,  -4.1559,  -0.0831,  -9.0153,  -6.6389,\n",
      "         -9.1572,  -5.4602,  -3.0991], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.083\n",
      "activated x value: tensor([-2.0262, -3.1999, -1.4780, 12.9662, -0.6659,  3.2805, -6.7984, -3.5443,\n",
      "         1.3208,  0.3254], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.9663], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4993e+01, -1.6166e+01, -1.4444e+01, -7.6294e-05, -1.3632e+01,\n",
      "        -9.6858e+00, -1.9765e+01, -1.6511e+01, -1.1646e+01, -1.2641e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([  3.4411,  -5.3706,  -1.6162,   2.5901,   0.2170,   7.4837,   4.4453,\n",
      "        -10.7436,   4.4321,  -5.4197], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5979], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.1568, -12.9686,  -9.2142,  -5.0078,  -7.3809,  -0.1143,  -3.1527,\n",
      "        -18.3415,  -3.1658, -13.0177], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.114\n",
      "activated x value: tensor([ -0.9398,  -1.4916,   4.3279,   3.7985,  -2.5608,   3.6055,   0.3616,\n",
      "        -12.0460,   9.4436,  -4.4798], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4561], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0396e+01, -1.0948e+01, -5.1282e+00, -5.6576e+00, -1.2017e+01,\n",
      "        -5.8506e+00, -9.0945e+00, -2.1502e+01, -1.2542e-02, -1.3936e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-4.2019,  6.4886,  1.3721,  1.9496, -6.3040,  0.7268, -1.4559, -1.0187,\n",
      "         2.6513,  0.1721], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5318], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7337,  -0.0432,  -5.1597,  -4.5822, -12.8358,  -5.8050,  -7.9877,\n",
      "         -7.5505,  -3.8804,  -6.3597], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([ -4.2837,  -0.7635,  -1.3735,   0.7087,  -1.3902,  -1.3440, -10.0231,\n",
      "         12.4208,   1.1362,   4.9730], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4214], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6705e+01, -1.3185e+01, -1.3795e+01, -1.1713e+01, -1.3812e+01,\n",
      "        -1.3765e+01, -2.2445e+01, -6.0844e-04, -1.1285e+01, -7.4484e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-1.1101,  2.1784, -0.3241,  0.8002, -2.9696,  3.5215,  0.5985, -5.0794,\n",
      "         3.8509, -0.2452], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.5606], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.6707, -2.3822, -4.8847, -3.7604, -7.5302, -1.0392, -3.9621, -9.6400,\n",
      "        -0.7097, -4.8058], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.710\n",
      "activated x value: tensor([-2.1715, -9.4445, -3.5298,  0.5735,  2.3027,  0.7200, -3.2102,  4.5890,\n",
      "         2.2441,  7.5562], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6179], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7894, -17.0625, -11.1478,  -7.0444,  -5.3153,  -6.8979, -10.8282,\n",
      "         -3.0289,  -5.3739,  -0.0618], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.062\n",
      "activated x value: tensor([-2.8787, -0.3757, -1.0452,  2.3396, -2.7145,  3.2870, -2.5865, -1.8547,\n",
      "         4.9007,  1.2211], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1723], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.0509, -5.5480, -6.2174, -2.8327, -7.8867, -1.8852, -7.7588, -7.0270,\n",
      "        -0.2715, -3.9511], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.272\n",
      "activated x value: tensor([ -0.9210,  -5.5958,   4.8493,  10.1647,  -0.0931,   2.2005,  -6.1762,\n",
      "        -10.1491,   6.9365,  -1.5340], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2087], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.1297, -15.8045,  -5.3594,  -0.0440, -10.3018,  -8.0082, -16.3849,\n",
      "        -20.3578,  -3.2722, -11.7427], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.044\n",
      "activated x value: tensor([ 14.6764, -12.2350,   0.2931,   1.1512,  -7.7376,   7.4275,  -2.0855,\n",
      "         -1.0850,   3.2899,  -2.3423], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([14.6771], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.2384e-04, -2.6912e+01, -1.4384e+01, -1.3526e+01, -2.2415e+01,\n",
      "        -7.2495e+00, -1.6763e+01, -1.5762e+01, -1.1387e+01, -1.7019e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-4.4354, -0.5328, -2.0178,  6.9906, -2.6514,  3.8013, -3.6378, -0.7536,\n",
      "         1.5826,  2.0652], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0433], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.4787,  -7.5761,  -9.0611,  -0.0527,  -9.6947,  -3.2420, -10.6810,\n",
      "         -7.7969,  -5.4607,  -4.9781], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.053\n",
      "activated x value: tensor([-7.4705, -6.6283, -6.0589, -2.2639,  5.9976,  0.3289, -5.5562,  7.2781,\n",
      "         4.1341, 10.5908], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6378], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-18.1084, -17.2661, -16.6967, -12.9017,  -4.6402, -10.3089, -16.1941,\n",
      "         -3.3597,  -6.5037,  -0.0470], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.047\n",
      "activated x value: tensor([ -0.9061, -12.3881,   0.8174,   6.5646,  -3.3015,  -0.9945,  -9.3470,\n",
      "         12.7922,   0.5286,   5.0430], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.7946], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3701e+01, -2.5183e+01, -1.1977e+01, -6.2300e+00, -1.6096e+01,\n",
      "        -1.3789e+01, -2.2142e+01, -2.4157e-03, -1.2266e+01, -7.7517e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-7.2209, -1.5394,  1.7716, -1.0404,  5.5206, -1.1285,  4.1651, -7.9162,\n",
      "         3.7108,  2.8034], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.9358], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.1567,  -7.4752,  -4.1642,  -6.9762,  -0.4152,  -7.0643,  -1.7707,\n",
      "        -13.8520,  -2.2250,  -3.1324], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.415\n",
      "activated x value: tensor([ 2.1156, -7.9566, -3.4495,  7.7263, -4.3045,  8.3677, -5.0677, -1.3823,\n",
      "         3.4358,  0.4707], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7970], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.6813, -16.7536, -12.2465,  -1.0707, -13.1015,  -0.4293, -13.8647,\n",
      "        -10.1793,  -5.3611,  -8.3263], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.429\n",
      "activated x value: tensor([-1.7767, -5.4051, -0.6786,  1.2427, -0.8177,  4.4833, -3.1179, -1.2767,\n",
      "         3.8491,  3.4142], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.1404], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9170, -10.5454,  -5.8189,  -3.8977,  -5.9580,  -0.6571,  -8.2583,\n",
      "         -6.4170,  -1.2913,  -1.7262], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.657\n",
      "activated x value: tensor([-3.7047, -4.9391,  1.0873,  3.8242, -2.2323, -1.4203, -7.6042, 10.9043,\n",
      "        -0.1907,  4.4843], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.9068], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4612e+01, -1.5846e+01, -9.8195e+00, -7.0826e+00, -1.3139e+01,\n",
      "        -1.2327e+01, -1.8511e+01, -2.5444e-03, -1.1098e+01, -6.4225e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([  2.2914, -10.5993,  10.9448,   9.6200,  -1.0481,   1.7307,  -2.3266,\n",
      "         -9.6918,   3.9334,  -5.4791], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1815], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.8901, -21.7808,  -0.2367,  -1.5615, -12.2296,  -9.4508, -13.5081,\n",
      "        -20.8733,  -7.2480, -16.6606], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.237\n",
      "activated x value: tensor([-5.2406,  8.0975,  4.4309,  0.2165, -3.3156, -3.0407, -0.3695, -2.5539,\n",
      "         4.1161, -1.8733], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1415], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.3821,  -0.0439,  -3.7106,  -7.9250, -11.4570, -11.1822,  -8.5110,\n",
      "        -10.6953,  -4.0254, -10.0148], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.044\n",
      "activated x value: tensor([-0.9030, -3.3374,  2.2366,  1.0395,  2.4987,  4.5463,  0.4984, -9.7878,\n",
      "         7.4989, -2.7538], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5636], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.4666, -10.9011,  -5.3270,  -6.5241,  -5.0649,  -3.0173,  -7.0653,\n",
      "        -17.3515,  -0.0647, -10.3174], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.065\n",
      "activated x value: tensor([-5.7474, -1.8576, -0.1464,  2.2583, -0.8432,  0.4742, -4.8680,  7.1157,\n",
      "        -0.8289,  4.7650], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.2164], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.9637,  -9.0740,  -7.3628,  -4.9580,  -8.0595,  -6.7422, -12.0844,\n",
      "         -0.1007,  -8.0452,  -2.4514], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.101\n",
      "activated x value: tensor([-1.1240, -7.7556, -2.1457, -2.7102,  2.7340, -1.1497, -4.4578,  7.7209,\n",
      "         1.5735,  7.5419], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3336], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4576, -16.0892, -10.4793, -11.0438,  -5.5996,  -9.4833, -12.7914,\n",
      "         -0.6127,  -6.7601,  -0.7917], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.613\n",
      "activated x value: tensor([ 0.9920, -5.0902,  0.1560, -0.5478, -0.1291,  5.8687,  4.1629, -6.4334,\n",
      "         3.1042, -1.6560], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1000], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.1080, -11.1902,  -5.9440,  -6.6478,  -6.2291,  -0.2313,  -1.9371,\n",
      "        -12.5334,  -2.9958,  -7.7560], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.231\n",
      "activated x value: tensor([ -6.1286,   2.6260,  11.1112,   4.8114,  -3.1365,   0.2933,   2.5243,\n",
      "        -10.5973,   3.8391,  -5.6838], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.1141], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7243e+01, -8.4881e+00, -2.9411e-03, -6.3027e+00, -1.4251e+01,\n",
      "        -1.0821e+01, -8.5898e+00, -2.1711e+01, -7.2751e+00, -1.6798e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([-0.0431, -2.7969, -6.5295, -1.2445, -0.2389,  1.9688, -2.5556,  6.8771,\n",
      "         1.1715,  3.6289], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9276], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.9707,  -9.7245, -13.4571,  -8.1721,  -7.1664,  -4.9588,  -9.4832,\n",
      "         -0.0505,  -5.7561,  -3.2987], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.051\n",
      "activated x value: tensor([-4.4051, -8.4280,  2.3115, -2.4932,  6.5912,  0.9951, 12.4599, -7.6159,\n",
      "         1.6200, -1.0488], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.4628], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6868e+01, -2.0891e+01, -1.0151e+01, -1.4956e+01, -5.8715e+00,\n",
      "        -1.1468e+01, -2.8934e-03, -2.0079e+01, -1.0843e+01, -1.3512e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 4.7469, -6.1084,  1.7744, -2.1263, -2.1400,  0.5192,  5.1696, -2.3953,\n",
      "         2.6969, -1.4607], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.7496], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.0026, -11.8580,  -3.9752,  -7.8759,  -7.8896,  -5.2303,  -0.5799,\n",
      "         -8.1449,  -3.0527,  -7.2103], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.580\n",
      "activated x value: tensor([-1.4823, -6.2138, -8.6200, -2.0281,  1.9130,  0.6860, -2.3517, 10.1592,\n",
      "         2.0562,  5.6176], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1705], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1653e+01, -1.6384e+01, -1.8791e+01, -1.2199e+01, -8.2575e+00,\n",
      "        -9.4844e+00, -1.2522e+01, -1.1252e-02, -8.1143e+00, -4.5528e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([-5.8502,  5.4481, -0.7790,  0.5401, -2.6873,  1.1105, -0.5485,  1.3054,\n",
      "         0.5267,  1.0195], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5067], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3569,  -0.0586,  -6.2857,  -4.9666,  -8.1940,  -4.3962,  -6.0552,\n",
      "         -4.2013,  -4.9800,  -4.4872], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.059\n",
      "activated x value: tensor([-6.7313,  7.0934,  1.6094,  1.4449, -3.5113, -1.7772, -0.3307,  1.6578,\n",
      "         0.4397,  0.7737], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1091], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.8404,  -0.0158,  -5.4997,  -5.6642, -10.6204,  -8.8863,  -7.4398,\n",
      "         -5.4514,  -6.6694,  -6.3354], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-4.1910, -1.4964, -0.5310, -4.1894,  8.1318, -2.5486,  4.4226,  0.6417,\n",
      "        -1.2762,  1.7622], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1586], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.3496,  -9.6550,  -8.6896, -12.3479,  -0.0268, -10.7072,  -3.7360,\n",
      "         -7.5169,  -9.4348,  -6.3964], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.027\n",
      "activated x value: tensor([-7.6423,  7.8474, -0.5428,  0.6760, -2.6303,  1.2851,  0.7418, -1.5825,\n",
      "         2.3770, -0.7395], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8551], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5497e+01, -7.7033e-03, -8.3980e+00, -7.1791e+00, -1.0485e+01,\n",
      "        -6.5701e+00, -7.1133e+00, -9.4376e+00, -5.4781e+00, -8.5947e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-8.7218, -3.5173,  0.6729,  1.1835,  3.2616, -2.4548, -1.4713,  3.2014,\n",
      "         0.1619,  7.2934], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.3317], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.0536, -10.8490,  -6.6589,  -6.1483,  -4.0702,  -9.7866,  -8.8030,\n",
      "         -4.1304,  -7.1698,  -0.0383], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([ 17.2833, -12.3331,  -1.2658,   2.3255,  -8.3235,   8.1353,  -3.2417,\n",
      "         -4.2763,   6.4054,  -3.7674], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([17.2835], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2589e-04, -2.9617e+01, -1.8549e+01, -1.4958e+01, -2.5607e+01,\n",
      "        -9.1481e+00, -2.0525e+01, -2.1560e+01, -1.0878e+01, -2.1051e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-4.6691, -0.9166, -0.5980,  2.0919, -1.9288, -1.2969, -7.0751, 10.4360,\n",
      "         0.2247,  4.1778], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.4382], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5107e+01, -1.1355e+01, -1.1036e+01, -8.3463e+00, -1.2367e+01,\n",
      "        -1.1735e+01, -1.7513e+01, -2.2268e-03, -1.0214e+01, -6.2604e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([ 1.1905, -6.6158,  6.6747, -0.4166, -2.4791,  0.2085, -0.7499, -1.5221,\n",
      "         3.4224, -0.6175], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7205], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.5299, -13.3363,  -0.0458,  -7.1371,  -9.1996,  -6.5120,  -7.4704,\n",
      "         -8.2426,  -3.2981,  -7.3379], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.046\n",
      "activated x value: tensor([-7.2135, -2.2826, -3.0066,  1.0154,  4.3720, -1.4956, -1.9744,  0.2292,\n",
      "         2.6580,  7.0055], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0906], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.3041,  -9.3732, -10.0972,  -6.0752,  -2.7186,  -8.5863,  -9.0651,\n",
      "         -6.8614,  -4.4326,  -0.0851], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.085\n",
      "activated x value: tensor([-8.5376, -1.8010, -3.0721, -1.1670,  5.0952,  4.8637, -0.6388, -0.1550,\n",
      "         5.9110, -1.6261], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4982], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-15.0357,  -8.2991,  -9.5703,  -7.6652,  -1.4030,  -1.6345,  -7.1369,\n",
      "         -6.6531,  -0.5871,  -8.1243], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.587\n",
      "activated x value: tensor([-9.1952,  9.6842, -0.4318,  3.4965, -3.7705, -0.3191, -0.6955, -0.1342,\n",
      "         0.9103,  0.8814], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6867], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8882e+01, -2.5291e-03, -1.0119e+01, -6.1902e+00, -1.3457e+01,\n",
      "        -1.0006e+01, -1.0382e+01, -9.8209e+00, -8.7765e+00, -8.8053e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 0.8168, -5.6190,  8.6992,  6.4816, -3.9621, -1.0597, -0.8096, -0.8990,\n",
      "        -1.3574, -3.1911], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8031], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9864, -14.4222,  -0.1039,  -2.3215, -12.7652,  -9.8628,  -9.6127,\n",
      "         -9.7021, -10.1605, -11.9942], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.104\n",
      "activated x value: tensor([-2.8905, -4.5830,  2.3625, -0.7742,  7.5828, -5.6399,  1.0647,  1.2424,\n",
      "        -1.3309,  3.1090], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6030], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.4935, -12.1860,  -5.2406,  -8.3772,  -0.0202, -13.2429,  -6.5383,\n",
      "         -6.3606,  -8.9339,  -4.4940], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([  4.7005, -11.5586,  -5.2764,   5.8138,  -6.5434,   2.3218,  -7.7866,\n",
      "         15.9024,   2.1361,   1.8350], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.9024], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.1202e+01, -2.7461e+01, -2.1179e+01, -1.0089e+01, -2.2446e+01,\n",
      "        -1.3581e+01, -2.3689e+01, -5.8174e-05, -1.3766e+01, -1.4067e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-0.8269, -0.7861,  2.1106,  5.7744, -2.5123,  2.9984, -2.5785, -2.2819,\n",
      "         0.6743, -3.4049], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8676], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6945, -6.6537, -3.7570, -0.0932, -8.3800, -2.8692, -8.4461, -8.1495,\n",
      "        -5.1934, -9.2725], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.093\n",
      "activated x value: tensor([-0.3796,  3.6943,  6.1897,  2.6453, -6.8381, -1.7485,  0.5878, -7.9953,\n",
      "         7.2459, -3.6304], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5740], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9536,  -3.8797,  -1.3843,  -4.9287, -14.4121,  -9.3226,  -6.9862,\n",
      "        -15.5694,  -0.3282, -11.2045], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -1.384\n",
      "activated x value: tensor([-2.5759, -8.9452, -1.1853,  4.0404, -2.0642,  8.2794, -4.0815, -1.2715,\n",
      "         4.4459,  3.4566], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3227], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.8986, -17.2680,  -9.5081,  -4.2824, -10.3869,  -0.0434, -12.4042,\n",
      "         -9.5942,  -3.8768,  -4.8661], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.043\n",
      "activated x value: tensor([ -0.9823, -10.5882,  -1.8821,  -2.5306,   1.6949,   2.1221,  -4.2306,\n",
      "          2.4265,   7.5417,   7.0216], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0168], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.9990, -18.6050,  -9.8989, -10.5473,  -6.3219,  -5.8947, -12.2474,\n",
      "         -5.5903,  -0.4751,  -0.9951], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.475\n",
      "activated x value: tensor([-4.4120,  2.8054,  1.5844, -1.6882, -0.1924,  0.5995, -0.7227, -0.0939,\n",
      "         1.4209, -0.1429], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([3.4229], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8349, -0.6175, -1.8384, -5.1111, -3.6153, -2.8234, -4.1456, -3.5167,\n",
      "        -2.0019, -3.5658], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.002\n",
      "activated x value: tensor([ 19.8322, -13.8868,   1.6979,  -0.7719, -13.7302,   8.5990,  -0.5052,\n",
      "         -2.6085,   6.5938,  -4.6830], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([19.8322], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.5259e-05, -3.3719e+01, -1.8134e+01, -2.0604e+01, -3.3562e+01,\n",
      "        -1.1233e+01, -2.0337e+01, -2.2441e+01, -1.3238e+01, -2.4515e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-4.3564, -3.9321, -3.1832, -0.9122,  5.1511,  1.4105, -2.2049,  2.1063,\n",
      "         1.0531,  4.2486], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5545], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.9109, -9.4866, -8.7377, -6.4666, -0.4034, -4.1440, -7.7594, -3.4481,\n",
      "        -4.5014, -1.3059], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.403\n",
      "activated x value: tensor([-0.2970, -2.8545,  0.0388,  3.0361,  1.6747,  3.2972, -0.9381, -5.6816,\n",
      "         2.2436, -0.6391], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1803], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.4773, -7.0349, -4.1415, -1.1442, -2.5056, -0.8831, -5.1185, -9.8619,\n",
      "        -1.9367, -4.8194], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -1.937\n",
      "activated x value: tensor([-3.0639, -2.8527,  4.5299, -0.0683,  0.1186,  3.4685, -2.1879, -8.5666,\n",
      "        10.7613, -3.0198], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.7640], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3828e+01, -1.3617e+01, -6.2340e+00, -1.0832e+01, -1.0645e+01,\n",
      "        -7.2955e+00, -1.2952e+01, -1.9331e+01, -2.6932e-03, -1.3784e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([  3.2713, -10.9637,  -0.1452,   4.6772,   2.6457,   4.4116,  -3.8782,\n",
      "         -6.6609,   6.5191,  -0.5709], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8131], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.5419, -17.7768,  -6.9583,  -2.1359,  -4.1674,  -2.4015, -10.6913,\n",
      "        -13.4740,  -0.2941,  -7.3840], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.294\n",
      "activated x value: tensor([-2.8507, -8.2600, -3.5454, -2.5072,  3.1510,  4.7473, -4.6943,  2.3160,\n",
      "         8.8266,  1.7127], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8490], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.6997, -17.1090, -12.3944, -11.3562,  -5.6979,  -4.1017, -13.5433,\n",
      "         -6.5329,  -0.0224,  -7.1362], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.022\n",
      "activated x value: tensor([ 2.6256, -6.5132, -4.3533,  7.9035, -5.7380,  7.6738, -4.1327, -2.9036,\n",
      "         4.2788,  1.2703], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.5066], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.8810, -15.0198, -12.8599,  -0.6032, -14.2447,  -0.8328, -12.6393,\n",
      "        -11.4102,  -4.2278,  -7.2364], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.833\n",
      "activated x value: tensor([-1.2282, -5.2912, -0.0220,  4.8266, -0.1953,  5.9749, -2.0071, -5.3691,\n",
      "         2.9824,  0.8364], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2962], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5244, -11.5874,  -6.3182,  -1.4696,  -6.4915,  -0.3213,  -8.3033,\n",
      "        -11.6653,  -3.3138,  -5.4598], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.470\n",
      "activated x value: tensor([ 0.7249, -7.7543,  6.7229, -2.2396,  1.2030, -2.6284, 12.8707, -4.4972,\n",
      "        -1.4226, -3.7633], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.8729], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2148e+01, -2.0627e+01, -6.1499e+00, -1.5112e+01, -1.1670e+01,\n",
      "        -1.5501e+01, -2.1505e-03, -1.7370e+01, -1.4295e+01, -1.6636e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.002\n",
      "activated x value: tensor([-1.2784,  0.2402, -1.7715,  3.9294, -3.0685,  3.8316, -3.1310, -0.1384,\n",
      "         0.8836,  0.6812], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.6452], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.9236, -4.4051, -6.4168, -0.7158, -7.7137, -0.8137, -7.7762, -4.7837,\n",
      "        -3.7616, -3.9640], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.814\n",
      "activated x value: tensor([-8.4473, -5.9108, -4.0420,  5.9166,  4.0733,  0.3080, -7.1574,  5.0929,\n",
      "         1.9062,  7.5775], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8457], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.2930, -13.7565, -11.8877,  -1.9290,  -3.7724,  -7.5377, -15.0031,\n",
      "         -2.7527,  -5.9395,  -0.2682], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.268\n",
      "activated x value: tensor([-3.8082, -2.4148,  1.9417, 12.3801, -4.8942, -0.1208, -5.7253,  3.5001,\n",
      "        -0.2742, -1.1536], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.3803], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-1.6189e+01, -1.4795e+01, -1.0439e+01, -1.7738e-04, -1.7275e+01,\n",
      "        -1.2501e+01, -1.8106e+01, -8.8802e+00, -1.2655e+01, -1.3534e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-1.3567, -6.0074,  2.5548,  1.6741,  0.7824, -2.9686, -6.9518, 11.2224,\n",
      "        -1.0995,  1.1440], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2227], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2579e+01, -1.7230e+01, -8.6679e+00, -9.5486e+00, -1.0440e+01,\n",
      "        -1.4191e+01, -1.8174e+01, -3.2330e-04, -1.2322e+01, -1.0079e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-2.3499, -3.9156, -1.1517, -0.6370,  0.5083, -0.0655, -4.3061,  6.9954,\n",
      "         0.6781,  4.4288], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0741], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.4241, -10.9898,  -8.2259,  -7.7111,  -6.5658,  -7.1396, -11.3803,\n",
      "         -0.0787,  -6.3961,  -2.6453], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.079\n",
      "activated x value: tensor([ 1.3184, -7.8527,  5.2164, -0.0197,  0.5673,  5.2683,  6.3229, -8.0603,\n",
      "         1.3147, -3.5568], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.8520], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.5336, -14.7047,  -1.6357,  -6.8717,  -6.2847,  -1.5837,  -0.5291,\n",
      "        -14.9123,  -5.5373, -10.4088], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -1.584\n",
      "activated x value: tensor([ 12.1118, -14.4912,   2.5942,  -0.7404,  -5.0967,   4.2219,  -2.0346,\n",
      "         -1.5493,   6.0371,  -0.1675], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.1146], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.7542e-03, -2.6606e+01, -9.5203e+00, -1.2855e+01, -1.7211e+01,\n",
      "        -7.8926e+00, -1.4149e+01, -1.3664e+01, -6.0774e+00, -1.2282e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ 2.6612, -7.9200,  0.2573,  4.5359, -1.8719,  9.0133,  0.5793, -9.1814,\n",
      "         2.9197, -1.5454], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0289], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.3678e+00, -1.6949e+01, -8.7716e+00, -4.4930e+00, -1.0901e+01,\n",
      "        -1.5659e-02, -8.4497e+00, -1.8210e+01, -6.1093e+00, -1.0574e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-2.1717, -9.8188, -3.2304,  1.9904,  1.3433,  1.4951, -5.7269, 11.8446,\n",
      "        -0.8762,  4.5515], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.8454], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4017e+01, -2.1664e+01, -1.5076e+01, -9.8550e+00, -1.0502e+01,\n",
      "        -1.0350e+01, -1.7572e+01, -7.9632e-04, -1.2722e+01, -7.2938e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([  0.6963, -15.0991,   4.0383,  -3.6950,   9.1712,   0.0178,   3.8355,\n",
      "         -1.4946,   1.1125,  -0.5245], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.1826], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.4863e+00, -2.4282e+01, -5.1443e+00, -1.2878e+01, -1.1370e-02,\n",
      "        -9.1647e+00, -5.3470e+00, -1.0677e+01, -8.0700e+00, -9.7071e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([ 2.0756, -3.2812,  1.0560,  4.2370, -9.3196,  6.3298, -8.1084, -1.4544,\n",
      "         8.2743,  0.2629], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.4260], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -6.3505, -11.7073,  -7.3700,  -4.1890, -17.7457,  -2.0962, -16.5344,\n",
      "         -9.8805,  -0.1518,  -8.1631], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.152\n",
      "activated x value: tensor([-10.4431,  -0.6673,   2.7791,   6.7133,  -3.7717,  -0.4016,  -7.0717,\n",
      "          7.2912,   2.1314,   3.7504], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7659], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-18.2090,  -8.4332,  -4.9868,  -1.0526, -11.5376,  -8.1675, -14.8376,\n",
      "         -0.4747,  -5.6345,  -4.0155], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -1.053\n",
      "activated x value: tensor([ 7.6158, -7.4556,  8.2738,  2.6700, -7.7689,  3.0161, -0.4780, -3.1779,\n",
      "         2.9066, -5.9065], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7001], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.0843, -16.1557,  -0.4263,  -6.0301, -16.4690,  -5.6840,  -9.1781,\n",
      "        -11.8780,  -5.7935, -14.6065], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -1.084\n",
      "activated x value: tensor([-6.6337,  0.1498,  2.6705,  1.4421,  1.7185, -3.4251, -0.7288,  5.1494,\n",
      "        -0.8450,  1.3452], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3109], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.9446,  -5.1610,  -2.6404,  -3.8687,  -3.5923,  -8.7360,  -6.0397,\n",
      "         -0.1615,  -6.1559,  -3.9657], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.161\n",
      "activated x value: tensor([-5.5631,  1.7043, -3.4198,  2.4044,  4.9077, -3.1748, -0.4162, -1.9029,\n",
      "         1.5284,  4.4829], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5049], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.0680,  -3.8005,  -8.9247,  -3.1005,  -0.5972,  -8.6797,  -5.9210,\n",
      "         -7.4078,  -3.9765,  -1.0220], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.597\n",
      "activated x value: tensor([-5.3148,  6.4177,  0.5037,  2.0359, -5.4623,  1.3047, -1.0203, -0.5344,\n",
      "         2.5068,  0.5887], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4625], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.7772,  -0.0447,  -5.9587,  -4.4265, -11.9248,  -5.1577,  -7.4827,\n",
      "         -6.9969,  -3.9556,  -5.8737], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.045\n",
      "activated x value: tensor([-6.4305, -8.3711,  1.6835, -1.6290, 13.7696, -4.5758,  3.1036, -1.1887,\n",
      "        -0.1423,  3.5880], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.7697], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0200e+01, -2.2141e+01, -1.2086e+01, -1.5399e+01, -6.8665e-05,\n",
      "        -1.8346e+01, -1.0666e+01, -1.4958e+01, -1.3912e+01, -1.0182e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([  4.8569,  -4.4919,   4.6462,   9.3565, -10.0388,   7.5794,  -4.3895,\n",
      "         -5.4725,   5.5112,  -7.9605], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.5476], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.6907, -14.0395,  -4.9015,  -0.1911, -19.5864,  -1.9682, -13.9371,\n",
      "        -15.0201,  -4.0365, -17.5082], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.191\n",
      "activated x value: tensor([ -3.4406,  -1.1964,   2.4796,   2.8737,  -1.6474,   7.2911,   7.0380,\n",
      "        -11.0870,   4.4671,  -6.5629], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9097], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3504,  -9.1062,  -5.4302,  -5.0360,  -9.5571,  -0.6186,  -0.8717,\n",
      "        -18.9967,  -3.4426, -14.4726], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.619\n",
      "activated x value: tensor([-7.8021, -7.3742, -0.1623,  0.8755, 12.3485, -3.7971, -3.1729, -1.7289,\n",
      "         4.2099,  7.5321], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.3569], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0159e+01, -1.9731e+01, -1.2519e+01, -1.1481e+01, -8.3675e-03,\n",
      "        -1.6154e+01, -1.5530e+01, -1.4086e+01, -8.1470e+00, -4.8248e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.008\n",
      "activated x value: tensor([-0.7490,  1.1495,  2.4402,  7.7336, -8.3604,  1.9459, -0.5244,  0.0714,\n",
      "        -0.6346, -3.0634], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.7442], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.4932e+00, -6.5947e+00, -5.3040e+00, -1.0604e-02, -1.6105e+01,\n",
      "        -5.7983e+00, -8.2686e+00, -7.6728e+00, -8.3788e+00, -1.0808e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.011\n",
      "activated x value: tensor([ 3.5684, -3.4478,  8.2506,  7.6252, -8.0981,  3.7932, -1.6906, -9.4818,\n",
      "         4.9106, -6.4732], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.7153], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.1469, -12.1631,  -0.4646,  -1.0900, -16.8133,  -4.9221, -10.4059,\n",
      "        -18.1971,  -3.8046, -15.1884], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.465\n",
      "activated x value: tensor([-1.1734, -5.6449,  0.5804,  0.5543,  2.4581,  5.5500,  5.7360, -7.5296,\n",
      "         1.7154, -2.6779], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3771], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5505, -12.0220,  -5.7967,  -5.8228,  -3.9190,  -0.8271,  -0.6411,\n",
      "        -13.9067,  -4.6617,  -9.0550], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.827\n",
      "activated x value: tensor([-7.7446,  5.8485,  1.4478,  2.3656, -2.4226,  3.5383, -1.7250, -6.1119,\n",
      "         4.1372,  0.4369], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1323], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.8769,  -0.2837,  -4.6845,  -3.7667,  -8.5549,  -2.5940,  -7.8572,\n",
      "        -12.2441,  -1.9950,  -5.6954], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.284\n",
      "activated x value: tensor([-10.7615,   9.7850,   0.1857,   3.8159,  -3.8519,  -1.6119,  -2.2166,\n",
      "          1.3019,   1.5545,   2.6619], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.7889], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-2.0550e+01, -3.9148e-03, -9.6032e+00, -5.9729e+00, -1.3641e+01,\n",
      "        -1.1401e+01, -1.2006e+01, -8.4870e+00, -8.2344e+00, -7.1270e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-1.0805, -6.1712, -1.3906,  3.2577,  2.6812,  6.4586,  2.3444, -6.4760,\n",
      "         3.4530, -3.6540], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exponential summation value: tensor([6.5812], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.6617, -12.7524,  -7.9718,  -3.3236,  -3.9000,  -0.1226,  -4.2369,\n",
      "        -13.0573,  -3.1282, -10.2352], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.123\n",
      "activated x value: tensor([-5.0770, -1.3260, -3.8941,  1.5790,  2.9846,  0.3754, -3.6060,  2.6274,\n",
      "         0.1725,  6.3045], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3775], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.4545,  -7.7035, -10.2716,  -4.7986,  -3.3929,  -6.0021,  -9.9835,\n",
      "         -3.7502,  -6.2050,  -0.0730], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.073\n",
      "activated x value: tensor([-7.6277,  0.6913, -2.8726,  1.3601,  2.1637,  3.3650,  0.9050, -4.7764,\n",
      "         4.5029,  2.4982], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0006], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.6284,  -4.3093,  -7.8732,  -3.6405,  -2.8369,  -1.6357,  -4.0956,\n",
      "         -9.7771,  -0.4977,  -2.5024], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.498\n",
      "activated x value: tensor([-8.0382, -0.9503, -2.4815,  1.6199,  2.7034,  0.9617, -3.3014,  1.2880,\n",
      "         1.8719,  6.3093], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3680], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.4062,  -7.3183,  -8.8495,  -4.7481,  -3.6646,  -5.4063,  -9.6694,\n",
      "         -5.0800,  -4.4961,  -0.0587], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.059\n",
      "activated x value: tensor([-3.1782, -8.0108, -0.9495, -3.0342,  7.5057, -2.1481,  0.9495,  1.0544,\n",
      "         2.2109,  4.9258], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5864], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.7646, -15.5973,  -8.5359, -10.6206,  -0.0808,  -9.7346,  -6.6369,\n",
      "         -6.5320,  -5.3755,  -2.6606], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.081\n",
      "activated x value: tensor([-3.6266, -6.4309,  4.9430, -2.6308,  2.5711,  3.3549,  8.7767, -4.0402,\n",
      "        -0.8219, -2.2171], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8044], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.4310, -15.2353,  -3.8614, -11.4353,  -6.2334,  -5.4495,  -0.0278,\n",
      "        -12.8447,  -9.6264, -11.0215], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.028\n",
      "activated x value: tensor([-2.1558, -4.7584, -1.3549,  9.4314, -4.4330,  5.2237, -8.1758, -0.7467,\n",
      "         3.6308,  3.3591], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4514], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.6072, -14.2098, -10.8063,  -0.0201, -13.8844,  -4.2277, -17.6272,\n",
      "        -10.1982,  -5.8206,  -6.0923], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.020\n",
      "activated x value: tensor([ -7.4851, -11.4735,   3.8198,  -2.6306,  11.1409,  -8.7598,   8.8781,\n",
      "          2.2480,   0.4768,   3.0381], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2409], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-18.7260, -22.7144,  -7.4211, -13.8716,  -0.1000, -20.0008,  -2.3628,\n",
      "         -8.9929, -10.7641,  -8.2028], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -2.363\n",
      "activated x value: tensor([-3.4262, -9.0694, -6.8805,  3.0472, -0.3100,  2.3005, -6.7802,  9.0642,\n",
      "         2.9101,  8.3062], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.4524], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.8786, -18.5218, -16.3330,  -6.4053,  -9.7624,  -7.1519, -16.2327,\n",
      "         -0.3883,  -6.5424,  -1.1462], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.146\n",
      "activated x value: tensor([ 15.2843, -14.7245,   3.1885,   5.9963, -12.0528,  10.1876,  -6.8468,\n",
      "         -2.3319,   7.5607,  -6.2484], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.2909], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.6357e-03, -3.0015e+01, -1.2102e+01, -9.2945e+00, -2.7344e+01,\n",
      "        -5.1033e+00, -2.2138e+01, -1.7623e+01, -7.7302e+00, -2.1539e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([-2.3382, -3.7655, 15.3972,  4.2388, -3.2533, -1.2800,  3.3161, -9.8834,\n",
      "         2.3456, -5.5921], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.3972], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7735e+01, -1.9163e+01, -2.1935e-05, -1.1158e+01, -1.8650e+01,\n",
      "        -1.6677e+01, -1.2081e+01, -2.5281e+01, -1.3052e+01, -2.0989e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([ -1.5985, -11.1406,  -1.0343,  -2.0387,   2.9318,  -1.5125,  -2.8284,\n",
      "          6.0466,   1.7225,   8.9563], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0125], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.6110, -20.1530, -10.0468, -11.0512,  -6.0807, -10.5250, -11.8409,\n",
      "         -2.9659,  -7.2900,  -0.0561], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.056\n",
      "activated x value: tensor([ 2.5696, -1.3471,  1.8139,  7.5335, -5.5188,  3.1253, -5.6537, -1.1167,\n",
      "         1.6846, -2.1047], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.5589], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.9892,  -8.9059,  -5.7450,  -0.0254, -13.0777,  -4.4336, -13.2126,\n",
      "         -8.6756,  -5.8743,  -9.6635], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.025\n",
      "activated x value: tensor([11.6187, -9.3781,  3.3261,  6.0624, -7.0466,  4.2229, -4.2563, -0.6620,\n",
      "        -0.0654, -2.9694], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.6234], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.7302e-03, -2.1002e+01, -8.2973e+00, -5.5610e+00, -1.8670e+01,\n",
      "        -7.4006e+00, -1.5880e+01, -1.2285e+01, -1.1689e+01, -1.4593e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.005\n",
      "activated x value: tensor([-4.6044, -2.3588,  0.1902, -0.1561,  4.4665, -1.5441,  0.2662, -1.3229,\n",
      "         0.2999,  3.7999], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.9204], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.5247, -7.2792, -4.7301, -5.0765, -0.4539, -6.4645, -4.6542, -6.2433,\n",
      "        -4.6205, -1.1205], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -1.120\n",
      "activated x value: tensor([-7.5401, -0.6300, -3.6373,  4.9595,  0.7136,  0.8092, -3.9492, -0.5121,\n",
      "         4.1151,  5.7198], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.2424], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.7825,  -6.8724,  -9.8797,  -1.2829,  -5.5288,  -5.4332, -10.1916,\n",
      "         -6.7545,  -2.1273,  -0.5226], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.523\n",
      "activated x value: tensor([ 11.8688, -13.7246,   0.3298,   1.5550,  -6.3056,   5.1630,  -4.7369,\n",
      "         -1.5642,   5.8538,   1.6323], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.8725], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.7394e-03, -2.5597e+01, -1.1543e+01, -1.0317e+01, -1.8178e+01,\n",
      "        -6.7095e+00, -1.6609e+01, -1.3437e+01, -6.0187e+00, -1.0240e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-6.8889,  0.1534,  4.2745,  4.0449, -4.7122, -5.6476, -6.0537,  7.8881,\n",
      "         1.2569,  5.7176], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0402], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.9291,  -7.8868,  -3.7657,  -3.9953, -12.7524, -13.6878, -14.0939,\n",
      "         -0.1521,  -6.7833,  -2.3226], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.152\n",
      "activated x value: tensor([-1.7380, -6.9315,  0.9097,  0.6151,  1.1098,  0.1793, -3.1666,  1.2669,\n",
      "         5.7615,  1.1272], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.8089], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.5468, -12.7404,  -4.8992,  -5.1938,  -4.6991,  -5.6296,  -8.9755,\n",
      "         -4.5420,  -0.0474,  -4.6817], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.047\n",
      "activated x value: tensor([  6.3372, -11.7416,   1.6040,   1.1687,  -2.3459,   3.0482,  -4.2771,\n",
      "          0.6956,   2.1829,   2.5986], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.4280], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0908, -18.1696,  -4.8240,  -5.2593,  -8.7739,  -3.3798, -10.7051,\n",
      "         -5.7324,  -4.2451,  -3.8294], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.091\n",
      "activated x value: tensor([-6.1415, -1.4389,  4.6088,  7.8009, -3.8775,  3.4975, -4.1966, -2.6248,\n",
      "         3.3955, -0.8377], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8659], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.0074,  -9.3048,  -3.2571,  -0.0650, -11.7433,  -4.3684, -12.0624,\n",
      "        -10.4907,  -4.4704,  -8.7036], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.065\n",
      "activated x value: tensor([-2.7075, -4.2554,  2.3475, -3.8229,  3.2263, -3.2912, 11.2454, -0.3984,\n",
      "        -0.8390, -0.5795], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([11.2459], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.3953e+01, -1.5501e+01, -8.8985e+00, -1.5069e+01, -8.0196e+00,\n",
      "        -1.4537e+01, -4.8923e-04, -1.1644e+01, -1.2085e+01, -1.1825e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-8.2661, -0.8531, -1.9164,  1.6279,  5.4327,  0.8630, -1.5452, -1.3800,\n",
      "         0.7259,  3.5585], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.6148], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.8809,  -6.4679,  -7.5312,  -3.9869,  -0.1820,  -4.7518,  -7.1600,\n",
      "         -6.9948,  -4.8889,  -2.0563], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -2.056\n",
      "activated x value: tensor([ 1.4452, -8.5708,  8.9744,  2.4720,  2.8180,  3.8031,  3.0921, -9.8679,\n",
      "         0.7841, -5.6325], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9872], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.5420e+00, -1.7558e+01, -1.2817e-02, -6.5153e+00, -6.1693e+00,\n",
      "        -5.1841e+00, -5.8952e+00, -1.8855e+01, -8.2032e+00, -1.4620e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([-3.7382, -4.3126, 10.1454,  5.7480, -3.0055, -4.3926,  5.5468, -0.6031,\n",
      "        -1.4545, -3.2658], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.1675], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-13.9057, -14.4802,  -0.0222,  -4.4195, -13.1731, -14.5601,  -4.6207,\n",
      "        -10.7707, -11.6221, -13.4333], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-7.7894,  0.1990,  3.2474,  3.5023, -0.4742, -1.3787,  0.7091, -4.1167,\n",
      "         6.6961,  0.1594], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7725], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.5620,  -6.5735,  -3.5251,  -3.2702,  -7.2467,  -8.1512,  -6.0634,\n",
      "        -10.8892,  -0.0764,  -6.6131], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.076\n",
      "activated x value: tensor([-5.4519,  0.5394,  1.5497,  6.2604, -3.2970,  0.2130, -6.6054,  0.6198,\n",
      "         3.4821,  2.2797], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3549], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.8068,  -5.8155,  -4.8051,  -0.0945,  -9.6519,  -6.1418, -12.9603,\n",
      "         -5.7351,  -2.8728,  -4.0752], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.094\n",
      "activated x value: tensor([ -4.3547,   5.7420,  13.1875,   7.2906, -10.4622,   0.1360,   2.4845,\n",
      "         -8.7648,   4.5435,  -9.4373], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.1910], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7546e+01, -7.4490e+00, -3.5267e-03, -5.9003e+00, -2.3653e+01,\n",
      "        -1.3055e+01, -1.0706e+01, -2.1956e+01, -8.6475e+00, -2.2628e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.004\n",
      "activated x value: tensor([-1.0471, -4.8711, -0.8287,  4.9938, -6.7391,  5.6283, -5.7233,  2.7713,\n",
      "         3.5198,  1.3822], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.1743], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.2214, -11.0454,  -7.0029,  -1.1805, -12.9134,  -0.5459, -11.8976,\n",
      "         -3.4029,  -2.6545,  -4.7920], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.546\n",
      "activated x value: tensor([-6.2851e+00, -3.9169e+00, -1.1269e+00,  1.2714e+00,  4.5105e+00,\n",
      "         1.2909e-01, -2.0346e-02, -6.2616e-01, -5.6849e-03,  6.1275e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3222], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.6073, -10.2391,  -7.4491,  -5.0508,  -1.8117,  -6.1931,  -6.3425,\n",
      "         -6.9484,  -6.3279,  -0.1947], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.195\n",
      "activated x value: tensor([ 0.6000, -0.2111, -1.5748,  7.9331, -3.8446,  4.7613, -5.6176, -2.2579,\n",
      "         3.3608, -3.9933], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9851], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.3851,  -8.1962,  -9.5599,  -0.0520, -11.8297,  -3.2238, -13.6027,\n",
      "        -10.2430,  -4.6243, -11.9784], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.052\n",
      "activated x value: tensor([-4.2110,  1.1158,  7.0498,  4.5076, -8.1839, -1.7001,  2.0158,  0.2265,\n",
      "         1.0997, -2.2800], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.1377], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-11.3487,  -6.0219,  -0.0878,  -2.6300, -15.3216,  -8.8378,  -5.1219,\n",
      "         -6.9112,  -6.0379,  -9.4177], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.088\n",
      "activated x value: tensor([-3.5516, -1.0481,  2.6372, -0.3830,  1.1244,  0.7659,  3.9793, -4.6236,\n",
      "        -0.1897,  0.6507], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3373], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.8889, -5.3853, -1.7001, -4.7202, -3.2129, -3.5714, -0.3580, -8.9608,\n",
      "        -4.5269, -3.6866], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -3.213\n",
      "activated x value: tensor([-1.4459, -3.1497, -3.6624,  1.3541,  3.3256,  0.6045, -4.0131,  3.2630,\n",
      "        -1.3832,  5.0364], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.3666], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-6.8125, -8.5163, -9.0290, -4.0125, -2.0410, -4.7621, -9.3797, -2.1036,\n",
      "        -6.7499, -0.3302], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.330\n",
      "activated x value: tensor([ 1.0533, -3.7909,  2.2235, -0.0772,  2.0962,  4.8065,  4.6974, -8.3733,\n",
      "         1.0878, -3.2944], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5458], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.4925,  -9.3366,  -3.3223,  -5.6230,  -3.4495,  -0.7393,  -0.8484,\n",
      "        -13.9190,  -4.4580,  -8.8402], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.739\n",
      "activated x value: tensor([-2.6615, -5.2022, -0.3037, -0.3861,  1.0544,  1.0078, -1.9126,  4.7171,\n",
      "        -0.4816,  4.2453], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.2443], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.9058, -10.4465,  -5.5480,  -5.6305,  -4.1900,  -4.2365,  -7.1569,\n",
      "         -0.5273,  -5.7259,  -0.9990], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.527\n",
      "activated x value: tensor([-5.5951e+00, -6.9749e+00,  1.1573e-02,  4.3643e+00, -2.2868e-01,\n",
      "        -3.3215e+00, -9.3396e+00,  1.3297e+01,  1.5398e+00,  6.0909e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.2974], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8893e+01, -2.0272e+01, -1.3286e+01, -8.9332e+00, -1.3526e+01,\n",
      "        -1.6619e+01, -2.2637e+01, -8.8501e-04, -1.1758e+01, -7.2065e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.8853, -0.1203,  0.6064,  0.7634, -2.3194,  3.7915,  2.4546, -2.8983,\n",
      "         1.3337, -1.4966], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.1753], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.0607, -4.2957, -3.5689, -3.4119, -6.4947, -0.3838, -1.7207, -7.0736,\n",
      "        -2.8416, -5.6719], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.384\n",
      "activated x value: tensor([-7.9641,  6.9558,  0.3687,  0.8852, -1.2202, -1.0064, -0.5612,  1.6473,\n",
      "         0.6660,  0.7747], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.9695], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4934e+01, -1.3640e-02, -6.6008e+00, -6.0843e+00, -8.1897e+00,\n",
      "        -7.9758e+00, -7.5307e+00, -5.3222e+00, -6.3035e+00, -6.1948e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([-1.5160, -3.0992, -2.7377,  6.4304, -2.3668,  4.7680, -5.3568, -0.8094,\n",
      "         2.3278,  3.1010], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6483], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.1642,  -9.7474,  -9.3860,  -0.2179,  -9.0150,  -1.8803, -12.0050,\n",
      "         -7.4577,  -4.3205,  -3.5473], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.218\n",
      "activated x value: tensor([ 5.5797, -6.9668, -2.3511,  2.7723, -4.0486,  4.4089, -3.7213, -0.7807,\n",
      "         3.1136,  3.1379], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.0145], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.4348, -12.9813,  -8.3656,  -3.2422, -10.0631,  -1.6056,  -9.7358,\n",
      "         -6.7952,  -2.9009,  -2.8766], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.435\n",
      "activated x value: tensor([ 15.3285, -13.6325,   0.4341,   3.2525,  -7.6316,   7.6573, -10.7640,\n",
      "          0.4634,   6.0572,   0.0346], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([15.3291], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-5.6648e-04, -2.8962e+01, -1.4895e+01, -1.2077e+01, -2.2961e+01,\n",
      "        -7.6718e+00, -2.6093e+01, -1.4866e+01, -9.2719e+00, -1.5295e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([10.2056, -9.2118,  1.8924,  1.6994, -4.4868,  3.3043, -2.5721, -2.5747,\n",
      "         3.7829, -1.6130], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.2087], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-3.0870e-03, -1.9421e+01, -8.3163e+00, -8.5093e+00, -1.4695e+01,\n",
      "        -6.9045e+00, -1.2781e+01, -1.2783e+01, -6.4258e+00, -1.1822e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.003\n",
      "activated x value: tensor([ -1.3210, -12.3853,  -6.7081,  -0.5168,   8.3200,   0.7404,   1.8720,\n",
      "          3.2207,   0.7922,   5.5999], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.3921], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7131, -20.7774, -15.1002,  -8.9089,  -0.0721,  -7.6517,  -6.5201,\n",
      "         -5.1714,  -7.5999,  -2.7922], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.072\n",
      "activated x value: tensor([-3.8466, -4.7185, -0.4822, -0.3942,  6.6912, -0.6061, -1.1328,  1.0626,\n",
      "        -0.0412,  3.2316], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7294], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-10.5760, -11.4479,  -7.2116,  -7.1236,  -0.0382,  -7.3354,  -7.8622,\n",
      "         -5.6667,  -6.7706,  -3.4978], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.038\n",
      "activated x value: tensor([-0.1058, -3.1160,  2.3255,  0.2881, -0.9011,  2.5375,  8.0740, -7.9693,\n",
      "         1.5462, -2.3271], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0834], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.1893e+00, -1.1199e+01, -5.7580e+00, -7.7953e+00, -8.9846e+00,\n",
      "        -5.5459e+00, -9.4118e-03, -1.6053e+01, -6.5373e+00, -1.0411e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.009\n",
      "activated x value: tensor([-2.1656,  2.7939,  2.7116,  7.5706, -6.3940,  3.8435, -1.0413, -5.5940,\n",
      "         3.2963, -4.3097], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.6236], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.7892,  -4.8297,  -4.9120,  -0.0530, -14.0176,  -3.7802,  -8.6650,\n",
      "        -13.2176,  -4.3273, -11.9333], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.053\n",
      "activated x value: tensor([ 1.3798, -4.1489,  4.0564,  5.3576, -6.6983,  5.7411,  2.1739, -9.2427,\n",
      "         4.4444, -3.5350], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5211], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -5.1413, -10.6700,  -2.4647,  -1.1635, -13.2195,  -0.7801,  -4.3473,\n",
      "        -15.7638,  -2.0767, -10.0561], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -2.077\n",
      "activated x value: tensor([-2.7853, -6.2976,  0.3611, -0.3556,  5.5003,  0.6765,  0.6222,  0.0850,\n",
      "        -0.0270,  2.4354], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.5770], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.3624, -11.8746,  -5.2159,  -5.9326,  -0.0767,  -4.9005,  -4.9548,\n",
      "         -5.4920,  -5.6040,  -3.1416], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.077\n",
      "activated x value: tensor([-6.6914, -5.7041, -1.3950,  7.3127, -1.1652,  7.0630, -5.4913, -2.6308,\n",
      "         5.9828,  1.4545], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0290], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-14.7204, -13.7331,  -9.4240,  -0.7163,  -9.1942,  -0.9660, -13.5203,\n",
      "        -10.6598,  -2.0463,  -6.5745], grad_fn=<SelectBackward>)\n",
      "target index: 3\n",
      "\n",
      "loss value: -0.716\n",
      "activated x value: tensor([12.2014, -9.5776,  2.5920,  1.5041, -9.0946,  7.9821,  5.5801, -6.2566,\n",
      "         3.4808, -8.1141], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.2175], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6163e-02, -2.1795e+01, -9.6255e+00, -1.0713e+01, -2.1312e+01,\n",
      "        -4.2354e+00, -6.6374e+00, -1.8474e+01, -8.7367e+00, -2.0332e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([ -3.1038, -10.3631,   0.3773,   4.6213,  -2.2430,   7.3280,  -7.1690,\n",
      "         -7.4149,  16.3012,   0.0796], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([16.3013], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9405e+01, -2.6664e+01, -1.5924e+01, -1.1680e+01, -1.8544e+01,\n",
      "        -8.9733e+00, -2.3470e+01, -2.3716e+01, -1.3542e-04, -1.6222e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-10.5776,   1.3915,   0.4013,   3.0488,  -2.9592,   2.2753,  -3.2849,\n",
      "         -0.1733,   7.9557,   1.3617], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9701], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8548e+01, -6.5786e+00, -7.5688e+00, -4.9213e+00, -1.0929e+01,\n",
      "        -5.6948e+00, -1.1255e+01, -8.1434e+00, -1.4332e-02, -6.6084e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([ -5.4502,   2.7959,  13.2321,   5.0389,  -6.3291,  -2.6723,   5.2366,\n",
      "        -10.2342,   3.8796,  -4.9570], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.2329], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8683e+01, -1.0437e+01, -7.2956e-04, -8.1939e+00, -1.9562e+01,\n",
      "        -1.5905e+01, -7.9963e+00, -2.3467e+01, -9.3532e+00, -1.8190e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([  3.9625, -14.1373,  -3.2649,   8.6932,  -2.4976,   5.9340,  -9.1860,\n",
      "          0.9401,   5.8857,   3.5248], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.8231], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -4.8606, -22.9603, -12.0879,  -0.1299, -11.3207,  -2.8891, -18.0090,\n",
      "         -7.8829,  -2.9374,  -5.2982], grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -5.298\n",
      "activated x value: tensor([-9.9840,  1.0261, -2.1759,  1.6035,  6.3002,  1.9353, -1.5571, -1.3073,\n",
      "         0.9915,  2.6624], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.3578], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-16.3418,  -5.3317,  -8.5337,  -4.7542,  -0.0576,  -4.4224,  -7.9149,\n",
      "         -7.6651,  -5.3663,  -3.6954], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.058\n",
      "activated x value: tensor([ -1.2248,  -3.4263,   6.7842,   0.6236,  -0.6074,   4.6724,   6.4306,\n",
      "        -10.7842,   3.7053,  -5.9967], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.4114], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -8.6362, -10.8376,  -0.6271,  -6.7878,  -8.0188,  -2.7390,  -0.9808,\n",
      "        -18.1956,  -3.7061, -13.4081], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -2.739\n",
      "activated x value: tensor([  1.1339,  -3.6672,   3.2052,   0.4395,  -0.4183,   7.9219,   3.7954,\n",
      "        -14.6822,   6.6154,  -3.7857], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.1826], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.0487, -11.8497,  -4.9774,  -7.7431,  -8.6008,  -0.2607,  -4.3871,\n",
      "        -22.8648,  -1.5672, -11.9682], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.261\n",
      "activated x value: tensor([ -5.0631,   1.8412,  13.7067,   6.8852, -12.2823,   2.5682,   2.0699,\n",
      "        -10.7195,   4.6432,  -4.8311], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([13.7079], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.8771e+01, -1.1867e+01, -1.2360e-03, -6.8227e+00, -2.5990e+01,\n",
      "        -1.1140e+01, -1.1638e+01, -2.4427e+01, -9.0647e+00, -1.8539e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-2.6481,  0.8883,  1.7557,  1.1969, -1.6283,  3.5346, -1.8591, -3.9509,\n",
      "         4.6433, -2.4232], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.0121], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-7.6602, -4.1238, -3.2564, -3.8152, -6.6404, -1.4775, -6.8712, -8.9630,\n",
      "        -0.3689, -7.4354], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.369\n",
      "activated x value: tensor([-9.3850, -3.1107,  2.2684,  0.5332,  1.2295, -4.4501, -3.5546,  9.8789,\n",
      "         1.5397,  5.4962], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.8923], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9277e+01, -1.3003e+01, -7.6239e+00, -9.3591e+00, -8.6629e+00,\n",
      "        -1.4342e+01, -1.3447e+01, -1.3402e-02, -8.3527e+00, -4.3962e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.013\n",
      "activated x value: tensor([  3.6289, -10.1861,  -4.3499,   0.4479,  -3.9188,   2.6838,  -7.2085,\n",
      "         12.6010,   3.3026,   4.0787], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.6015], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-8.9726e+00, -2.2788e+01, -1.6951e+01, -1.2154e+01, -1.6520e+01,\n",
      "        -9.9178e+00, -1.9810e+01, -4.7207e-04, -9.2989e+00, -8.5228e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-10.7118,   8.9426,   1.0467,   3.5231,  -3.3683,  -1.7385,  -1.0875,\n",
      "          0.7370,   1.2119,   2.2288], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.9494], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.9661e+01, -6.7768e-03, -7.9027e+00, -5.4263e+00, -1.2318e+01,\n",
      "        -1.0688e+01, -1.0037e+01, -8.2124e+00, -7.7375e+00, -6.7206e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.007\n",
      "activated x value: tensor([  9.0398, -12.9376,   5.1287,   0.3066,  -2.9763,   4.5159,   5.2227,\n",
      "         -7.4357,   3.3321,  -3.7426], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.0946], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0548, -22.0322,  -3.9659,  -8.7880, -12.0709,  -4.5788,  -3.8719,\n",
      "        -16.5303,  -5.7625, -12.8372], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.055\n",
      "activated x value: tensor([-0.1059, -8.5041, -0.9568, -0.4194, -0.6536,  0.5310, -6.7416,  9.9355,\n",
      "         0.7459,  5.7786], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.9513], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.0057e+01, -1.8455e+01, -1.0908e+01, -1.0371e+01, -1.0605e+01,\n",
      "        -9.4204e+00, -1.6693e+01, -1.5834e-02, -9.2054e+00, -4.1727e+00],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -0.016\n",
      "activated x value: tensor([-11.1475,   3.6696,   0.7325,   0.1126,   2.2477,   1.5458,  -1.5428,\n",
      "          0.9253,   6.5442,  -3.2432], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.6262], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-17.7736,  -2.9566,  -5.8936,  -6.5136,  -4.3785,  -5.0803,  -8.1689,\n",
      "         -5.7009,  -0.0819,  -9.8693], grad_fn=<SelectBackward>)\n",
      "target index: 8\n",
      "\n",
      "loss value: -0.082\n",
      "activated x value: tensor([-1.6859, -5.4849,  0.9417,  3.8845,  0.4583,  5.1643, -1.6619, -3.4468,\n",
      "         2.0530, -0.8947], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([5.4652], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -7.1511, -10.9501,  -4.5235,  -1.5807,  -5.0069,  -0.3009,  -7.1271,\n",
      "         -8.9120,  -3.4122,  -6.3599], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.301\n",
      "activated x value: tensor([-0.3251, -3.5508,  1.1364,  0.2875,  0.7663,  1.7888,  4.1815, -3.3927,\n",
      "        -0.5313, -0.4118], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.3831], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-4.7082, -7.9339, -3.2467, -4.0956, -3.6168, -2.5943, -0.2015, -7.7758,\n",
      "        -4.9144, -4.7948], grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.202\n",
      "activated x value: tensor([  7.9305, -11.4781,   0.9259,   2.2960,  -3.3458,   0.9522,  -5.2979,\n",
      "          0.9472,   1.6153,   5.2093], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.0018], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -0.0714, -19.4799,  -7.0759,  -5.7058, -11.3476,  -7.0496, -13.2997,\n",
      "         -7.0546,  -6.3866,  -2.7926], grad_fn=<SelectBackward>)\n",
      "target index: 0\n",
      "\n",
      "loss value: -0.071\n",
      "activated x value: tensor([-3.9083, -3.7331,  3.5797, -4.3908,  2.0935, -2.1460, 12.6635, -7.2781,\n",
      "         2.8917,  0.5753], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([12.6637], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.6572e+01, -1.6397e+01, -9.0840e+00, -1.7055e+01, -1.0570e+01,\n",
      "        -1.4810e+01, -2.0218e-04, -1.9942e+01, -9.7721e+00, -1.2088e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 6\n",
      "\n",
      "loss value: -0.000\n",
      "activated x value: tensor([-4.0166, -1.3392,  7.9714,  2.4356,  3.3211, -1.1282,  2.4875, -9.5752,\n",
      "         1.5967, -1.9330], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.9909], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.0075,  -9.3300,  -0.0194,  -5.5553,  -4.6698,  -9.1191,  -5.5033,\n",
      "        -17.5660,  -6.3941,  -9.9239], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.019\n",
      "activated x value: tensor([-5.3850, -8.6962,  3.7900,  3.1880,  2.7216, -3.8936, -3.9063,  5.5914,\n",
      "         0.7269,  6.2700], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.7826], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-12.1676, -15.4788,  -2.9927,  -3.5947,  -4.0610, -10.6762, -10.6890,\n",
      "         -1.1913,  -6.0557,  -0.5126], grad_fn=<SelectBackward>)\n",
      "target index: 7\n",
      "\n",
      "loss value: -1.191\n",
      "activated x value: tensor([-2.5952, -4.0504,  2.6909, -2.5447,  3.8106,  5.9412,  1.1309, -8.4439,\n",
      "         5.5000, -0.6257], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5350], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -9.1301, -10.5854,  -3.8441,  -9.0797,  -2.7243,  -0.5938,  -5.4041,\n",
      "        -14.9789,  -1.0350,  -7.1606], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.594\n",
      "activated x value: tensor([-14.0231,   7.8074,   2.2697,   2.7297,  -2.4265,   0.6914,   0.5515,\n",
      "         -2.8964,   3.9492,   0.5438], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.8404], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-21.8635,  -0.0330,  -5.5707,  -5.1107, -10.2669,  -7.1490,  -7.2889,\n",
      "        -10.7368,  -3.8912,  -7.2966], grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.033\n",
      "activated x value: tensor([-8.8471,  8.6363,  1.6197,  1.7496, -3.7775,  1.9032,  0.9393, -4.2519,\n",
      "         4.1625, -1.8392], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([8.6512], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.7498e+01, -1.4891e-02, -7.0314e+00, -6.9016e+00, -1.2429e+01,\n",
      "        -6.7479e+00, -7.7118e+00, -1.2903e+01, -4.4887e+00, -1.0490e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 1\n",
      "\n",
      "loss value: -0.015\n",
      "activated x value: tensor([ 5.0227, -5.0907,  4.2831,  2.3951, -8.0383,  6.1472, -4.0346, -0.8374,\n",
      "         2.8245, -2.0151], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([6.5794], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -1.5567, -11.6701,  -2.2963,  -4.1843, -14.6177,  -0.4322, -10.6140,\n",
      "         -7.4168,  -3.7549,  -8.5945], grad_fn=<SelectBackward>)\n",
      "target index: 5\n",
      "\n",
      "loss value: -0.432\n",
      "activated x value: tensor([ 3.7372, -8.9440,  6.9429,  0.2807, -3.0510, -0.2139,  1.3969,  3.5327,\n",
      "        -0.0166, -3.2837], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([7.0204], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([ -3.2831, -15.9644,  -0.0775,  -6.7396, -10.0713,  -7.2342,  -5.6234,\n",
      "         -3.4877,  -7.0370, -10.3041], grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.077\n",
      "activated x value: tensor([ 0.7252, -7.8990, 10.6185,  2.4045, -1.9196, -0.5842, -0.5988, -3.1103,\n",
      "         2.0402, -2.9390], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([10.6190], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-9.8938e+00, -1.8518e+01, -5.4264e-04, -8.2146e+00, -1.2539e+01,\n",
      "        -1.1203e+01, -1.1218e+01, -1.3729e+01, -8.5789e+00, -1.3558e+01],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 2\n",
      "\n",
      "loss value: -0.001\n",
      "activated x value: tensor([-3.7325, -1.6886, -0.8260,  0.0408,  4.7137, -0.6581,  0.1609,  0.3798,\n",
      "         0.2993,  2.4185], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([4.8590], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substrated value(loss candidates):\n",
      " tensor([-8.5915, -6.5476, -5.6849, -4.8181, -0.1452, -5.5171, -4.6980, -4.4792,\n",
      "        -4.5597, -2.4404], grad_fn=<SelectBackward>)\n",
      "target index: 4\n",
      "\n",
      "loss value: -0.145\n",
      "activated x value: tensor([-4.7097, -5.9473, -1.7158, -2.3424,  3.6203, -3.0099, -1.9831,  2.5615,\n",
      "         3.8092,  9.6540], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.6601], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.4370e+01, -1.5607e+01, -1.1376e+01, -1.2002e+01, -6.0398e+00,\n",
      "        -1.2670e+01, -1.1643e+01, -7.0986e+00, -5.8509e+00, -6.1350e-03],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.006\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5  # learning rate\n",
    "epochs = 2  # how many epochs to train for\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 가장 간소화 된 신경망 네트워크를 생성하고 훈련해보았음\n",
    "\n",
    "이제 훈련 이후의 손실 값과 정확도를 확인해보자 !\n",
    "\n",
    "우리는 손실 값은 줄어들고 정확도는 올라가기를 기대했으며, 실제로 그렇게 학습이 되었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated x value: tensor([-2.8979, -5.9608, -2.1821, -3.2856,  4.2231, -3.3023, -2.7167,  2.5361,\n",
      "         4.2619,  9.2613], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2756], grad_fn=<SelectBackward>)\n",
      "\n",
      "substrated value(loss candidates):\n",
      " tensor([-1.2174e+01, -1.5236e+01, -1.1458e+01, -1.2561e+01, -5.0526e+00,\n",
      "        -1.2578e+01, -1.1992e+01, -6.7395e+00, -5.0137e+00, -1.4354e-02],\n",
      "       grad_fn=<SelectBackward>)\n",
      "target index: 9\n",
      "\n",
      "loss value: -0.014\n",
      "activated x value: tensor([-2.8979, -5.9608, -2.1821, -3.2856,  4.2231, -3.3023, -2.7167,  2.5361,\n",
      "         4.2619,  9.2613], grad_fn=<SelectBackward>)\n",
      "exponential summation value: tensor([9.2756], grad_fn=<SelectBackward>)\n",
      "\n",
      "tensor(0.0823, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.functional 사용하기\n",
    "------------------------------\n",
    "\n",
    "- 이제 앞서 정의한 함수들과 똑같은 기능을 수행하는 코드를 PyTorch의 `nn` 클래스들을 이용해 리팩토링 할 것\n",
    "- PyTorch의 클래스들을 이용하면 우리는 보다 짧고, 이해하기 쉽고, 확장이 용이한 코드를 작성할 수 있음\n",
    "\n",
    "- 앞서 작성한 코드들을 단축시키기 가장 쉬운 방법은 손수 작성한 활성화 함수와 손실 함수를 `torch.nn.functional`로 대체하는 것\n",
    "- 해당 모듈은 `torch.nn`에 속한 함수들을 모두 포함하며, 다양한 활성화 함수와 신경망을 생성할 때 도움이 될 수 있는 pooling 함수 등을 포함\n",
    "    - 해당 모듈은 convolution 연산을 수행하는 함수, 선형 레이어 등도 포함하고 있지만 해당 기능들은 다른 모듈을 이용하는 것이 편리함\n",
    "- negative log likelihood 손실 값과 log softmax 함수를 사용한다면, PyTorch는 이 둘을 결합한 하나의 함수 `F.cross_entropy`를 제공\n",
    "    - 따라서 손실 함수의 대체를 통해 활성화 함수까지 기존 모델에서 지울 수 있게 됨 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model` 함수에서 더 이상 `log_softmax`를 호출하지 않음에 주목하자\n",
    "\n",
    "그리고 이전과 같이 손실 값과 정확도를 출력해보도록 하자\n",
    "\n",
    "**이전 모델**\n",
    "\n",
    "```\n",
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0823, grad_fn=<NllLossBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module 사용하기\n",
    "-----------------------------\n",
    "- 이제 `nn.Module`와 `nn.Parameter`를 사용해 보다 깔끔하고 정확한 훈련 과정을 거쳐보도록 하자.\n",
    "- 우선 `nn.Module`을 상속 받는 모델을 정의하도록 하자. (`nn.Module`은 자체로 하나의 클래스이며, 클래스 내의 상태 변화를 추적할 수 있음)\n",
    "- 또한 클래스가 가중치와 편향을 관리하게 하고, 순전파를 위한 함수를 정의할 수 있음\n",
    "- `nn.Module`은 다양한 속성과 함수를 자체적으로 포함하고 있으며, 우리는 이중 `.parameters()`와 `.zero_grad()` 함수를 사용할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금부터 함수가 아닌 **객체**를 이용하기 때문에, 모델 객체를 초기화 해주어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 손실 값은 이전과 마찬가지로 계산할 수 있음\n",
    "- 우리는 `nn.Module` 객체를 함수와 마찬가지로 사용할 수 있으며, 내부적으로 PyTorch 프레임워크는 모델의 `forward` 함수를 자동으로 호출해줌\n",
    "    - 즉, `nn.Module` 객체는 *callable* 한 객체라고 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3984, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 우리는 훈련을 수행하는 반복문 내에서 파라미터들을 변수명에 따라 각각 업데이트 해주었으며, 매 배치마다 발생한 기울기를 손수 초기화해주었음\n",
    "\n",
    "```\n",
    "with torch.no_grad():\n",
    "    weights -= weights.grad * lr\n",
    "    bias -= bias.grad * lr\n",
    "    weights.grad.zero_()\n",
    "    bias.grad.zero_()\n",
    "```\n",
    "\n",
    "이제 우리는 `model.parameters()`와 `model.zero_grad()` 메소드를 이용해 해당 과정을 보다 간결하고 손쉽게 수행할 수 있음. \n",
    "\n",
    "이는 이후 보다 복잡한 모델을 사용할 때, 사용자가 모든 파라미터 변수명을 손수 관리하지 않아도 되도록 도와줌\n",
    "\n",
    "```\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()\n",
    "```\n",
    "\n",
    "이제 모델의 훈련 과정을 `fit` 함수로 감싸도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 값이 내려갔는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linear 사용하기\n",
    "-------------------------\n",
    "\n",
    "- 코드 리팩토링을 지속해보도록 하자 !\n",
    "- `self.weights`와 `self.bias`를 손수 정의, 초기화 및 계산하는 대신 선형 연산을 담당하는 `nn.Linear` 계층을 사용해보도록 하자 !\n",
    "- PyTorch는 다양한 기정의된 계층들이 있으며, 해당 계층들을 통해 우리는 모델 내 코드를 엄청나게 간소화 시킬 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Linear 계층은 He Uniform initialization 사용 !\n",
    "        # bias는 기본 값이 True로 설정되어 있어 자동으로 생성됨\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정의한 모델의 객체를 생성하고, 손실 값을 이전과 같이 계산해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3052, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때는 모델 부의 수정만 있었으므로 앞서 정의한 `fit` 함수를 그대로 사용하도록 하자 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1a7b6402a575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim 사용하기\n",
    "------------------------------\n",
    "\n",
    "- PyTorch는 또한 다양한 최적화 알고리즘을 `torch.optim` 라이브러리를 통해 제공한다.\n",
    "- 이제 파라미터들을 손수 업데이트해주지 않고 `step` 함수를 이용해 최적화 알고리즘이 직접 minima를 찾아가도록 할 수 있다.\n",
    "\n",
    "optim의 사용은 앞서 정의한 훈련 과정에서 파라미터를 손수 업데이트 하는 부분을 대체할 수 있다:\n",
    "```\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()\n",
    "```\n",
    "\n",
    "위의 코드 대신 아래와 같은 코드를 사용할 수 있게 된다:\n",
    "\n",
    "```\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "```\n",
    "(`optim.zero_grad()`는 기울기 값들을 0으로 초기화해주며, 해당 함수는 다음 미니배치의 훈련 이전에 호출되어야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델과 최적화 알고리즘들 재사용할 수 있도록 간단한 함수를 정의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0812, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 사용하기\n",
    "------------------------------\n",
    "\n",
    "- PyTorch는 Dataset이라는 추상 클래스를 지님\n",
    "- Dataset은 파이썬 메소드 `len`을 사용하기 위한 `__len__`과 자신이 지니고 있는 원소들의 인덱스를 메기기 위한 `__getitem__` 함수를 지니는 것이면 무엇이든 될 수 있으음\n",
    "- Dataset의 자세한 활용은 [튜토리얼](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)을 참조할 것 !\n",
    "\n",
    "- PyTorch의 `TensorDataset`은 tensor들을 감싸는 데이터셋\n",
    "- 길이와 인덱싱 방법을 정의해주면 `TensorDataset`은 iterate, index 그리고 slice를 기능을 1차원의 tensor와 함께 제공해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_train`와 `y_train`는 `TensorDataset` 하나로 묶을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 우리는 데이터와 라벨 값의 미니배치를 각각 iterate 해야 했음:\n",
    "```\n",
    "xb = x_train[start_i:end_i]\n",
    "yb = y_train[start_i:end_i]\n",
    "```\n",
    "\n",
    "이제는 두 과정을 한 번에 수행 가능:\n",
    "```\n",
    "xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0826, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader 사용하기\n",
    "------------------------------\n",
    "\n",
    "- PyTorch의 `DataLoader` 클래스는 전체 배치를 관리하는 역할을 수행\n",
    "- 아무 `Dataset` 클래스를 이용해서 `DataLoader` 클래스를 생성할 수 있음\n",
    "- `DataLoader`는 배치 사이즈로 나뉘어진 미니 배치들을 iterate 하기 쉽게 도와줌\n",
    "- `train_ds[i*bs : i*bs+bs]`를 통해 인덱싱을 않아도 DataLoader는 미니 배치를 자동으로 제공해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000, batch size: 64, total mini-batches: 782\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "print(f'Total: {len(x_train)}, batch size: {bs}, total mini-batches: {len(train_dl)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 우리가 미니배치를 위해 사용한 반복문은 다음과 같음:\n",
    "```\n",
    "n, c = x_train.shape\n",
    "\n",
    "for i in range((n-1)//bs + 1):\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "    pred = model(xb)\n",
    "```\n",
    "\n",
    "이제 DataLoader를 이용함에 따라 미니배치가 자동으로 할당되고, 반복문을 다음과 같이 더 간결하게 작성할 수 있음:\n",
    "```\n",
    "for xb,yb in train_dl:\n",
    "    pred = model(xb)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3350, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0818, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch가 제공하는 `nn.Module`, `nn.Parameter`, `Dataset` 그리고 `DataLoader` 덕분에 훈련 반복문을 보다 간결하고 이해하기 쉽게 작성할 수 있게 되었음\n",
    "\n",
    "이제 모델을 실용적이고, 효율적으로 생성하기 위해 필요한 기본 기능들을 더 추가해보도록 하자 !\n",
    "\n",
    "validation 과정 추가\n",
    "-----------------------\n",
    "\n",
    "- Section 1에서 우리는 단순히 그럴싸한 훈련 과정을 정의하는데에만 집중했음.\n",
    "- 그러나, 실제 실험에서는 **항상** 모델이 과적합 되지 않는지를 확인하기 위한 `검증 데이터셋`을 지녀야 함\n",
    "\n",
    "\n",
    "- 훈련 데이터를 잘 섞어주는 것은 미니 매치들과 과적합의 상관성을 예방하기 위해 매우 중요한 과정\n",
    "- 훈련 데이터를 섞어주지 않으면 검증 데이터 셋을 섞든, 섞지 않든 항상 같은 검증 손실 값을 발생시킬 것임\n",
    "- But, 검증 데이터 셋에 대해서는 shuffling을 수행해줄 필요가 전혀 없음\n",
    "\n",
    "\n",
    "- 검증 데이터 셋에 대해서는 훈련 데이터 셋의 배치 사이즈에 2배에 달하는 미니 배치를 생성할 것임\n",
    "- 왜냐하면 검증 과정에서는 역전파 과정이 불필요하고 이에 따라 사용되는 메모리가 더 적기 때문 ! (기울기 저장 X)\n",
    "- 이를 활용해 더 큰 크기의 미니 배치를 할당하고, 손실 값을 보다 빨리 계산하도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 매 epoch의 학습 이후, 검증 손실 값을 계산하고 출력하도록 할 것임\n",
    "\n",
    "(훈련 이전에는 `model.train()` 함수를 호출해주고, 추론 이전에는 `model.eval()` 함수를 실행시켜주는 것을 잊지 말도록 하자. 이는 `nn.BatchNorm2d`나 `nn.Dropout`과 같은 계층들이 상황에 맞게 적절한 행동을 취하게 하기 위함이다 !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.3025660812854767\n",
      "Epoch: 1, Loss: 0.2926877439022064\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {(valid_loss / len(valid_dl)).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit() 함수와 get_data() 함수 생성\n",
    "----------------------------------\n",
    "\n",
    "- 이제 다시 조금의 리팩토링을 수행해보도록 하자.\n",
    "- 지금까지 훈련 데이터셋과 검증 데이터셋에서 손실 값을 계산하는 과정을 두 번 거치고 있었다. 이를 개선하기 위해 `loss_batch`라는 함수를 정의하도록 하자.\n",
    "\n",
    "\n",
    "훈련 데이터 셋을 이용해 손실 값을 계산할 때는 최적화 알고리즘 (optimizer) 인자로 넘겨 역전파를 수행하도록 한다.\n",
    "\n",
    "검증 데이터셋의 손실 값을 계산할 때는 역전파를 수행하지 않기 때문에 optimizer를 인자로 넘겨주지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit` 함수는 모델을 훈련하기 위해 필요한 필수 연산들을 수행하며, 매 epoch 마다 훈련, 검증 손실 값을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        # 검증 데이터셋에 대해 손실 값을 구할 때는 전체 데이터셋의 평균 손실 값을 구하도록 한다.\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_data` 함수는 훈련 데이터셋과 검증 데이터셋을 배치로 할당한 DataLoader를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 DataLoader를 얻고, 모델을 실행시키기 까지 단 3줄의 코드만이 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3061266632080078\n",
      "1 0.3007306632041931\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN은 어떻게 구성할 수 있을까?\n",
    "-------------\n",
    "\n",
    "- 우리는 이제 3개의 convolutional 계층을 가진 신경망을 설계해 볼 것\n",
    "- 이전 section들에서 작성한 함수들은 모두 특정 모델을 상정하고 정의된 것이 아니기 때문에 CNN 모델을 설계할 때도 앞서 정의한 함수들을 수정하지 않고 그대로 사용할 수 있음\n",
    "\n",
    "\n",
    "- 이번 설계에서는 기정의된 `Conv2d` 클래스를 convolutional 계층으로 사용할 것\n",
    "- 각각의 convolution 계층은 ReLU 함수를 활성화 함수로 사용\n",
    "- 이후, ReLU를 거친 값들에 Average pooling을 적용 (PyTorch의 `view`는 numpy에서의 `reshape`로 생각할 수 있음 !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # xb : [64, 784]\n",
    "        xb = xb.view(-1, 1, 28, 28)  # xb: [64, 1, 28, 28]\n",
    "        xb = F.relu(self.conv1(xb))  # xb: [64, 16, 14, 14]\n",
    "        xb = F.relu(self.conv2(xb))  # xb: [64, 16, 7, 7]\n",
    "        xb = F.relu(self.conv3(xb))  # xb: [64, 10, 4, 4]\n",
    "        xb = F.avg_pool2d(xb, 4)     # xb: [64, 10, 1, 1]\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Momentum](https://cs231n.github.io/neural-networks-3/#sgd) 업데이트는 SGD의 변형으로 이전의 기울기 업데이트를 고려해 보다 빠른 훈련이 가능케 해준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5ea83f4943ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-3bf2a26cc75e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-cc1144d494db>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-c94a80b93422>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# xb: [64, 1, 28, 28]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# xb: [64, 16, 14, 14]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# xb: [64, 16, 7, 7]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# xb: [64, 10, 4, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# xb: [64, 10, 1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ev/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ev/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential\n",
    "------------------------\n",
    "\n",
    "- `torch.nn`은 손쉽게 사용 가능한 클래스 `Sequential`을 제공하기도 한다.\n",
    "- `Sequential` 객체는 자신이 포함하고 있는 모듈들을 순서대로 실행시켜주는 역할을 담당한다.\n",
    "- 이를 이용해 신경망을 보다 쉽게 작성할 수 있게 된다.\n",
    "\n",
    "\n",
    "- `Sequential`의 장점을 극대화하기 위해 **커스텀 레이어**를 작성해보자.\n",
    "- 예를 들어, PyTorch는 `view`를 수행하기 위한 계층이 따로 존재하지 않는다.\n",
    "    - `view` 함수를 수행하는 `Lambda` 계층을 커스텀 레이어로 작성해 `Sequential`에 추가해보도록 하자 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sequential`을 이용한 모델은 다음과 같이 간단하게 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e9fa5948106d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-3bf2a26cc75e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-cc1144d494db>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ev/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ev/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU 사용하기\n",
    "---------------\n",
    "\n",
    "만약 당신이 CUDA 사용이 가능한 GPU를 가지고 있다면, 훈련 속도를 굉장히 증진시킬 수 있다.\n",
    "\n",
    "이를 CUDA 사용이 가능한지 확인하기 위해 다음과 같은 코드를 실행시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 cuda 옵션을 포함하는 device 객체를 생성하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`preprocess` 함수를 수정해 batch들을 GPU로 옮겨주도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 우리의 모델도 GPU로 옮겨주도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 보다 빠른 훈련 속도를 경험할 수 있게 될 것이다 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마무리하며..\n",
    "-----------------\n",
    "\n",
    "이제 우리는 PyTorch를 이용해 다양한 모델을 훈련할 수 있는 파이프 라인을 정의할 수 있게 되었다 !\n",
    "\n",
    "지금까지 학습한 내용을 요약해보도록 하자:\n",
    "\n",
    "- **torch.nn**\n",
    "    - `Module`: 함수와 같이 호출이 가능하며, 신경망 계층들의 가중치 변화들을 관리할 수 있는 편리한 객체. Module 객체 안에 어떠한 `Parameter`들을 포함하고 있는지를 기록하며, 기울기의 0 초기화, 가중치 업데이트들을 수행할 수 있는 객체 !\n",
    "    - `Parameter`: `Module` 객체에게 가중치의 존재와 역전파를 통해 가중치 업데이트가 필요하다고 알리는 텐서의 Wrapper 클래스. `requires_grad` 속성을 가지고 있는 텐서들만 가중치 업데이트를 받을 수 있음\n",
    "    - `functional`: 활성화 함수, 손실 함수 등을 포함하고 있는 모듈. 합성곱 계층, 선형 계층 등도 포함하지만 앞서 언급한 것과 같이 이들은 nn.Linear와 같이 계층으로 사용하는 것이 바람직\n",
    "\n",
    "\n",
    "- **torch.optim**: `SGD`와 같이 역전파 과정 중 `Parameter`의 가중치를 업데이트 하는 최적화 알고리즘들을 포함\n",
    "\n",
    "\n",
    "- **Dataset**: 길이를 나타내는 `__len__`과 데이터 추출이 가능한 `__getitem__` 함수를 포함해 `TensorDataset`과 같이 편리한 클래스들을 제공해주는 추상 인터페이스 객체\n",
    "\n",
    "\n",
    "- **DataLoader**: `Dataset`을 받아 데이터를 반복문에서 사용할 수 있는 mini batch들로 변환해주는 객체"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
