{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training and updating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "with open('spaCy/exercises/iphone.json') as f:\n",
    "    TEXTS = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to preorder the iPhone X',\n",
       " 'iPhone X is coming',\n",
       " 'Should I pay $1,000 for the iPhone X?',\n",
       " 'The iPhone 8 reviews are here',\n",
       " 'Your iPhone goes up to 11 today',\n",
       " 'I need a new phone! Any tips?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{'LOWER':'iphone'}, {'LOWER':'x'}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{'LOWER':'iphone'}, {'IS_DIGIT':True, 'OP':'?'}] \n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add('GADGET', None, pattern1, pattern2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET'), (20, 26, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET'), (0, 6, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET'), (28, 34, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, 'GADGET') for span in spans]\n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {'entities':entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "    \n",
    "print(*TRAINING_DATA, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = [\n",
    "    (\"How to preorder the iPhone X\", {'entities': [(20, 28, 'GADGET')]})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for 10 iterations\n",
    "for i in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    # Create batches and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        # Split the batch in texts and annotations\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "        \n",
    "# Save the model\n",
    "#nlp.to_disk(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "\n",
    "with open(\"spaCy/exercises/gadgets.json\") as f:\n",
    "    TRAINING_DATA = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\") # tokenizer\n",
    "ner = nlp.create_pipe(\"ner\") # entitiy recognizer 를 pipe에 추가!\n",
    "nlp.add_pipe(ner)\n",
    "ner.add_label(\"GADGET\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['How to preorder the iPhone X', {'entities': [[20, 28, 'GADGET']]}],\n",
       " ['iPhone X is coming', {'entities': [[0, 8, 'GADGET']]}],\n",
       " ['Should I pay $1,000 for the iPhone X?', {'entities': [[28, 36, 'GADGET']]}],\n",
       " ['The iPhone 8 reviews are here', {'entities': [[4, 12, 'GADGET']]}],\n",
       " ['Your iPhone goes up to 11 today', {'entities': [[5, 11, 'GADGET']]}],\n",
       " ['I need a new phone! Any tips?', {'entities': []}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 7.760874032974243}\n",
      "{'ner': 12.152697265148163}\n",
      "{'ner': 15.706751629710197}\n",
      "{'ner': 1.812375183799304}\n",
      "{'ner': 6.4459035091567785}\n",
      "{'ner': 9.585161367780529}\n",
      "{'ner': 2.1559822793351486}\n",
      "{'ner': 4.640617244294845}\n",
      "{'ner': 8.396100066951476}\n",
      "{'ner': 3.2555352989584208}\n",
      "{'ner': 4.697562226559967}\n",
      "{'ner': 8.055177561473101}\n",
      "{'ner': 0.9545068128209095}\n",
      "{'ner': 2.9374474006181117}\n",
      "{'ner': 4.395142194494838}\n",
      "{'ner': 0.6991139204328647}\n",
      "{'ner': 2.0966594541823724}\n",
      "{'ner': 2.254309345508638}\n",
      "{'ner': 0.07469282332397142}\n",
      "{'ner': 1.3934085878148608}\n",
      "{'ner': 1.3940566562108714}\n",
      "{'ner': 0.00022648402086744568}\n",
      "{'ner': 0.0012043443527964826}\n",
      "{'ner': 0.8097342398529399}\n",
      "{'ner': 0.0003391681372058031}\n",
      "{'ner': 0.0005922831563225373}\n",
      "{'ner': 2.2507665140497672}\n",
      "{'ner': 8.111711790181886e-05}\n",
      "{'ner': 8.231224039434437e-05}\n",
      "{'ner': 2.074323022602053}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
